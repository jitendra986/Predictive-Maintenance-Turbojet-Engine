{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26732,
     "status": "ok",
     "timestamp": 1718627582985,
     "user": {
      "displayName": "jitendra tiwari",
      "userId": "04882265798590373880"
     },
     "user_tz": -120
    },
    "id": "70-XsHkDGUKu",
    "outputId": "6bb24682-dbae-4c4e-be23-bdb60fe62dee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /home/eragroup/anaconda3/lib/python3.7/site-packages (2.9.1)\n",
      "Requirement already satisfied: packaging in /home/eragroup/anaconda3/lib/python3.7/site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: numpy>=1.20 in /home/eragroup/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.21.6)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in /home/eragroup/anaconda3/lib/python3.7/site-packages (from tensorflow) (2.9.1)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in /home/eragroup/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /home/eragroup/anaconda3/lib/python3.7/site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/eragroup/anaconda3/lib/python3.7/site-packages (from tensorflow) (4.2.0)\n",
      "Requirement already satisfied: setuptools in /home/eragroup/anaconda3/lib/python3.7/site-packages (from tensorflow) (62.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/eragroup/anaconda3/lib/python3.7/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /home/eragroup/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/eragroup/anaconda3/lib/python3.7/site-packages (from tensorflow) (14.0.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/eragroup/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.12.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/eragroup/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.31.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/eragroup/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.11.2)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/eragroup/anaconda3/lib/python3.7/site-packages (from tensorflow) (0.2.2)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/eragroup/anaconda3/lib/python3.7/site-packages (from tensorflow) (0.26.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/eragroup/anaconda3/lib/python3.7/site-packages (from tensorflow) (3.8.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /home/eragroup/anaconda3/lib/python3.7/site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /home/eragroup/anaconda3/lib/python3.7/site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/eragroup/anaconda3/lib/python3.7/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/eragroup/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/eragroup/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/eragroup/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/eragroup/anaconda3/lib/python3.7/site-packages (from astunparse>=1.6.0->tensorflow) (0.33.6)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/eragroup/anaconda3/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.1.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/eragroup/anaconda3/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/eragroup/anaconda3/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.27.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/eragroup/anaconda3/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/eragroup/anaconda3/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/eragroup/anaconda3/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.20.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/eragroup/anaconda3/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/eragroup/anaconda3/lib/python3.7/site-packages (from packaging->tensorflow) (2.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/eragroup/anaconda3/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.6)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/eragroup/anaconda3/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/eragroup/anaconda3/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.1.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/eragroup/anaconda3/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in /home/eragroup/anaconda3/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (0.23)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/eragroup/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/eragroup/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/eragroup/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/eragroup/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2019.9.11)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/eragroup/anaconda3/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/eragroup/anaconda3/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/eragroup/anaconda3/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.8.0)\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19128,
     "status": "ok",
     "timestamp": 1718627615090,
     "user": {
      "displayName": "jitendra tiwari",
      "userId": "04882265798590373880"
     },
     "user_tz": -120
    },
    "id": "3wOjKm186Pth",
    "outputId": "42183fc5-359b-4a36-ec2e-4e7ee208179f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-19 15:16:12.596348: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-19 15:16:12.742402: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-8.0/lib64:/usr/local/cuda-8.0/extras/CUPTI/lib64:\n",
      "2024-09-19 15:16:12.742424: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base has been moved to tensorflow.python.trackable.base. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.checkpoint_management has been moved to tensorflow.python.checkpoint.checkpoint_management. The old module will be deleted in version 2.9.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.resource has been moved to tensorflow.python.trackable.resource. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base_delegate has been moved to tensorflow.python.trackable.base_delegate. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.graph_view has been moved to tensorflow.python.checkpoint.graph_view. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.python_state has been moved to tensorflow.python.trackable.python_state. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.functional_saver has been moved to tensorflow.python.checkpoint.functional_saver. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.checkpoint_options has been moved to tensorflow.python.checkpoint.checkpoint_options. The old module will be deleted in version 2.11.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-19 15:16:14.764195: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-19 15:16:14.796206: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-8.0/lib64:/usr/local/cuda-8.0/extras/CUPTI/lib64:\n",
      "2024-09-19 15:16:14.796364: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-8.0/lib64:/usr/local/cuda-8.0/extras/CUPTI/lib64:\n",
      "2024-09-19 15:16:14.796491: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cud"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 11524782617819832223\n",
       " xla_global_id: -1]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "a/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-8.0/lib64:/usr/local/cuda-8.0/extras/CUPTI/lib64:\n",
      "2024-09-19 15:16:14.799170: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-8.0/lib64:/usr/local/cuda-8.0/extras/CUPTI/lib64:\n",
      "2024-09-19 15:16:14.799315: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-8.0/lib64:/usr/local/cuda-8.0/extras/CUPTI/lib64:\n",
      "2024-09-19 15:16:14.799443: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-8.0/lib64:/usr/local/cuda-8.0/extras/CUPTI/lib64:\n",
      "2024-09-19 15:16:14.799457: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1867] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1718627615091,
     "user": {
      "displayName": "jitendra tiwari",
      "userId": "04882265798590373880"
     },
     "user_tz": -120
    },
    "id": "4BsYPkY7gYGx"
   },
   "outputs": [],
   "source": [
    "# Multiclass classification\n",
    "#Predict if an asset will fail within two different intervals related to the two different decisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2iklamKYlNjh"
   },
   "source": [
    "`tensorflow.keras`: This imports the Keras module from TensorFlow, which provides an API for building and training deep learning models.<br>\n",
    "`os`: This module provides functions for interacting with the operating system. It's commonly used for tasks such as file manipulation and directory operations.<br>\n",
    "`sklearn.preprocessing`: This module from scikit-learn provides functions for preprocessing data, such as scaling, normalization, and encoding categorical variables.<br>\n",
    "`sklearn.metrics`: This module contains functions for evaluating model performance, such as computing confusion matrices, recall scores, and precision scores.<br>\n",
    "`tensorflow.keras.models.Sequential`: This class from Keras represents a sequential model, which is a linear stack of layers. It's used for building feedforward neural networks.<br>\n",
    "`tensorflow.keras.models.load_model`: This function is used to load a pre-trained Keras model from a file.<br>\n",
    "`tensorflow.keras.layers`: This module contains various types of layers that can be added to a Keras model, such as dense (fully connected) layers, dropout layers, and LSTM layers.\n",
    "`multiclass_model_w1_30.h5`:The .h5 extension indicates that the model will be saved in the Hierarchical Data Format version 5 (HDF5) format, which is commonly used for storing large numerical datasets. The model will be saved with the filename **multiclass_model_w1_30.h5.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 2268,
     "status": "ok",
     "timestamp": 1718627620493,
     "user": {
      "displayName": "jitendra tiwari",
      "userId": "04882265798590373880"
     },
     "user_tz": -120
    },
    "id": "QfpzPSgG-If3"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Setting seed for reproducibility\n",
    "np.random.seed(1234)\n",
    "PYTHONHASHSEED = 0\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score\n",
    "from tensorflow.keras.models import Sequential,load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "\n",
    "# define path to save model\n",
    "model_path = 'multiclass_model_w1_30.h5'# This file then contains the already trained network, so that you don't have to retrain every time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EilFg--x-ety"
   },
   "source": [
    "## Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "executionInfo": {
     "elapsed": 251,
     "status": "ok",
     "timestamp": 1718627651010,
     "user": {
      "displayName": "jitendra tiwari",
      "userId": "04882265798590373880"
     },
     "user_tz": -120
    },
    "id": "JjbfnUZGgc3C",
    "outputId": "6d96f27d-6b20-4bec-a2be-2ed504a55ca0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.0007</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.82</td>\n",
       "      <td>1589.70</td>\n",
       "      <td>1400.60</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8138.62</td>\n",
       "      <td>8.4195</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.06</td>\n",
       "      <td>23.4190</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.15</td>\n",
       "      <td>1591.82</td>\n",
       "      <td>1403.14</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8131.49</td>\n",
       "      <td>8.4318</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.00</td>\n",
       "      <td>23.4236</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.0043</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1587.99</td>\n",
       "      <td>1404.20</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8133.23</td>\n",
       "      <td>8.4178</td>\n",
       "      <td>0.03</td>\n",
       "      <td>390</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.95</td>\n",
       "      <td>23.3442</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1582.79</td>\n",
       "      <td>1401.87</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8133.83</td>\n",
       "      <td>8.3682</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.88</td>\n",
       "      <td>23.3739</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.37</td>\n",
       "      <td>1582.85</td>\n",
       "      <td>1406.22</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8133.80</td>\n",
       "      <td>8.4294</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.90</td>\n",
       "      <td>23.4044</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1       2       3      4       5       6        7        8      9   \\\n",
       "0   1   1 -0.0007 -0.0004  100.0  518.67  641.82  1589.70  1400.60  14.62   \n",
       "1   1   2  0.0019 -0.0003  100.0  518.67  642.15  1591.82  1403.14  14.62   \n",
       "2   1   3 -0.0043  0.0003  100.0  518.67  642.35  1587.99  1404.20  14.62   \n",
       "3   1   4  0.0007  0.0000  100.0  518.67  642.35  1582.79  1401.87  14.62   \n",
       "4   1   5 -0.0019 -0.0002  100.0  518.67  642.37  1582.85  1406.22  14.62   \n",
       "\n",
       "   ...       18      19    20   21    22     23     24       25  26  27  \n",
       "0  ...  8138.62  8.4195  0.03  392  2388  100.0  39.06  23.4190 NaN NaN  \n",
       "1  ...  8131.49  8.4318  0.03  392  2388  100.0  39.00  23.4236 NaN NaN  \n",
       "2  ...  8133.23  8.4178  0.03  390  2388  100.0  38.95  23.3442 NaN NaN  \n",
       "3  ...  8133.83  8.3682  0.03  392  2388  100.0  38.88  23.3739 NaN NaN  \n",
       "4  ...  8133.80  8.4294  0.03  393  2388  100.0  38.90  23.4044 NaN NaN  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read training data - It is the aircraft engine run-to-failure data.\n",
    "train_df = pd.read_csv('PM_train.txt', sep=\" \", header=None)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 285,
     "status": "ok",
     "timestamp": 1718627653067,
     "user": {
      "displayName": "jitendra tiwari",
      "userId": "04882265798590373880"
     },
     "user_tz": -120
    },
    "id": "XBjr189aTPt1",
    "outputId": "4c02043a-513d-4edd-cd67-6ea664a41de7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20631, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XrpsNnInsevi"
   },
   "source": [
    "`train_df.sort_values(['id','cycle'])`: This line sorts the DataFrame **train_df** first by the 'id' column and then by the 'cycle' column. It ensures that the data is ordered by engine ID and cycle number, which may be necessary for certain analyses or modeling tasks. The sorted DataFrame is then assigned back to the variable **train_df**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 360,
     "status": "ok",
     "timestamp": 1718627659356,
     "user": {
      "displayName": "jitendra tiwari",
      "userId": "04882265798590373880"
     },
     "user_tz": -120
    },
    "id": "mo0v9RsVriPz"
   },
   "outputs": [],
   "source": [
    "train_df.drop(train_df.columns[[26, 27]], axis=1, inplace=True)\n",
    "train_df.columns = ['id', 'cycle', 'setting1', 'setting2', 'setting3', 's1', 's2', 's3',\n",
    "                     's4', 's5', 's6', 's7', 's8', 's9', 's10', 's11', 's12', 's13', 's14',\n",
    "                     's15', 's16', 's17', 's18', 's19', 's20', 's21']\n",
    "\n",
    "train_df = train_df.sort_values(['id','cycle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "executionInfo": {
     "elapsed": 290,
     "status": "ok",
     "timestamp": 1718627661504,
     "user": {
      "displayName": "jitendra tiwari",
      "userId": "04882265798590373880"
     },
     "user_tz": -120
    },
    "id": "E7x-rVZz6Ptq",
    "outputId": "0c2cc3b7-5974-4b39-d653-d08f95eb88bc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cycle</th>\n",
       "      <th>setting1</th>\n",
       "      <th>setting2</th>\n",
       "      <th>setting3</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>...</th>\n",
       "      <th>s12</th>\n",
       "      <th>s13</th>\n",
       "      <th>s14</th>\n",
       "      <th>s15</th>\n",
       "      <th>s16</th>\n",
       "      <th>s17</th>\n",
       "      <th>s18</th>\n",
       "      <th>s19</th>\n",
       "      <th>s20</th>\n",
       "      <th>s21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.0007</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.82</td>\n",
       "      <td>1589.70</td>\n",
       "      <td>1400.60</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>521.66</td>\n",
       "      <td>2388.02</td>\n",
       "      <td>8138.62</td>\n",
       "      <td>8.4195</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.06</td>\n",
       "      <td>23.4190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.15</td>\n",
       "      <td>1591.82</td>\n",
       "      <td>1403.14</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.28</td>\n",
       "      <td>2388.07</td>\n",
       "      <td>8131.49</td>\n",
       "      <td>8.4318</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.00</td>\n",
       "      <td>23.4236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.0043</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1587.99</td>\n",
       "      <td>1404.20</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.42</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8133.23</td>\n",
       "      <td>8.4178</td>\n",
       "      <td>0.03</td>\n",
       "      <td>390</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.95</td>\n",
       "      <td>23.3442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1582.79</td>\n",
       "      <td>1401.87</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.86</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>8133.83</td>\n",
       "      <td>8.3682</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.88</td>\n",
       "      <td>23.3739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.37</td>\n",
       "      <td>1582.85</td>\n",
       "      <td>1406.22</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.19</td>\n",
       "      <td>2388.04</td>\n",
       "      <td>8133.80</td>\n",
       "      <td>8.4294</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.90</td>\n",
       "      <td>23.4044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20626</td>\n",
       "      <td>100</td>\n",
       "      <td>196</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.49</td>\n",
       "      <td>1597.98</td>\n",
       "      <td>1428.63</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>519.49</td>\n",
       "      <td>2388.26</td>\n",
       "      <td>8137.60</td>\n",
       "      <td>8.4956</td>\n",
       "      <td>0.03</td>\n",
       "      <td>397</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.49</td>\n",
       "      <td>22.9735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20627</td>\n",
       "      <td>100</td>\n",
       "      <td>197</td>\n",
       "      <td>-0.0016</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.54</td>\n",
       "      <td>1604.50</td>\n",
       "      <td>1433.58</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>519.68</td>\n",
       "      <td>2388.22</td>\n",
       "      <td>8136.50</td>\n",
       "      <td>8.5139</td>\n",
       "      <td>0.03</td>\n",
       "      <td>395</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.30</td>\n",
       "      <td>23.1594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20628</td>\n",
       "      <td>100</td>\n",
       "      <td>198</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.42</td>\n",
       "      <td>1602.46</td>\n",
       "      <td>1428.18</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>520.01</td>\n",
       "      <td>2388.24</td>\n",
       "      <td>8141.05</td>\n",
       "      <td>8.5646</td>\n",
       "      <td>0.03</td>\n",
       "      <td>398</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.44</td>\n",
       "      <td>22.9333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20629</td>\n",
       "      <td>100</td>\n",
       "      <td>199</td>\n",
       "      <td>-0.0011</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.23</td>\n",
       "      <td>1605.26</td>\n",
       "      <td>1426.53</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>519.67</td>\n",
       "      <td>2388.23</td>\n",
       "      <td>8139.29</td>\n",
       "      <td>8.5389</td>\n",
       "      <td>0.03</td>\n",
       "      <td>395</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.29</td>\n",
       "      <td>23.0640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20630</td>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>-0.0032</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.85</td>\n",
       "      <td>1600.38</td>\n",
       "      <td>1432.14</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>519.30</td>\n",
       "      <td>2388.26</td>\n",
       "      <td>8137.33</td>\n",
       "      <td>8.5036</td>\n",
       "      <td>0.03</td>\n",
       "      <td>396</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.37</td>\n",
       "      <td>23.0522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20631 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  cycle  setting1  setting2  setting3      s1      s2       s3  \\\n",
       "0        1      1   -0.0007   -0.0004     100.0  518.67  641.82  1589.70   \n",
       "1        1      2    0.0019   -0.0003     100.0  518.67  642.15  1591.82   \n",
       "2        1      3   -0.0043    0.0003     100.0  518.67  642.35  1587.99   \n",
       "3        1      4    0.0007    0.0000     100.0  518.67  642.35  1582.79   \n",
       "4        1      5   -0.0019   -0.0002     100.0  518.67  642.37  1582.85   \n",
       "...    ...    ...       ...       ...       ...     ...     ...      ...   \n",
       "20626  100    196   -0.0004   -0.0003     100.0  518.67  643.49  1597.98   \n",
       "20627  100    197   -0.0016   -0.0005     100.0  518.67  643.54  1604.50   \n",
       "20628  100    198    0.0004    0.0000     100.0  518.67  643.42  1602.46   \n",
       "20629  100    199   -0.0011    0.0003     100.0  518.67  643.23  1605.26   \n",
       "20630  100    200   -0.0032   -0.0005     100.0  518.67  643.85  1600.38   \n",
       "\n",
       "            s4     s5  ...     s12      s13      s14     s15   s16  s17   s18  \\\n",
       "0      1400.60  14.62  ...  521.66  2388.02  8138.62  8.4195  0.03  392  2388   \n",
       "1      1403.14  14.62  ...  522.28  2388.07  8131.49  8.4318  0.03  392  2388   \n",
       "2      1404.20  14.62  ...  522.42  2388.03  8133.23  8.4178  0.03  390  2388   \n",
       "3      1401.87  14.62  ...  522.86  2388.08  8133.83  8.3682  0.03  392  2388   \n",
       "4      1406.22  14.62  ...  522.19  2388.04  8133.80  8.4294  0.03  393  2388   \n",
       "...        ...    ...  ...     ...      ...      ...     ...   ...  ...   ...   \n",
       "20626  1428.63  14.62  ...  519.49  2388.26  8137.60  8.4956  0.03  397  2388   \n",
       "20627  1433.58  14.62  ...  519.68  2388.22  8136.50  8.5139  0.03  395  2388   \n",
       "20628  1428.18  14.62  ...  520.01  2388.24  8141.05  8.5646  0.03  398  2388   \n",
       "20629  1426.53  14.62  ...  519.67  2388.23  8139.29  8.5389  0.03  395  2388   \n",
       "20630  1432.14  14.62  ...  519.30  2388.26  8137.33  8.5036  0.03  396  2388   \n",
       "\n",
       "         s19    s20      s21  \n",
       "0      100.0  39.06  23.4190  \n",
       "1      100.0  39.00  23.4236  \n",
       "2      100.0  38.95  23.3442  \n",
       "3      100.0  38.88  23.3739  \n",
       "4      100.0  38.90  23.4044  \n",
       "...      ...    ...      ...  \n",
       "20626  100.0  38.49  22.9735  \n",
       "20627  100.0  38.30  23.1594  \n",
       "20628  100.0  38.44  22.9333  \n",
       "20629  100.0  38.29  23.0640  \n",
       "20630  100.0  38.37  23.0522  \n",
       "\n",
       "[20631 rows x 26 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QEpD7amS-lpu"
   },
   "source": [
    "## Data Preprocessing\n",
    "data preprocessing step, particularly for labeling the data for training purposes. Let's break down what each part of the code does:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O5-_dxq60Nf4"
   },
   "source": [
    ">`Data Labeling`: This part calculates the Remaining Useful Life (RUL) or Time to Failure for each engine by finding the maximum cycle number (cycle) for each engine ID (id). The result is stored in a DataFrame rul with columns 'id' and 'max'.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 226,
     "status": "ok",
     "timestamp": 1718627665071,
     "user": {
      "displayName": "jitendra tiwari",
      "userId": "04882265798590373880"
     },
     "user_tz": -120
    },
    "id": "ulY14O06knOI"
   },
   "outputs": [],
   "source": [
    "#######\n",
    "# TRAIN\n",
    "#######\n",
    "# Data Labeling - generate column RUL(Remaining Usefull Life or Time to Failure)\n",
    "rul = pd.DataFrame(train_df.groupby('id')['cycle'].max()).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1718627666649,
     "user": {
      "displayName": "jitendra tiwari",
      "userId": "04882265798590373880"
     },
     "user_tz": -120
    },
    "id": "BnqCery8yupl",
    "outputId": "a8a61e79-462b-411c-83fb-fce3cb8f1957"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cycle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  cycle\n",
       "0   1    192\n",
       "1   2    287\n",
       "2   3    179\n",
       "3   4    189\n",
       "4   5    269"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rul.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ZubPMTD0T9z"
   },
   "source": [
    ">`Merge RUL with Training Data`:the RUL information is merged back into the original training DataFrame **train_df** based on the engine ID. This allows each row in train_df to have the corresponding maximum cycle number as well.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 407,
     "status": "ok",
     "timestamp": 1718627669592,
     "user": {
      "displayName": "jitendra tiwari",
      "userId": "04882265798590373880"
     },
     "user_tz": -120
    },
    "id": "6Ycs7i7Qyu32"
   },
   "outputs": [],
   "source": [
    "rul.columns = ['id', 'max']\n",
    "train_df = train_df.merge(rul, on=['id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1718627670706,
     "user": {
      "displayName": "jitendra tiwari",
      "userId": "04882265798590373880"
     },
     "user_tz": -120
    },
    "id": "AroVzMsuzHhp",
    "outputId": "b0765883-fee3-4fec-d93b-305ecb7a939f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cycle</th>\n",
       "      <th>setting1</th>\n",
       "      <th>setting2</th>\n",
       "      <th>setting3</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>...</th>\n",
       "      <th>s13</th>\n",
       "      <th>s14</th>\n",
       "      <th>s15</th>\n",
       "      <th>s16</th>\n",
       "      <th>s17</th>\n",
       "      <th>s18</th>\n",
       "      <th>s19</th>\n",
       "      <th>s20</th>\n",
       "      <th>s21</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.0007</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.82</td>\n",
       "      <td>1589.70</td>\n",
       "      <td>1400.60</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.02</td>\n",
       "      <td>8138.62</td>\n",
       "      <td>8.4195</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.06</td>\n",
       "      <td>23.4190</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.15</td>\n",
       "      <td>1591.82</td>\n",
       "      <td>1403.14</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.07</td>\n",
       "      <td>8131.49</td>\n",
       "      <td>8.4318</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.00</td>\n",
       "      <td>23.4236</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.0043</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1587.99</td>\n",
       "      <td>1404.20</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8133.23</td>\n",
       "      <td>8.4178</td>\n",
       "      <td>0.03</td>\n",
       "      <td>390</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.95</td>\n",
       "      <td>23.3442</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1582.79</td>\n",
       "      <td>1401.87</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>8133.83</td>\n",
       "      <td>8.3682</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.88</td>\n",
       "      <td>23.3739</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.37</td>\n",
       "      <td>1582.85</td>\n",
       "      <td>1406.22</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.04</td>\n",
       "      <td>8133.80</td>\n",
       "      <td>8.4294</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.90</td>\n",
       "      <td>23.4044</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  cycle  setting1  setting2  setting3      s1      s2       s3       s4  \\\n",
       "0   1      1   -0.0007   -0.0004     100.0  518.67  641.82  1589.70  1400.60   \n",
       "1   1      2    0.0019   -0.0003     100.0  518.67  642.15  1591.82  1403.14   \n",
       "2   1      3   -0.0043    0.0003     100.0  518.67  642.35  1587.99  1404.20   \n",
       "3   1      4    0.0007    0.0000     100.0  518.67  642.35  1582.79  1401.87   \n",
       "4   1      5   -0.0019   -0.0002     100.0  518.67  642.37  1582.85  1406.22   \n",
       "\n",
       "      s5  ...      s13      s14     s15   s16  s17   s18    s19    s20  \\\n",
       "0  14.62  ...  2388.02  8138.62  8.4195  0.03  392  2388  100.0  39.06   \n",
       "1  14.62  ...  2388.07  8131.49  8.4318  0.03  392  2388  100.0  39.00   \n",
       "2  14.62  ...  2388.03  8133.23  8.4178  0.03  390  2388  100.0  38.95   \n",
       "3  14.62  ...  2388.08  8133.83  8.3682  0.03  392  2388  100.0  38.88   \n",
       "4  14.62  ...  2388.04  8133.80  8.4294  0.03  393  2388  100.0  38.90   \n",
       "\n",
       "       s21  max  \n",
       "0  23.4190  192  \n",
       "1  23.4236  192  \n",
       "2  23.3442  192  \n",
       "3  23.3739  192  \n",
       "4  23.4044  192  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d-eouxGv0gpG"
   },
   "source": [
    ">`Calculate RUL`: This line calculates the RUL by subtracting the current cycle number ('cycle') from the maximum cycle number ('max') for each engine. This represents how many more cycles the engine is expected to operate before failure.<br>\n",
    ">`Drop Unnecessary Columns`: After calculating RUL, the 'max' column, which was used temporarily to calculate RUL, is dropped from the DataFrame as it's no longer needed.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "executionInfo": {
     "elapsed": 305,
     "status": "ok",
     "timestamp": 1718627674524,
     "user": {
      "displayName": "jitendra tiwari",
      "userId": "04882265798590373880"
     },
     "user_tz": -120
    },
    "id": "vulNLE0CztxT",
    "outputId": "c91c3d5a-e954-49a4-9148-e01114d896e3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cycle</th>\n",
       "      <th>setting1</th>\n",
       "      <th>setting2</th>\n",
       "      <th>setting3</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>...</th>\n",
       "      <th>s13</th>\n",
       "      <th>s14</th>\n",
       "      <th>s15</th>\n",
       "      <th>s16</th>\n",
       "      <th>s17</th>\n",
       "      <th>s18</th>\n",
       "      <th>s19</th>\n",
       "      <th>s20</th>\n",
       "      <th>s21</th>\n",
       "      <th>RUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.0007</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.82</td>\n",
       "      <td>1589.70</td>\n",
       "      <td>1400.60</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.02</td>\n",
       "      <td>8138.62</td>\n",
       "      <td>8.4195</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.06</td>\n",
       "      <td>23.4190</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.15</td>\n",
       "      <td>1591.82</td>\n",
       "      <td>1403.14</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.07</td>\n",
       "      <td>8131.49</td>\n",
       "      <td>8.4318</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.00</td>\n",
       "      <td>23.4236</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.0043</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1587.99</td>\n",
       "      <td>1404.20</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8133.23</td>\n",
       "      <td>8.4178</td>\n",
       "      <td>0.03</td>\n",
       "      <td>390</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.95</td>\n",
       "      <td>23.3442</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1582.79</td>\n",
       "      <td>1401.87</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>8133.83</td>\n",
       "      <td>8.3682</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.88</td>\n",
       "      <td>23.3739</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.37</td>\n",
       "      <td>1582.85</td>\n",
       "      <td>1406.22</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.04</td>\n",
       "      <td>8133.80</td>\n",
       "      <td>8.4294</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.90</td>\n",
       "      <td>23.4044</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>-0.0034</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.19</td>\n",
       "      <td>1584.07</td>\n",
       "      <td>1395.16</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.06</td>\n",
       "      <td>8130.69</td>\n",
       "      <td>8.4311</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.88</td>\n",
       "      <td>23.3255</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "      <td>97</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.07</td>\n",
       "      <td>1595.77</td>\n",
       "      <td>1407.81</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.06</td>\n",
       "      <td>8128.74</td>\n",
       "      <td>8.4105</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.01</td>\n",
       "      <td>23.2963</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.00</td>\n",
       "      <td>1591.11</td>\n",
       "      <td>1404.56</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.06</td>\n",
       "      <td>8127.89</td>\n",
       "      <td>8.4012</td>\n",
       "      <td>0.03</td>\n",
       "      <td>391</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.96</td>\n",
       "      <td>23.2554</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.46</td>\n",
       "      <td>1592.73</td>\n",
       "      <td>1406.13</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.10</td>\n",
       "      <td>8131.77</td>\n",
       "      <td>8.4481</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.82</td>\n",
       "      <td>23.2323</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>-0.0021</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.22</td>\n",
       "      <td>1589.63</td>\n",
       "      <td>1411.35</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>8132.49</td>\n",
       "      <td>8.4241</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.93</td>\n",
       "      <td>23.4090</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  cycle  setting1  setting2  setting3      s1      s2       s3       s4  \\\n",
       "0    1      1   -0.0007   -0.0004     100.0  518.67  641.82  1589.70  1400.60   \n",
       "1    1      2    0.0019   -0.0003     100.0  518.67  642.15  1591.82  1403.14   \n",
       "2    1      3   -0.0043    0.0003     100.0  518.67  642.35  1587.99  1404.20   \n",
       "3    1      4    0.0007    0.0000     100.0  518.67  642.35  1582.79  1401.87   \n",
       "4    1      5   -0.0019   -0.0002     100.0  518.67  642.37  1582.85  1406.22   \n",
       "..  ..    ...       ...       ...       ...     ...     ...      ...      ...   \n",
       "95   1     96   -0.0034    0.0001     100.0  518.67  642.19  1584.07  1395.16   \n",
       "96   1     97    0.0035   -0.0003     100.0  518.67  642.07  1595.77  1407.81   \n",
       "97   1     98    0.0006    0.0004     100.0  518.67  642.00  1591.11  1404.56   \n",
       "98   1     99   -0.0005   -0.0000     100.0  518.67  642.46  1592.73  1406.13   \n",
       "99   1    100   -0.0021   -0.0003     100.0  518.67  642.22  1589.63  1411.35   \n",
       "\n",
       "       s5  ...      s13      s14     s15   s16  s17   s18    s19    s20  \\\n",
       "0   14.62  ...  2388.02  8138.62  8.4195  0.03  392  2388  100.0  39.06   \n",
       "1   14.62  ...  2388.07  8131.49  8.4318  0.03  392  2388  100.0  39.00   \n",
       "2   14.62  ...  2388.03  8133.23  8.4178  0.03  390  2388  100.0  38.95   \n",
       "3   14.62  ...  2388.08  8133.83  8.3682  0.03  392  2388  100.0  38.88   \n",
       "4   14.62  ...  2388.04  8133.80  8.4294  0.03  393  2388  100.0  38.90   \n",
       "..    ...  ...      ...      ...     ...   ...  ...   ...    ...    ...   \n",
       "95  14.62  ...  2388.06  8130.69  8.4311  0.03  392  2388  100.0  38.88   \n",
       "96  14.62  ...  2388.06  8128.74  8.4105  0.03  392  2388  100.0  39.01   \n",
       "97  14.62  ...  2388.06  8127.89  8.4012  0.03  391  2388  100.0  38.96   \n",
       "98  14.62  ...  2388.10  8131.77  8.4481  0.03  393  2388  100.0  38.82   \n",
       "99  14.62  ...  2388.08  8132.49  8.4241  0.03  392  2388  100.0  38.93   \n",
       "\n",
       "        s21  RUL  \n",
       "0   23.4190  191  \n",
       "1   23.4236  190  \n",
       "2   23.3442  189  \n",
       "3   23.3739  188  \n",
       "4   23.4044  187  \n",
       "..      ...  ...  \n",
       "95  23.3255   96  \n",
       "96  23.2963   95  \n",
       "97  23.2554   94  \n",
       "98  23.2323   93  \n",
       "99  23.4090   92  \n",
       "\n",
       "[100 rows x 27 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['RUL'] = train_df['max'] - train_df['cycle']\n",
    "train_df.drop('max', axis=1, inplace=True)\n",
    "train_df.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oBFd2pLr0odt"
   },
   "source": [
    "> `Labeling for Classification`: This part assigns labels to each data point based on the calculated RUL. It defines thresholds `w1` and `w0`, and assigns:\n",
    ">> * Label 1 ('label1') as 1 if RUL is less than or equal to 'w1', and 0 otherwise.\n",
    ">> * Label2 ('label2') as 1 if RUL is less than or equal to 'w1', 2 if RUL is less than or equal to 'w0', and 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 253,
     "status": "ok",
     "timestamp": 1718627687767,
     "user": {
      "displayName": "jitendra tiwari",
      "userId": "04882265798590373880"
     },
     "user_tz": -120
    },
    "id": "K6wpAOpjyvGl"
   },
   "outputs": [],
   "source": [
    "w1 = 30\n",
    "w0 = 10\n",
    "train_df['label1'] = np.where(train_df['RUL'] <= w1, 1, 0 )\n",
    "train_df['label2'] = train_df['label1']\n",
    "train_df.loc[train_df['RUL'] <= w0, 'label2'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1718627689346,
     "user": {
      "displayName": "jitendra tiwari",
      "userId": "04882265798590373880"
     },
     "user_tz": -120
    },
    "id": "6nJhPwEw1RgE",
    "outputId": "7f353f5c-749d-40cb-a975-21873c79143f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cycle</th>\n",
       "      <th>setting1</th>\n",
       "      <th>setting2</th>\n",
       "      <th>setting3</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>...</th>\n",
       "      <th>s15</th>\n",
       "      <th>s16</th>\n",
       "      <th>s17</th>\n",
       "      <th>s18</th>\n",
       "      <th>s19</th>\n",
       "      <th>s20</th>\n",
       "      <th>s21</th>\n",
       "      <th>RUL</th>\n",
       "      <th>label1</th>\n",
       "      <th>label2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.0007</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.82</td>\n",
       "      <td>1589.70</td>\n",
       "      <td>1400.60</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8.4195</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.06</td>\n",
       "      <td>23.4190</td>\n",
       "      <td>191</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.15</td>\n",
       "      <td>1591.82</td>\n",
       "      <td>1403.14</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8.4318</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.00</td>\n",
       "      <td>23.4236</td>\n",
       "      <td>190</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.0043</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1587.99</td>\n",
       "      <td>1404.20</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8.4178</td>\n",
       "      <td>0.03</td>\n",
       "      <td>390</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.95</td>\n",
       "      <td>23.3442</td>\n",
       "      <td>189</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1582.79</td>\n",
       "      <td>1401.87</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8.3682</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.88</td>\n",
       "      <td>23.3739</td>\n",
       "      <td>188</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.37</td>\n",
       "      <td>1582.85</td>\n",
       "      <td>1406.22</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8.4294</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.90</td>\n",
       "      <td>23.4044</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  cycle  setting1  setting2  setting3      s1      s2       s3       s4  \\\n",
       "0   1      1   -0.0007   -0.0004     100.0  518.67  641.82  1589.70  1400.60   \n",
       "1   1      2    0.0019   -0.0003     100.0  518.67  642.15  1591.82  1403.14   \n",
       "2   1      3   -0.0043    0.0003     100.0  518.67  642.35  1587.99  1404.20   \n",
       "3   1      4    0.0007    0.0000     100.0  518.67  642.35  1582.79  1401.87   \n",
       "4   1      5   -0.0019   -0.0002     100.0  518.67  642.37  1582.85  1406.22   \n",
       "\n",
       "      s5  ...     s15   s16  s17   s18    s19    s20      s21  RUL  label1  \\\n",
       "0  14.62  ...  8.4195  0.03  392  2388  100.0  39.06  23.4190  191       0   \n",
       "1  14.62  ...  8.4318  0.03  392  2388  100.0  39.00  23.4236  190       0   \n",
       "2  14.62  ...  8.4178  0.03  390  2388  100.0  38.95  23.3442  189       0   \n",
       "3  14.62  ...  8.3682  0.03  392  2388  100.0  38.88  23.3739  188       0   \n",
       "4  14.62  ...  8.4294  0.03  393  2388  100.0  38.90  23.4044  187       0   \n",
       "\n",
       "   label2  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F_8MNc2Z6Ptu"
   },
   "source": [
    "## Now I want to separate the training set into a training and validation set. I will use 80 training sets for the training and 20 training sets as evaluation sets for the PdM policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 272,
     "status": "ok",
     "timestamp": 1718627694382,
     "user": {
      "displayName": "jitendra tiwari",
      "userId": "04882265798590373880"
     },
     "user_tz": -120
    },
    "id": "Sdm_ZG3E6Ptv"
   },
   "outputs": [],
   "source": [
    "list_ID = np.arange(81,101,1) # I take the 20 last #TODO: make this random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "13rqadVW6Ptv"
   },
   "source": [
    "## I separate into training and validation set before any data scaling is performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 377,
     "status": "ok",
     "timestamp": 1718627811514,
     "user": {
      "displayName": "jitendra tiwari",
      "userId": "04882265798590373880"
     },
     "user_tz": -120
    },
    "id": "2nwuKyvt6Ptw"
   },
   "outputs": [],
   "source": [
    "validation_df = train_df.loc[train_df['id'].isin(list_ID)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "executionInfo": {
     "elapsed": 376,
     "status": "ok",
     "timestamp": 1718627815227,
     "user": {
      "displayName": "jitendra tiwari",
      "userId": "04882265798590373880"
     },
     "user_tz": -120
    },
    "id": "pM4-dDoC6Ptw",
    "outputId": "5d16f5b8-b639-404c-f09a-ce7349ae3148"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cycle</th>\n",
       "      <th>setting1</th>\n",
       "      <th>setting2</th>\n",
       "      <th>setting3</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>...</th>\n",
       "      <th>s15</th>\n",
       "      <th>s16</th>\n",
       "      <th>s17</th>\n",
       "      <th>s18</th>\n",
       "      <th>s19</th>\n",
       "      <th>s20</th>\n",
       "      <th>s21</th>\n",
       "      <th>RUL</th>\n",
       "      <th>label1</th>\n",
       "      <th>label2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>16138</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.0050</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.04</td>\n",
       "      <td>1589.91</td>\n",
       "      <td>1406.63</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8.4455</td>\n",
       "      <td>0.03</td>\n",
       "      <td>391</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.87</td>\n",
       "      <td>23.3365</td>\n",
       "      <td>239</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16139</td>\n",
       "      <td>81</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.65</td>\n",
       "      <td>1586.25</td>\n",
       "      <td>1407.88</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8.4573</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.91</td>\n",
       "      <td>23.3452</td>\n",
       "      <td>238</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16140</td>\n",
       "      <td>81</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.55</td>\n",
       "      <td>1586.42</td>\n",
       "      <td>1396.40</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8.4522</td>\n",
       "      <td>0.03</td>\n",
       "      <td>394</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.04</td>\n",
       "      <td>23.3610</td>\n",
       "      <td>237</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16141</td>\n",
       "      <td>81</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.0001</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.41</td>\n",
       "      <td>1594.89</td>\n",
       "      <td>1404.86</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8.4403</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.77</td>\n",
       "      <td>23.4206</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16142</td>\n",
       "      <td>81</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.41</td>\n",
       "      <td>1590.49</td>\n",
       "      <td>1409.58</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8.3971</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.04</td>\n",
       "      <td>23.3311</td>\n",
       "      <td>235</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20626</td>\n",
       "      <td>100</td>\n",
       "      <td>196</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.49</td>\n",
       "      <td>1597.98</td>\n",
       "      <td>1428.63</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8.4956</td>\n",
       "      <td>0.03</td>\n",
       "      <td>397</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.49</td>\n",
       "      <td>22.9735</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20627</td>\n",
       "      <td>100</td>\n",
       "      <td>197</td>\n",
       "      <td>-0.0016</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.54</td>\n",
       "      <td>1604.50</td>\n",
       "      <td>1433.58</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8.5139</td>\n",
       "      <td>0.03</td>\n",
       "      <td>395</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.30</td>\n",
       "      <td>23.1594</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20628</td>\n",
       "      <td>100</td>\n",
       "      <td>198</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.42</td>\n",
       "      <td>1602.46</td>\n",
       "      <td>1428.18</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8.5646</td>\n",
       "      <td>0.03</td>\n",
       "      <td>398</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.44</td>\n",
       "      <td>22.9333</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20629</td>\n",
       "      <td>100</td>\n",
       "      <td>199</td>\n",
       "      <td>-0.0011</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.23</td>\n",
       "      <td>1605.26</td>\n",
       "      <td>1426.53</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8.5389</td>\n",
       "      <td>0.03</td>\n",
       "      <td>395</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.29</td>\n",
       "      <td>23.0640</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20630</td>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>-0.0032</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.85</td>\n",
       "      <td>1600.38</td>\n",
       "      <td>1432.14</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8.5036</td>\n",
       "      <td>0.03</td>\n",
       "      <td>396</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.37</td>\n",
       "      <td>23.0522</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4493 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  cycle  setting1  setting2  setting3      s1      s2       s3  \\\n",
       "16138   81      1   -0.0050    0.0003     100.0  518.67  642.04  1589.91   \n",
       "16139   81      2    0.0023    0.0002     100.0  518.67  642.65  1586.25   \n",
       "16140   81      3   -0.0005    0.0005     100.0  518.67  642.55  1586.42   \n",
       "16141   81      4   -0.0001   -0.0000     100.0  518.67  642.41  1594.89   \n",
       "16142   81      5    0.0024    0.0002     100.0  518.67  643.41  1590.49   \n",
       "...    ...    ...       ...       ...       ...     ...     ...      ...   \n",
       "20626  100    196   -0.0004   -0.0003     100.0  518.67  643.49  1597.98   \n",
       "20627  100    197   -0.0016   -0.0005     100.0  518.67  643.54  1604.50   \n",
       "20628  100    198    0.0004    0.0000     100.0  518.67  643.42  1602.46   \n",
       "20629  100    199   -0.0011    0.0003     100.0  518.67  643.23  1605.26   \n",
       "20630  100    200   -0.0032   -0.0005     100.0  518.67  643.85  1600.38   \n",
       "\n",
       "            s4     s5  ...     s15   s16  s17   s18    s19    s20      s21  \\\n",
       "16138  1406.63  14.62  ...  8.4455  0.03  391  2388  100.0  38.87  23.3365   \n",
       "16139  1407.88  14.62  ...  8.4573  0.03  392  2388  100.0  38.91  23.3452   \n",
       "16140  1396.40  14.62  ...  8.4522  0.03  394  2388  100.0  39.04  23.3610   \n",
       "16141  1404.86  14.62  ...  8.4403  0.03  392  2388  100.0  38.77  23.4206   \n",
       "16142  1409.58  14.62  ...  8.3971  0.03  392  2388  100.0  39.04  23.3311   \n",
       "...        ...    ...  ...     ...   ...  ...   ...    ...    ...      ...   \n",
       "20626  1428.63  14.62  ...  8.4956  0.03  397  2388  100.0  38.49  22.9735   \n",
       "20627  1433.58  14.62  ...  8.5139  0.03  395  2388  100.0  38.30  23.1594   \n",
       "20628  1428.18  14.62  ...  8.5646  0.03  398  2388  100.0  38.44  22.9333   \n",
       "20629  1426.53  14.62  ...  8.5389  0.03  395  2388  100.0  38.29  23.0640   \n",
       "20630  1432.14  14.62  ...  8.5036  0.03  396  2388  100.0  38.37  23.0522   \n",
       "\n",
       "       RUL  label1  label2  \n",
       "16138  239       0       0  \n",
       "16139  238       0       0  \n",
       "16140  237       0       0  \n",
       "16141  236       0       0  \n",
       "16142  235       0       0  \n",
       "...    ...     ...     ...  \n",
       "20626    4       1       2  \n",
       "20627    3       1       2  \n",
       "20628    2       1       2  \n",
       "20629    1       1       2  \n",
       "20630    0       1       2  \n",
       "\n",
       "[4493 rows x 29 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 263,
     "status": "ok",
     "timestamp": 1718627818022,
     "user": {
      "displayName": "jitendra tiwari",
      "userId": "04882265798590373880"
     },
     "user_tz": -120
    },
    "id": "Q6aoJ3v76Ptx"
   },
   "outputs": [],
   "source": [
    "train_df = train_df[~train_df.id.isin(list_ID)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 288,
     "status": "ok",
     "timestamp": 1718627820336,
     "user": {
      "displayName": "jitendra tiwari",
      "userId": "04882265798590373880"
     },
     "user_tz": -120
    },
    "id": "PyrZZu6_uCJS",
    "outputId": "52f0d9a5-f604-48b0-e839-6c7a3b120c71"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16138, 29), (4493, 29))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, validation_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oPP7siRw6Ptx"
   },
   "source": [
    "# Perform the min max scaling of the training data set\n",
    "# use min_max_scaler.fit_transform()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VYkFz5FqQplh"
   },
   "source": [
    ">`Create a copy of the cycle column`: This line creates a new column named 'cycle_norm' in the train_df DataFrame and initializes it with the values from the original 'cycle' column. This column will be normalized later.<br>\n",
    "> `Select columns for normalization`: This line selects all columns from **train_df** except 'id', 'cycle', 'RUL', 'label1', and 'label2'. These columns are the ones that will undergo normalization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "n_loHDxEQnHc"
   },
   "outputs": [],
   "source": [
    "train_df['cycle_norm'] = train_df['cycle']\n",
    "cols_normalize = train_df.columns.difference(['id','cycle','RUL','label1','label2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cycle_norm', 's1', 's10', 's11', 's12', 's13', 's14', 's15', 's16',\n",
       "       's17', 's18', 's19', 's2', 's20', 's21', 's3', 's4', 's5', 's6', 's7',\n",
       "       's8', 's9', 'setting1', 'setting2', 'setting3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "62AHbVv4RgN-"
   },
   "source": [
    "> `Initialize MinMaxScaler`: This line initializes a MinMaxScaler object from the scikit-learn preprocessing module. This scaler will be used to perform Min-Max normalization.<br>\n",
    "> `Perform Min-Max normalization`: This line applies Min-Max normalization to the selected columns (`cols_normalize`) of the `train_df` DataFrame.<br>\n",
    "> `min_max_scaler.fit_transform(train_df[cols_normalize])` computes the Min-Max normalization for the selected columns.<br>\n",
    "> The resulting normalized values are stored in a new DataFrame called `norm_train_df`, with the same index as `train_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "yA4WFngxQm4Z"
   },
   "outputs": [],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "norm_train_df = pd.DataFrame(min_max_scaler.fit_transform(train_df[cols_normalize]),\n",
    "                             columns=cols_normalize,\n",
    "                             index=train_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MBEf7s4DS3jR"
   },
   "source": [
    "> `Join normalized DataFrame with the original DataFrame`: This line joins the normalized DataFrame (`norm_train_df`) with the original DataFrame (`train_df`) excluding the columns that were normalized.<br>\n",
    "> The resulting DataFrame `join_df` contains both the normalized columns and the original columns that were not normalized.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "ThKcf5Qf6Ptx"
   },
   "outputs": [],
   "source": [
    "# MinMax normalization (from 0 to 1)\n",
    "join_df = train_df[train_df.columns.difference(cols_normalize)].join(norm_train_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dF2-ITehT1_P"
   },
   "source": [
    "`Reorder columns`:\n",
    "> * This line reorders the columns of `join_df` to match the original order of columns in `train_df`.\n",
    "> * The reordered DataFrame is then assigned back to `train_df`, effectively replacing the original DataFrame with the normalized version.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "BWuYsg8eTyoJ"
   },
   "outputs": [],
   "source": [
    "train_df = join_df.reindex(columns = train_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "MrXBeYUg6Ptx"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cycle</th>\n",
       "      <th>setting1</th>\n",
       "      <th>setting2</th>\n",
       "      <th>setting3</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>...</th>\n",
       "      <th>s16</th>\n",
       "      <th>s17</th>\n",
       "      <th>s18</th>\n",
       "      <th>s19</th>\n",
       "      <th>s20</th>\n",
       "      <th>s21</th>\n",
       "      <th>RUL</th>\n",
       "      <th>label1</th>\n",
       "      <th>label2</th>\n",
       "      <th>cycle_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.456647</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.183735</td>\n",
       "      <td>0.425154</td>\n",
       "      <td>0.309757</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.708661</td>\n",
       "      <td>0.725482</td>\n",
       "      <td>191</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.606936</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.283133</td>\n",
       "      <td>0.473456</td>\n",
       "      <td>0.352633</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.661417</td>\n",
       "      <td>0.732001</td>\n",
       "      <td>190</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.248555</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.343373</td>\n",
       "      <td>0.386193</td>\n",
       "      <td>0.370527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.622047</td>\n",
       "      <td>0.619473</td>\n",
       "      <td>189</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.537572</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.343373</td>\n",
       "      <td>0.267715</td>\n",
       "      <td>0.331195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.566929</td>\n",
       "      <td>0.661565</td>\n",
       "      <td>188</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.387283</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.349398</td>\n",
       "      <td>0.269082</td>\n",
       "      <td>0.404625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.582677</td>\n",
       "      <td>0.704790</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16133</td>\n",
       "      <td>80</td>\n",
       "      <td>181</td>\n",
       "      <td>0.739884</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.840361</td>\n",
       "      <td>0.756892</td>\n",
       "      <td>0.787812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.181102</td>\n",
       "      <td>0.369473</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.498615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16134</td>\n",
       "      <td>80</td>\n",
       "      <td>182</td>\n",
       "      <td>0.416185</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.783133</td>\n",
       "      <td>0.621554</td>\n",
       "      <td>0.743754</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.141732</td>\n",
       "      <td>0.151786</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.501385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16135</td>\n",
       "      <td>80</td>\n",
       "      <td>183</td>\n",
       "      <td>0.601156</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.736614</td>\n",
       "      <td>0.878629</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.141732</td>\n",
       "      <td>0.037698</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.504155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16136</td>\n",
       "      <td>80</td>\n",
       "      <td>184</td>\n",
       "      <td>0.358382</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.789157</td>\n",
       "      <td>0.728412</td>\n",
       "      <td>0.809926</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.291339</td>\n",
       "      <td>0.127551</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.506925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16137</td>\n",
       "      <td>80</td>\n",
       "      <td>185</td>\n",
       "      <td>0.583815</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.804217</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.661040</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.149606</td>\n",
       "      <td>0.177438</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.509695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16138 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  cycle  setting1  setting2  setting3   s1        s2        s3  \\\n",
       "0       1      1  0.456647  0.166667       0.0  0.0  0.183735  0.425154   \n",
       "1       1      2  0.606936  0.250000       0.0  0.0  0.283133  0.473456   \n",
       "2       1      3  0.248555  0.750000       0.0  0.0  0.343373  0.386193   \n",
       "3       1      4  0.537572  0.500000       0.0  0.0  0.343373  0.267715   \n",
       "4       1      5  0.387283  0.333333       0.0  0.0  0.349398  0.269082   \n",
       "...    ..    ...       ...       ...       ...  ...       ...       ...   \n",
       "16133  80    181  0.739884  0.666667       0.0  0.0  0.840361  0.756892   \n",
       "16134  80    182  0.416185  0.833333       0.0  0.0  0.783133  0.621554   \n",
       "16135  80    183  0.601156  0.500000       0.0  0.0  0.686747  0.736614   \n",
       "16136  80    184  0.358382  0.666667       0.0  0.0  0.789157  0.728412   \n",
       "16137  80    185  0.583815  0.500000       0.0  0.0  0.804217  0.805195   \n",
       "\n",
       "             s4   s5  ...  s16       s17  s18  s19       s20       s21  RUL  \\\n",
       "0      0.309757  0.0  ...  0.0  0.363636  0.0  0.0  0.708661  0.725482  191   \n",
       "1      0.352633  0.0  ...  0.0  0.363636  0.0  0.0  0.661417  0.732001  190   \n",
       "2      0.370527  0.0  ...  0.0  0.181818  0.0  0.0  0.622047  0.619473  189   \n",
       "3      0.331195  0.0  ...  0.0  0.363636  0.0  0.0  0.566929  0.661565  188   \n",
       "4      0.404625  0.0  ...  0.0  0.454545  0.0  0.0  0.582677  0.704790  187   \n",
       "...         ...  ...  ...  ...       ...  ...  ...       ...       ...  ...   \n",
       "16133  0.787812  0.0  ...  0.0  0.818182  0.0  0.0  0.181102  0.369473    4   \n",
       "16134  0.743754  0.0  ...  0.0  0.727273  0.0  0.0  0.141732  0.151786    3   \n",
       "16135  0.878629  0.0  ...  0.0  0.818182  0.0  0.0  0.141732  0.037698    2   \n",
       "16136  0.809926  0.0  ...  0.0  0.818182  0.0  0.0  0.291339  0.127551    1   \n",
       "16137  0.661040  0.0  ...  0.0  0.818182  0.0  0.0  0.149606  0.177438    0   \n",
       "\n",
       "       label1  label2  cycle_norm  \n",
       "0           0       0    0.000000  \n",
       "1           0       0    0.002770  \n",
       "2           0       0    0.005540  \n",
       "3           0       0    0.008310  \n",
       "4           0       0    0.011080  \n",
       "...       ...     ...         ...  \n",
       "16133       1       2    0.498615  \n",
       "16134       1       2    0.501385  \n",
       "16135       1       2    0.504155  \n",
       "16136       1       2    0.506925  \n",
       "16137       1       2    0.509695  \n",
       "\n",
       "[16138 rows x 30 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "T5AtglSI1t99"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['label2'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "74I2omLtQLLs"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['label1'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "57FSFDb4-r3d"
   },
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6LaPWraKepMF"
   },
   "source": [
    "`Define a function to generate sequences:`\n",
    "> * This function generates sequences of sensor data for each engine (`id`) in the dataset.\n",
    "> * It takes three arguments:\n",
    ">> * `id_df:` DataFrame containing data for a specific engine (`id`).\n",
    ">> * `seq_length:` Length of the sequence window.\n",
    ">> * `seq_cols:` List of column names to include in the sequences.\n",
    "> * It iterates over the rows of `id_df`, creating sequences of length seq_length without padding.<br>\n",
    "> * It ensures that only sequences of the specified length are considered, which is important for sequence-based modeling tasks.<br>\n",
    "\n",
    "`Data Preparation:`\n",
    "> * `data_matrix = id_df[seq_cols].values:`\n",
    ">> * This line extracts the columns specified by `seq_cols` from the DataFrame `id_df` and converts them to a numpy array.<br>\n",
    ">> * It selects only the relevant columns needed for creating sequences.\n",
    "\n",
    "`Sequence Generation:`\n",
    "> * `num_elements:` This line calculates the number of rows (elements) in the data_matrix.<br>\n",
    "> `for start, stop in zip(range(0, num_elements-seq_length), range(seq_length, num_elements)):`\n",
    ">> * This is a loop that iterates over the rows of the data matrix to create sequences.<br>\n",
    ">> * It uses the `zip` function to iterate over two parallel lists: one list starts from 0 to `num_elements` - `seq_length`, and the other starts from `seq_length` to `num_elements`.<br>\n",
    ">> * This ensures that sequences of length `seq_length` are generated without overlap.<br>\n",
    ">> * `start` and `stop` define the start and end indices of each sequence.<br>\n",
    "> `yield data_matrix[start:stop, :]:`\n",
    ">> * This line yields (returns) each sequence as a 2D numpy array.<br>\n",
    ">> * It uses array slicing to extract the rows corresponding to the current sequence range.<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "zSInZu-EkFtf"
   },
   "outputs": [],
   "source": [
    "# pick a large window size of 50 cycles. This sets the length of the sequence window to 50 cycles.\n",
    "sequence_length = 50\n",
    "\n",
    "# function to reshape features into (samples, time steps, features)\n",
    "def gen_sequence(id_df, seq_length, seq_cols):\n",
    "    \"\"\" Only sequences that meet the window-length are considered, no padding is used. This means for testing\n",
    "    we need to drop those which are below the window-length. An alternative would be to pad sequences so that\n",
    "    we can use shorter ones \"\"\"\n",
    "    # for one id I put all the rows in a single matrix\n",
    "    data_matrix = id_df[seq_cols].values\n",
    "    num_elements = data_matrix.shape[0]\n",
    "    # Iterate over two lists in parallel.\n",
    "    # For example id1 have 192 rows and sequence_length is equal to 50\n",
    "    # so zip iterate over two following list of numbers (0,112),(50,192)\n",
    "    # 0 50 -> from row 0 to row 50\n",
    "    # 1 51 -> from row 1 to row 51\n",
    "    # 2 52 -> from row 2 to row 52\n",
    "    # ...\n",
    "    # 111 191 -> from row 111 to 191\n",
    "    for start, stop in zip(range(0, num_elements-seq_length), range(seq_length, num_elements)):\n",
    "        yield data_matrix[start:stop, :]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "aAWprb25jV4h"
   },
   "outputs": [],
   "source": [
    "# pick the feature columns, This selects the columns to be included in the sequences.\n",
    "# sensor_cols contains the sensor data columns (s1 to s21).\n",
    "sensor_cols = ['s' + str(i) for i in range(1,22)]\n",
    "#sequence_cols initially contains the operational settings columns (setting1, setting2, setting3, cycle_norm).\n",
    "# Then, it's extended to include the sensor data columns as well.\n",
    "sequence_cols = ['setting1', 'setting2', 'setting3', 'cycle_norm']\n",
    "sequence_cols.extend(sensor_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YEV0vj7AkJOl"
   },
   "source": [
    "## generate sequences for each engine\n",
    "> * This creates a generator expression that iterates over unique engine IDs in the training data.<br>\n",
    "> * For each engine, it generates sequences using the `gen_sequence` function defined earlier.<br>\n",
    "> * Each sequence is a list of sensor data, and multiple sequences are generated for each engine.<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "gAsGvlwBjVpe"
   },
   "outputs": [],
   "source": [
    "seq_gen = (list(gen_sequence(train_df[train_df['id']==id], sequence_length, sequence_cols))\n",
    "           for id in train_df['id'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z_Fc99j1rPQa"
   },
   "source": [
    "> * This concatenates all the generated sequences into a single numpy array.\n",
    "> * It converts the array to `float32` data type.\n",
    "> * The resulting `seq_array` contains the sequences of sensor data, with shape `(num_sequences, sequence_length, num_features)`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "6C8e0SuHjVbh"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12138, 50, 25)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate sequences and convert to numpy array\n",
    "seq_array = np.concatenate(list(seq_gen)).astype(np.float32)\n",
    "seq_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "An8AqEX_6Pty"
   },
   "outputs": [],
   "source": [
    "# we always take the measurements of the last 50 cycles as input!\n",
    "# Every sequence is reduced by a length of 50 (=sequence_length). We have 80 training sets, 80*50 = 4000 \"less\" inputs\n",
    "# train_df.shape = (16138, 30)\n",
    "# seq_array.shape = (12138, 50, 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Chu8ocOhxkaf"
   },
   "source": [
    "`Function Signature:` This function efficiently generates labels for each sequence of sensor data. It ensures that the labels are correctly aligned with the sequences and handles the special case where the first sequence uses the last label as its target.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "> This function takes three arguments:\n",
    ">> * `id_df:` DataFrame containing data for a specific engine (id).<br>\n",
    ">> * `seq_length`: Length of the sequence window.<br>\n",
    ">> * `label`: List of column names representing the labels.\n",
    "\n",
    "`Data Preparation:`\n",
    "> * `data_matrix = id_df[label].values:`\n",
    ">> * This line extracts the columns specified by label from the DataFrame id_df and converts them to a numpy array.<br>\n",
    ">> * It selects only the relevant label(s) needed for generating sequences.<br>\n",
    "\n",
    "`Label Generation:`\n",
    "> * `num_elements:`This line calculates the number of rows (elements) in the data matrix, which corresponds to the number of labels.<br>\n",
    "> * `return data_matrix[seq_length:num_elements, :]:`\n",
    ">> * This line returns the labels associated with each sequence.<br>\n",
    ">> * It removes the first `seq_length` labels because, for each engine (`id`), the first sequence of size `seq_length` uses the last label as its target. The previous labels are discarded.<br>\n",
    ">> * All subsequent sequences for the same engine (`id`) will have one label associated with them step by step.<br>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "xIDbZQrJ6Pty"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12138, 1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function to generate labels\n",
    "def gen_labels(id_df, seq_length, label):\n",
    "    # For one id I put all the labels in a single matrix.\n",
    "    # For example:\n",
    "    # [[1]\n",
    "    # [4]\n",
    "    # [1]\n",
    "    # [5]\n",
    "    # [9]\n",
    "    # ...\n",
    "    # [200]]\n",
    "    data_matrix = id_df[label].values\n",
    "    num_elements = data_matrix.shape[0]\n",
    "    # I have to remove the first seq_length labels\n",
    "    # because for one id the first sequence of seq_length size have as target\n",
    "    # the last label (the previous ones are discarded).\n",
    "    # All the next id's sequences will have associated step by step one label as target.\n",
    "    return data_matrix[seq_length:num_elements, :]\n",
    "\n",
    "# generate labels\n",
    "label_gen = [gen_labels(train_df[train_df['id']==id], sequence_length, ['label2'])\n",
    "             for id in train_df['id'].unique()]\n",
    "label_array = np.concatenate(label_gen).astype(np.float32)\n",
    "label_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "pjniT37X6Ptz"
   },
   "outputs": [],
   "source": [
    "# When modeling multi-class classification problems using neural networks,\n",
    "# it is good practice to reshape the output attribute from a vector that contains values for each class value to be\n",
    "# a matrix with a boolean for each class value and whether or not a given instance has that class value or not.\n",
    "# This is called one hot encoding or creating dummy variables from a categorical variable.\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6qBrRZdYZiHb"
   },
   "source": [
    "`to_categorical` is a utility function in Keras that converts class vectors (integers) to binary class matrices.<br>\n",
    "`dummy_label_array = to_categorical(label_array):`This line applies one-hot encoding to the `label_array`.<br>\n",
    "`label_array` contains the labels associated with each sequence, where each label represents a class or category.<br>\n",
    "> * One-hot encoding converts these integer labels into binary vectors, where each vector has a length equal to the number of classes and contains a 1 in the position corresponding to the class and 0s elsewhere.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "HEpXlgujjc11"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12138, 1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "e3BMrY396Pt0"
   },
   "outputs": [],
   "source": [
    "dummy_label_array = to_categorical(label_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "XnwyiGj06Pt0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_label_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "M40CNdn7krRw"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12138, 3)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_label_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "Nj3Hmdzl9l2q"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dummy_label_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "dWhWIVl56Pt1",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 3)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_features = seq_array.shape[2]\n",
    "nb_out      = dummy_label_array.shape[1]\n",
    "nb_features, nb_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s0h3i_FJg7pJ"
   },
   "source": [
    "`Extracting Feature and Output Dimensions:`\n",
    "> `nb_features:`Determines the number of features in the input sequence data.<br>\n",
    "> `nb_out:`Determines the number of output classes. It's extracted from the shape of the label array.<br>\n",
    "\n",
    "`Defining the Model Architecture:` describe in the code below.\n",
    "`Compiling the Model:` `model.compile(...)` Here, `categorical_crossentropy` is used as the loss function for multi-class classification.\n",
    "\n",
    "`Model Summary:`Prints a summary of the model architecture, including the layers and their parameters.\n",
    "\n",
    "`Training the Model:` `model.fit(...):` Trains the model on the training data. It specifies the input data (`seq_array`) and the corresponding labels (`dummy_label_array`). Other parameters include the number of epochs, batch size, validation split, verbosity, and callbacks.<br>\n",
    "\n",
    "\n",
    "`history.history.keys():` After training, this prints the keys of the history object, which contains information about training and validation metrics over each epoch.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "r9k0p5-46Pt1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-19 15:16:52.936003: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1867] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 50, 100)           50400     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 50, 100)           0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 50)                30200     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 153       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80,753\n",
      "Trainable params: 80,753\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd5a802ec20> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd5a802ec20> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd4e4edcd40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd4e4edcd40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "58/58 - 17s - loss: 0.4198 - accuracy: 0.8320 - val_loss: 0.2263 - val_accuracy: 0.9110 - 17s/epoch - 295ms/step\n",
      "Epoch 2/10\n",
      "58/58 - 13s - loss: 0.1780 - accuracy: 0.9268 - val_loss: 0.1875 - val_accuracy: 0.9292 - 13s/epoch - 227ms/step\n",
      "Epoch 3/10\n",
      "58/58 - 13s - loss: 0.1356 - accuracy: 0.9437 - val_loss: 0.1319 - val_accuracy: 0.9423 - 13s/epoch - 225ms/step\n",
      "Epoch 4/10\n",
      "58/58 - 13s - loss: 0.1312 - accuracy: 0.9461 - val_loss: 0.1298 - val_accuracy: 0.9374 - 13s/epoch - 225ms/step\n",
      "Epoch 5/10\n",
      "58/58 - 13s - loss: 0.1120 - accuracy: 0.9523 - val_loss: 0.1157 - val_accuracy: 0.9440 - 13s/epoch - 227ms/step\n",
      "Epoch 6/10\n",
      "58/58 - 13s - loss: 0.0997 - accuracy: 0.9592 - val_loss: 0.1552 - val_accuracy: 0.9357 - 13s/epoch - 224ms/step\n",
      "Epoch 7/10\n",
      "58/58 - 13s - loss: 0.1122 - accuracy: 0.9509 - val_loss: 0.1533 - val_accuracy: 0.9341 - 13s/epoch - 224ms/step\n",
      "Epoch 8/10\n",
      "58/58 - 13s - loss: 0.0949 - accuracy: 0.9607 - val_loss: 0.0883 - val_accuracy: 0.9638 - 13s/epoch - 225ms/step\n",
      "Epoch 9/10\n",
      "58/58 - 13s - loss: 0.0956 - accuracy: 0.9615 - val_loss: 0.1232 - val_accuracy: 0.9407 - 13s/epoch - 226ms/step\n",
      "Epoch 10/10\n",
      "58/58 - 13s - loss: 0.0942 - accuracy: 0.9583 - val_loss: 0.0953 - val_accuracy: 0.9522 - 13s/epoch - 226ms/step\n",
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "# Next, we build a deep network.\n",
    "# The first layer is an LSTM layer with 100 units followed by another LSTM layer with 50 units.\n",
    "# Dropout is also applied after each LSTM layer to control overfitting.\n",
    "# Final layer is a Dense output layer with single unit and sigmoid activation since this is a binary classification problem.\n",
    "# build the network\n",
    "\n",
    "# Initializes a sequential model, which allows you to build a model layer by layer.\n",
    "model = Sequential()\n",
    "\n",
    "#Adds an LSTM layer to the model. The first LSTM layer has 100 units, returns sequences, and takes input in the shape of (sequence_length, nb_features).\n",
    "model.add(LSTM(\n",
    "         input_shape=(sequence_length, nb_features),\n",
    "         units=100,\n",
    "         return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "#Adds another LSTM layer with 50 units. This layer does not return sequences, indicating it's the final LSTM layer.\n",
    "model.add(LSTM(\n",
    "          units=50,\n",
    "          return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "#Adds a dense (fully connected) layer to the model with a softmax activation function. This layer produces the output classes.\n",
    "model.add(Dense(units=nb_out, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "# fit the network\n",
    "history = model.fit(seq_array, dummy_label_array, epochs=10, batch_size=200, validation_split=0.05, verbose=2,\n",
    "          callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=0, mode='min'),\n",
    "                       keras.callbacks.ModelCheckpoint(model_path,monitor='val_loss', save_best_only=True, mode='min', verbose=0)]\n",
    "          )\n",
    "\n",
    "# list all data in history\n",
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4sWk2GlE6Pt2"
   },
   "source": [
    "# Every time I retrain the algorithm I get different training results, i.e., also different evaluation of the decisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pWyZJ2mP-1pB"
   },
   "source": [
    "## Model Evaluation on Validation set created during the training (i.e., validation_split=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "FpVYSzXkmk5l"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for Accuracy\n",
    "fig_acc = plt.figure(figsize=(10, 10))\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# fig_acc.savefig(\"model_accuracy.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "-u2aW0bj6Pt3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61/61 [==============================] - 6s 97ms/step - loss: 0.0866 - accuracy: 0.9638\n",
      "Accurracy: 0.9638326168060303\n"
     ]
    }
   ],
   "source": [
    "# summarize history for Loss\n",
    "fig_acc = plt.figure(figsize=(10, 10))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# fig_acc.savefig(\"model_loss.png\")\n",
    "\n",
    "# training metrics\n",
    "scores = model.evaluate(seq_array, dummy_label_array, verbose=1, batch_size=200)\n",
    "print('Accurracy: {}'.format(scores[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iK6St5XcVyd9"
   },
   "source": [
    "`y_pred = (model.predict(seq_array) > 0.5).astype(\"int32\"):` Predicts the abels for the input sequences using the trained model. The predictions are hresholded at 0.5, meaning that any output probability greater than 0.5 is considered as class 1, otherwise class 0. The predictions are then converted to integers (0 or 1).<br>\n",
    "\n",
    "`y_true = dummy_label_array:` Sets the true labels from the dummy label array, which represents the actual labels of the data.\n",
    "then print the **confusion_matrix**\n",
    "\n",
    "`cm = confusion_matrix(y_true.argmax(axis=1), y_pred.argmax(axis=1)):` Computes the confusion matrix using the true labels (`y_true`) and the predicted labels `(y_pred). argmax(axis=1)` is used to convert one-hot encoded labels back to their original integer form before computing the confusion matrix.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "KRwaYKfV6Pt4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fd49ee924d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fd49ee924d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "380/380 [==============================] - 14s 35ms/step\n",
      "Confusion matrix\n",
      "- x-axis is true labels.\n",
      "- y-axis is predicted labels\n",
      "[[9519  139    0]\n",
      " [ 170 1337   93]\n",
      " [   1   37  842]]\n"
     ]
    }
   ],
   "source": [
    "# make predictions and compute confusion matrix\n",
    "# y_pred = model.predict_classes(seq_array,verbose=1, batch_size=200)\n",
    "y_pred = (model.predict(seq_array) > 0.5).astype(\"int32\") # this way (>0.5) the outcome goes from a probability to 0,1\n",
    "y_true = dummy_label_array\n",
    "\n",
    "# test_set = pd.DataFrame(y_pred)\n",
    "# # test_set.to_csv('binary_submit_train.csv', index = None)\n",
    "\n",
    "print('Confusion matrix\\n- x-axis is true labels.\\n- y-axis is predicted labels')\n",
    "cm = confusion_matrix(y_true.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oxvEuR4S-6VI"
   },
   "source": [
    "## Second PdM policy evaluation on the validation set.\n",
    "\n",
    "For each validation set, I need to give the on-line sensor data as input to the trained LSTM.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "k_GqqVKV6Pt4"
   },
   "outputs": [],
   "source": [
    "if os.path.isfile(model_path):\n",
    "    estimator = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "vloF6HXQ6Pt4"
   },
   "outputs": [],
   "source": [
    "# Assumptions for the costs, taken by the 2019 RESS paper\n",
    "C_p    = 100\n",
    "C_c    = 1000\n",
    "C_unav = 10\n",
    "C_inv  = 1\n",
    "DT     = 10  # Decisions can be taken every DT=10\n",
    "L      = 20  # lead time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "PZ-vs1-x6Pt5"
   },
   "outputs": [],
   "source": [
    "array_decisions = np.arange(0,400,10) # decisions can only be made every DT = 10 cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "5KP5yjWw6Pt5"
   },
   "outputs": [],
   "source": [
    "# estimator.predict(seq_array_validation_k).reshape(3) returns a vector with 3 elements\n",
    "# [Pr(RUL>w1), Pr(w0<RUL<=w1), Pr(RUL<=w0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "PqIzk2b96Pt5"
   },
   "outputs": [],
   "source": [
    "validation_df['cycle_norm'] = validation_df['cycle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "pzX435pyxgxD"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4493, 30)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "tAF7B0eOY1BN"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cycle</th>\n",
       "      <th>setting1</th>\n",
       "      <th>setting2</th>\n",
       "      <th>setting3</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>...</th>\n",
       "      <th>s16</th>\n",
       "      <th>s17</th>\n",
       "      <th>s18</th>\n",
       "      <th>s19</th>\n",
       "      <th>s20</th>\n",
       "      <th>s21</th>\n",
       "      <th>RUL</th>\n",
       "      <th>label1</th>\n",
       "      <th>label2</th>\n",
       "      <th>cycle_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>16138</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.0050</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.04</td>\n",
       "      <td>1589.91</td>\n",
       "      <td>1406.63</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03</td>\n",
       "      <td>391</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.87</td>\n",
       "      <td>23.3365</td>\n",
       "      <td>239</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16139</td>\n",
       "      <td>81</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.65</td>\n",
       "      <td>1586.25</td>\n",
       "      <td>1407.88</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.91</td>\n",
       "      <td>23.3452</td>\n",
       "      <td>238</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16140</td>\n",
       "      <td>81</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.55</td>\n",
       "      <td>1586.42</td>\n",
       "      <td>1396.40</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03</td>\n",
       "      <td>394</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.04</td>\n",
       "      <td>23.3610</td>\n",
       "      <td>237</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16141</td>\n",
       "      <td>81</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.0001</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.41</td>\n",
       "      <td>1594.89</td>\n",
       "      <td>1404.86</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.77</td>\n",
       "      <td>23.4206</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16142</td>\n",
       "      <td>81</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.41</td>\n",
       "      <td>1590.49</td>\n",
       "      <td>1409.58</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.04</td>\n",
       "      <td>23.3311</td>\n",
       "      <td>235</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16375</td>\n",
       "      <td>81</td>\n",
       "      <td>238</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.54</td>\n",
       "      <td>1598.68</td>\n",
       "      <td>1428.15</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03</td>\n",
       "      <td>395</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.48</td>\n",
       "      <td>23.0828</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16376</td>\n",
       "      <td>81</td>\n",
       "      <td>239</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.84</td>\n",
       "      <td>1602.45</td>\n",
       "      <td>1429.38</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03</td>\n",
       "      <td>398</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.30</td>\n",
       "      <td>23.0611</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16377</td>\n",
       "      <td>81</td>\n",
       "      <td>240</td>\n",
       "      <td>-0.0026</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>644.01</td>\n",
       "      <td>1601.01</td>\n",
       "      <td>1423.61</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03</td>\n",
       "      <td>397</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.37</td>\n",
       "      <td>23.0289</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16378</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.73</td>\n",
       "      <td>1582.64</td>\n",
       "      <td>1401.58</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03</td>\n",
       "      <td>391</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.84</td>\n",
       "      <td>23.4584</td>\n",
       "      <td>213</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16379</td>\n",
       "      <td>82</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.0025</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.07</td>\n",
       "      <td>1585.10</td>\n",
       "      <td>1395.89</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.10</td>\n",
       "      <td>23.5238</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>242 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  cycle  setting1  setting2  setting3      s1      s2       s3  \\\n",
       "16138  81      1   -0.0050    0.0003     100.0  518.67  642.04  1589.91   \n",
       "16139  81      2    0.0023    0.0002     100.0  518.67  642.65  1586.25   \n",
       "16140  81      3   -0.0005    0.0005     100.0  518.67  642.55  1586.42   \n",
       "16141  81      4   -0.0001   -0.0000     100.0  518.67  642.41  1594.89   \n",
       "16142  81      5    0.0024    0.0002     100.0  518.67  643.41  1590.49   \n",
       "...    ..    ...       ...       ...       ...     ...     ...      ...   \n",
       "16375  81    238    0.0011   -0.0004     100.0  518.67  643.54  1598.68   \n",
       "16376  81    239    0.0068    0.0005     100.0  518.67  643.84  1602.45   \n",
       "16377  81    240   -0.0026   -0.0003     100.0  518.67  644.01  1601.01   \n",
       "16378  82      1    0.0000   -0.0002     100.0  518.67  641.73  1582.64   \n",
       "16379  82      2   -0.0025    0.0001     100.0  518.67  642.07  1585.10   \n",
       "\n",
       "            s4     s5  ...   s16  s17   s18    s19    s20      s21  RUL  \\\n",
       "16138  1406.63  14.62  ...  0.03  391  2388  100.0  38.87  23.3365  239   \n",
       "16139  1407.88  14.62  ...  0.03  392  2388  100.0  38.91  23.3452  238   \n",
       "16140  1396.40  14.62  ...  0.03  394  2388  100.0  39.04  23.3610  237   \n",
       "16141  1404.86  14.62  ...  0.03  392  2388  100.0  38.77  23.4206  236   \n",
       "16142  1409.58  14.62  ...  0.03  392  2388  100.0  39.04  23.3311  235   \n",
       "...        ...    ...  ...   ...  ...   ...    ...    ...      ...  ...   \n",
       "16375  1428.15  14.62  ...  0.03  395  2388  100.0  38.48  23.0828    2   \n",
       "16376  1429.38  14.62  ...  0.03  398  2388  100.0  38.30  23.0611    1   \n",
       "16377  1423.61  14.62  ...  0.03  397  2388  100.0  38.37  23.0289    0   \n",
       "16378  1401.58  14.62  ...  0.03  391  2388  100.0  38.84  23.4584  213   \n",
       "16379  1395.89  14.62  ...  0.03  392  2388  100.0  39.10  23.5238  212   \n",
       "\n",
       "       label1  label2  cycle_norm  \n",
       "16138       0       0           1  \n",
       "16139       0       0           2  \n",
       "16140       0       0           3  \n",
       "16141       0       0           4  \n",
       "16142       0       0           5  \n",
       "...       ...     ...         ...  \n",
       "16375       1       2         238  \n",
       "16376       1       2         239  \n",
       "16377       1       2         240  \n",
       "16378       0       0           1  \n",
       "16379       0       0           2  \n",
       "\n",
       "[242 rows x 30 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_df.head(242)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MBklUcnv6Pt5"
   },
   "source": [
    "## Second PdM policy evaluation on a the whole validation data set (ids 81 to 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "vfyabzdL6Pt_"
   },
   "outputs": [],
   "source": [
    "costs_rep_array   = np.zeros(20) # An array to store costs related to replacements.\n",
    "\n",
    "costs_delay_array = np.zeros(20) # An array to store costs related to delays.\n",
    "costs_stock_array = np.zeros(20) # An array to store costs related to stock.\n",
    "\n",
    "t_LC_array        = np.zeros(20) # An array to store lead time.\n",
    "t_order_array     = np.zeros(20) # An array to store order time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JsWT1ebGbOdz"
   },
   "source": [
    "> 1. Initializes a counter variable to 0.\n",
    "> 2. Iterates over unique IDs in the `validation_df` DataFrame.\n",
    "> 3. For each ID:\n",
    ">> * Sets flags for preventive replacement and ordering to False.<br>\n",
    ">> * Iterates over cycles within the range of the DataFrame.<br>\n",
    ">> * Checks if the current cycle is in the `array_decisions`.<br>\n",
    ">> * If it is, preprocesses the validation data for the LSTM model.<br>\n",
    ">> * Predicts the probability of RUL being smaller than w1 and DT (decision time) using the trained model.<br>\n",
    ">> * Evaluates decision heuristics:\n",
    ">>> * If no order has been placed yet and the cost of preventive replacement is less than or equal to the cost of waiting until `w1`, orders the component and sets the order time.<br>\n",
    ">>> * If the cost of preventive replacement is less than or equal to the cost of waiting until `DT`, performs preventive replacement, calculates related costs, and breaks the loop.<br>\n",
    ">> If preventive replacement is not performed:\n",
    ">>> * Sets the component failure time to the last cycle in the ID's data.<br>\n",
    ">>> * Sets replacement costs to `C_c`.<br>\n",
    ">>> * Calculates delay costs based on whether an order has been placed.<br>\n",
    ">> * Prints diagnostic information for each iteration.\n",
    ">> * Increments the counter.\n",
    "\n",
    "\n",
    "This code essentially simulates a decision-making process for component maintenance based on predictive models and cost considerations.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 25)\n",
      "seq_array_test_k:  [[[0.20809248 0.75       0.         ... 0.         0.5590551  0.6085601 ]\n",
      "  [0.6300578  0.6666667  0.         ... 0.         0.5905512  0.62089   ]\n",
      "  [0.4682081  0.9166667  0.         ... 0.         0.6929134  0.6432823 ]\n",
      "  ...\n",
      "  [0.5317919  0.16666667 0.         ... 0.         0.53543305 0.53869045]\n",
      "  [0.39884394 0.9166667  0.         ... 0.         0.63779527 0.75042516]\n",
      "  [0.54913294 0.9166667  0.         ... 0.         0.6929134  0.6330782 ]]]\n",
      "(60, 25)\n",
      "seq_array_test_k:  [[[0.47976878 0.16666667 0.         ... 0.         0.48031497 0.60430837]\n",
      "  [0.44508672 0.8333333  0.         ... 0.         0.7007874  0.5715703 ]\n",
      "  [0.63583815 0.6666667  0.         ... 0.         0.5984252  0.4890873 ]\n",
      "  ...\n",
      "  [0.5260116  0.6666667  0.         ... 0.         0.6771653  0.71456915]\n",
      "  [0.3236994  0.5833333  0.         ... 0.         0.5511811  0.5575397 ]\n",
      "  [0.5953757  0.16666667 0.         ... 0.         0.6062992  0.46230158]]]\n",
      "(70, 25)\n",
      "seq_array_test_k:  [[[0.5549133  0.25       0.         ... 0.         0.5748032  0.7285998 ]\n",
      "  [0.5202312  0.5        0.         ... 0.         0.6771653  0.51842403]\n",
      "  [0.65317917 0.8333333  0.         ... 0.         0.5984252  0.6466837 ]\n",
      "  ...\n",
      "  [0.42774567 0.8333333  0.         ... 0.         0.496063   0.5616497 ]\n",
      "  [0.41040462 0.16666667 0.         ... 0.         0.5748032  0.5177154 ]\n",
      "  [0.60115606 0.8333333  0.         ... 0.         0.71653545 0.48837867]]]\n",
      "(80, 25)\n",
      "seq_array_test_k:  [[[0.5549133  0.41666666 0.         ... 0.         0.53543305 0.5222506 ]\n",
      "  [0.4682081  0.75       0.         ... 0.         0.51968503 0.5058107 ]\n",
      "  [0.44508672 0.41666666 0.         ... 0.         0.6771653  0.4589002 ]\n",
      "  ...\n",
      "  [0.5549133  0.9166667  0.         ... 0.         0.62992126 0.31717688]\n",
      "  [0.49710983 0.25       0.         ... 0.         0.5590551  0.5874433 ]\n",
      "  [0.45086706 0.8333333  0.         ... 0.         0.56692916 0.52012473]]]\n",
      "(90, 25)\n",
      "seq_array_test_k:  [[[0.40462428 0.9166667  0.         ... 0.         0.5826772  0.6686508 ]\n",
      "  [0.5953757  0.33333334 0.         ... 0.         0.71653545 0.60841835]\n",
      "  [0.68786126 0.9166667  0.         ... 0.         0.47244096 0.55711454]\n",
      "  ...\n",
      "  [0.39884394 0.75       0.         ... 0.         0.44094488 0.598356  ]\n",
      "  [0.7514451  0.16666667 0.         ... 0.         0.62204725 0.5406746 ]\n",
      "  [0.6763006  0.16666667 0.         ... 0.         0.48818898 0.67800456]]]\n",
      "(100, 25)\n",
      "seq_array_test_k:  [[[0.42774567 0.8333333  0.         ... 0.         0.5748032  0.740788  ]\n",
      "  [0.3583815  0.5833333  0.         ... 0.         0.54330707 0.37188208]\n",
      "  [0.433526   1.         0.         ... 0.         0.51968503 0.63038546]\n",
      "  ...\n",
      "  [0.27745664 0.33333334 0.         ... 0.         0.44094488 0.66652495]\n",
      "  [0.50289017 0.8333333  0.         ... 0.         0.54330707 0.51459754]\n",
      "  [0.21387284 0.16666667 0.         ... 0.         0.63779527 0.6502268 ]]]\n",
      "(110, 25)\n",
      "seq_array_test_k:  [[[0.6936416  0.41666666 0.         ... 0.         0.6771653  0.5103458 ]\n",
      "  [0.6473988  0.25       0.         ... 0.         0.41732284 0.52876985]\n",
      "  [0.57225436 0.5833333  0.         ... 0.         0.52755904 0.47491497]\n",
      "  ...\n",
      "  [0.4566474  0.41666666 0.         ... 0.         0.54330707 0.54634356]\n",
      "  [0.58381504 0.9166667  0.         ... 0.         0.5748032  0.5316043 ]\n",
      "  [0.4682081  0.8333333  0.         ... 0.         0.6062992  0.48228458]]]\n",
      "(120, 25)\n",
      "seq_array_test_k:  [[[0.5433526  0.41666666 0.         ... 0.         0.53543305 0.6272676 ]\n",
      "  [0.31213874 0.75       0.         ... 0.         0.511811   0.6053004 ]\n",
      "  [0.39306358 0.33333334 0.         ... 0.         0.52755904 0.6268424 ]\n",
      "  ...\n",
      "  [0.69942194 0.6666667  0.         ... 0.         0.5984252  0.36621314]\n",
      "  [0.19075145 0.6666667  0.         ... 0.         0.4015748  0.61706346]\n",
      "  [0.2601156  0.5833333  0.         ... 0.         0.61417323 0.6203231 ]]]\n",
      "(130, 25)\n",
      "seq_array_test_k:  [[[0.6242775  0.5833333  0.         ... 0.         0.5590551  0.5328798 ]\n",
      "  [0.67052025 0.75       0.         ... 0.         0.53543305 0.69203514]\n",
      "  [0.3815029  0.5833333  0.         ... 0.         0.6929134  0.2361111 ]\n",
      "  ...\n",
      "  [0.4566474  0.8333333  0.         ... 0.         0.5590551  0.37698412]\n",
      "  [0.40462428 0.75       0.         ... 0.         0.48031497 0.5086451 ]\n",
      "  [0.46242774 0.25       0.         ... 0.         0.42519686 0.3465136 ]]]\n",
      "(140, 25)\n",
      "seq_array_test_k:  [[[0.7514451  0.5        0.         ... 0.         0.39370078 0.4284297 ]\n",
      "  [0.45086706 0.33333334 0.         ... 0.         0.62992126 0.66369045]\n",
      "  [0.5260116  0.75       0.         ... 0.         0.43307087 0.51544785]\n",
      "  ...\n",
      "  [0.5202312  0.8333333  0.         ... 0.         0.5748032  0.67403626]\n",
      "  [0.53757226 0.25       0.         ... 0.         0.4566929  0.54152495]\n",
      "  [0.5606936  0.41666666 0.         ... 0.         0.51968503 0.5130386 ]]]\n",
      "(150, 25)\n",
      "seq_array_test_k:  [[[0.46242774 1.         0.         ... 0.         0.48818898 0.6758787 ]\n",
      "  [0.5433526  0.8333333  0.         ... 0.         0.52755904 0.45479023]\n",
      "  [0.60115606 0.41666666 0.         ... 0.         0.52755904 0.53741497]\n",
      "  ...\n",
      "  [0.5953757  0.33333334 0.         ... 0.         0.51968503 0.44940478]\n",
      "  [0.5780347  0.25       0.         ... 0.         0.52755904 0.5428004 ]\n",
      "  [0.51445085 0.9166667  0.         ... 0.         0.48818898 0.42276078]]]\n",
      "(160, 25)\n",
      "seq_array_test_k:  [[[0.51445085 0.75       0.         ... 0.         0.56692916 0.5022676 ]\n",
      "  [0.6763006  0.9166667  0.         ... 0.         0.54330707 0.60218257]\n",
      "  [0.5086705  0.25       0.         ... 0.         0.6062992  0.53202945]\n",
      "  ...\n",
      "  [0.63583815 0.16666667 0.         ... 0.         0.48031497 0.4186508 ]\n",
      "  [0.48554912 0.6666667  0.         ... 0.         0.511811   0.62216556]\n",
      "  [0.3468208  0.25       0.         ... 0.         0.51968503 0.5702948 ]]]\n",
      "(170, 25)\n",
      "seq_array_test_k:  [[[0.33526012 0.9166667  0.         ... 0.         0.4015748  0.4659864 ]\n",
      "  [0.56647396 0.25       0.         ... 0.         0.5590551  0.37542516]\n",
      "  [0.24277456 0.9166667  0.         ... 0.         0.46456692 0.69430274]\n",
      "  ...\n",
      "  [0.5260116  0.33333334 0.         ... 0.         0.511811   0.4160998 ]\n",
      "  [0.76878613 1.         0.         ... 0.         0.496063   0.5005669 ]\n",
      "  [0.5202312  0.5        0.         ... 0.         0.38582677 0.50014174]]]\n",
      "(180, 25)\n",
      "seq_array_test_k:  [[[0.5953757  0.6666667  0.         ... 0.         0.48031497 0.53047055]\n",
      "  [0.60115606 0.6666667  0.         ... 0.         0.51968503 0.48185942]\n",
      "  [0.63583815 0.9166667  0.         ... 0.         0.5748032  0.5607993 ]\n",
      "  ...\n",
      "  [0.68786126 0.41666666 0.         ... 0.         0.37007874 0.3894558 ]\n",
      "  [0.63583815 1.         0.         ... 0.         0.47244096 0.47732428]\n",
      "  [0.37572256 0.33333334 0.         ... 0.         0.37007874 0.47831634]]]\n",
      "(190, 25)\n",
      "seq_array_test_k:  [[[0.36416185 0.5        0.         ... 0.         0.41732284 0.48441043]\n",
      "  [0.33526012 0.41666666 0.         ... 0.         0.39370078 0.46570295]\n",
      "  [0.58381504 0.5833333  0.         ... 0.         0.51968503 0.466695  ]\n",
      "  ...\n",
      "  [0.4913295  0.8333333  0.         ... 0.         0.4488189  0.44019273]\n",
      "  [0.48554912 0.8333333  0.         ... 0.         0.37795275 0.47009638]\n",
      "  [0.6416185  0.5833333  0.         ... 0.         0.4566929  0.43126416]]]\n",
      "(200, 25)\n",
      "seq_array_test_k:  [[[0.5895954  0.5        0.         ... 0.         0.511811   0.4988662 ]\n",
      "  [0.45086706 0.33333334 0.         ... 0.         0.42519686 0.5705782 ]\n",
      "  [0.5260116  0.8333333  0.         ... 0.         0.54330707 0.52820295]\n",
      "  ...\n",
      "  [0.6820809  0.9166667  0.         ... 0.         0.25984251 0.39058957]\n",
      "  [0.45086706 0.9166667  0.         ... 0.         0.27559054 0.36366212]\n",
      "  [0.6300578  0.16666667 0.         ... 0.         0.30708662 0.45564058]]]\n",
      "(210, 25)\n",
      "seq_array_test_k:  [[[0.41618496 0.33333334 0.         ... 0.         0.511811   0.36692178]\n",
      "  [0.68786126 0.25       0.         ... 0.         0.42519686 0.56575966]\n",
      "  [0.45086706 0.75       0.         ... 0.         0.38582677 0.35232428]\n",
      "  ...\n",
      "  [0.20231214 0.8333333  0.         ... 0.         0.28346458 0.35232428]\n",
      "  [0.50289017 0.8333333  0.         ... 0.         0.33070865 0.34509638]\n",
      "  [0.6069364  0.5        0.         ... 0.         0.28346458 0.388322  ]]]\n",
      "(220, 25)\n",
      "seq_array_test_k:  [[[0.5433526  0.16666667 0.         ... 0.         0.511811   0.44274378]\n",
      "  [0.42196533 0.25       0.         ... 0.         0.5590551  0.47378117]\n",
      "  [0.3583815  0.6666667  0.         ... 0.         0.4566929  0.5830499 ]\n",
      "  ...\n",
      "  [0.53757226 0.25       0.         ... 0.         0.4566929  0.30555555]\n",
      "  [0.7745665  0.25       0.         ... 0.         0.25984251 0.35941043]\n",
      "  [0.53757226 0.33333334 0.         ... 0.         0.48031497 0.35104877]]]\n",
      "(230, 25)\n",
      "seq_array_test_k:  [[[0.45086706 0.16666667 0.         ... 0.         0.38582677 0.46754536]\n",
      "  [0.5202312  0.41666666 0.         ... 0.         0.41732284 0.55130386]\n",
      "  [0.433526   0.8333333  0.         ... 0.         0.37007874 0.53514737]\n",
      "  ...\n",
      "  [0.7398844  0.9166667  0.         ... 0.         0.38582677 0.23285148]\n",
      "  [0.78612715 0.16666667 0.         ... 0.         0.3464567  0.29407597]\n",
      "  [0.39884394 0.25       0.         ... 0.         0.33070865 0.32681406]]]\n",
      "(240, 25)\n",
      "seq_array_test_k:  [[[0.5086705  0.8333333  0.         ... 0.         0.56692916 0.43183106]\n",
      "  [0.3236994  0.6666667  0.         ... 0.         0.4015748  0.36082765]\n",
      "  [0.6473988  0.25       0.         ... 0.         0.40944883 0.3015873 ]\n",
      "  ...\n",
      "  [0.5606936  0.16666667 0.         ... 0.         0.2519685  0.24900794]\n",
      "  [0.89017344 0.9166667  0.         ... 0.         0.11023622 0.21825397]\n",
      "  [0.3468208  0.25       0.         ... 0.         0.16535433 0.17261904]]]\n",
      "(50, 25)\n",
      "seq_array_test_k:  [[[0.49710983 0.33333334 0.         ... 0.         0.53543305 0.78132087]\n",
      "  [0.35260117 0.5833333  0.         ... 0.         0.7401575  0.87400794]\n",
      "  [0.27745664 0.75       0.         ... 0.         0.6614173  0.80909866]\n",
      "  ...\n",
      "  [0.5086705  0.33333334 0.         ... 0.         0.62992126 0.74957484]\n",
      "  [0.63583815 0.75       0.         ... 0.         0.62204725 0.62712586]\n",
      "  [0.5606936  0.16666667 0.         ... 0.         0.7007874  0.7508503 ]]]\n",
      "(60, 25)\n",
      "seq_array_test_k:  [[[0.31791908 0.08333334 0.         ... 0.         0.68503934 0.66213155]\n",
      "  [0.28323698 0.08333334 0.         ... 0.         0.7480315  0.7906746 ]\n",
      "  [0.42196533 0.8333333  0.         ... 0.         0.7637795  0.7960601 ]\n",
      "  ...\n",
      "  [0.49710983 0.75       0.         ... 0.         0.5590551  0.64824265]\n",
      "  [0.45086706 0.6666667  0.         ... 0.         0.8582677  0.81575966]\n",
      "  [0.5549133  0.25       0.         ... 0.         0.5590551  0.8725907 ]]]\n",
      "(70, 25)\n",
      "seq_array_test_k:  [[[0.4682081  0.8333333  0.         ... 0.         0.62992126 0.7542517 ]\n",
      "  [0.44508672 0.33333334 0.         ... 0.         0.6771653  0.6672336 ]\n",
      "  [0.57225436 0.8333333  0.         ... 0.         0.7322835  0.68013036]\n",
      "  ...\n",
      "  [0.28323698 0.16666667 0.         ... 0.         0.6456693  0.7585034 ]\n",
      "  [0.5780347  0.75       0.         ... 0.         0.62204725 0.54790246]\n",
      "  [0.3815029  0.41666666 0.         ... 0.         0.6929134  0.81179136]]]\n",
      "(80, 25)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq_array_test_k:  [[[0.5260116  0.75       0.         ... 0.         0.6929134  0.6886338 ]\n",
      "  [0.28901735 0.08333334 0.         ... 0.         0.62992126 0.77508503]\n",
      "  [0.5260116  0.75       0.         ... 0.         0.6614173  0.52706915]\n",
      "  ...\n",
      "  [0.5086705  0.25       0.         ... 0.         0.6929134  0.6814059 ]\n",
      "  [0.48554912 0.8333333  0.         ... 0.         0.6692913  0.66468257]\n",
      "  [0.6242775  0.5        0.         ... 0.         0.8031496  0.6001984 ]]]\n",
      "(90, 25)\n",
      "seq_array_test_k:  [[[0.7109827  0.25       0.         ... 0.         0.77165353 0.73214287]\n",
      "  [0.5086705  0.8333333  0.         ... 0.         0.6692913  0.6883503 ]\n",
      "  [0.433526   0.5833333  0.         ... 0.         0.72440946 0.70209754]\n",
      "  ...\n",
      "  [0.69942194 0.33333334 0.         ... 0.         0.6614173  0.6507937 ]\n",
      "  [0.4566474  0.25       0.         ... 0.         0.71653545 0.7536848 ]\n",
      "  [0.5953757  0.16666667 0.         ... 0.         0.68503934 0.6238662 ]]]\n",
      "(100, 25)\n",
      "seq_array_test_k:  [[[0.6300578  0.41666666 0.         ... 0.         0.63779527 0.74433106]\n",
      "  [0.6820809  0.8333333  0.         ... 0.         0.78740156 0.62783444]\n",
      "  [0.41618496 0.5        0.         ... 0.         0.6535433  0.8272392 ]\n",
      "  ...\n",
      "  [0.716763   0.33333334 0.         ... 0.         0.62992126 0.75382656]\n",
      "  [0.7630058  0.41666666 0.         ... 0.         0.6614173  0.70904195]\n",
      "  [0.3815029  0.25       0.         ... 0.         0.6771653  0.72208047]]]\n",
      "(110, 25)\n",
      "seq_array_test_k:  [[[0.49710983 0.8333333  0.         ... 0.         0.6692913  0.6760204 ]\n",
      "  [0.43930635 0.08333334 0.         ... 0.         0.6692913  0.75949544]\n",
      "  [0.37572256 0.41666666 0.         ... 0.         0.7559055  0.71541953]\n",
      "  ...\n",
      "  [0.6820809  0.16666667 0.         ... 0.         0.5511811  0.7422052 ]\n",
      "  [0.48554912 0.5        0.         ... 0.         0.63779527 0.6466837 ]\n",
      "  [0.5260116  0.75       0.         ... 0.         0.7480315  0.65291953]]]\n",
      "(120, 25)\n",
      "seq_array_test_k:  [[[0.41618496 0.6666667  0.         ... 0.         0.6062992  0.8547336 ]\n",
      "  [0.23121387 0.25       0.         ... 0.         0.7401575  0.74291384]\n",
      "  [0.60115606 0.33333334 0.         ... 0.         0.53543305 0.7152778 ]\n",
      "  ...\n",
      "  [0.5433526  0.6666667  0.         ... 0.         0.6692913  0.8767007 ]\n",
      "  [0.6300578  0.41666666 0.         ... 0.         0.62992126 0.57539684]\n",
      "  [0.68786126 0.16666667 0.         ... 0.         0.62992126 0.7032313 ]]]\n",
      "(130, 25)\n",
      "seq_array_test_k:  [[[0.4682081  0.33333334 0.         ... 0.         0.6062992  0.65802157]\n",
      "  [0.3815029  0.5        0.         ... 0.         0.7480315  0.8500567 ]\n",
      "  [0.60115606 0.25       0.         ... 0.         0.61417323 0.66765875]\n",
      "  ...\n",
      "  [0.47976878 0.75       0.         ... 0.         0.503937   0.65206915]\n",
      "  [0.3815029  0.5        0.         ... 0.         0.5590551  0.63208616]\n",
      "  [0.82080925 0.33333334 0.         ... 0.         0.6771653  0.5314626 ]]]\n",
      "(140, 25)\n",
      "seq_array_test_k:  [[[0.5317919  0.75       0.         ... 0.         0.63779527 0.72491497]\n",
      "  [0.37572256 0.16666667 0.         ... 0.         0.70866144 0.5933957 ]\n",
      "  [0.5260116  0.25       0.         ... 0.         0.6062992  0.74007934]\n",
      "  ...\n",
      "  [0.25433525 0.75       0.         ... 0.         0.71653545 0.6588719 ]\n",
      "  [0.33526012 0.6666667  0.         ... 0.         0.503937   0.66213155]\n",
      "  [0.42774567 0.25       0.         ... 0.         0.6535433  0.7413549 ]]]\n",
      "(150, 25)\n",
      "seq_array_test_k:  [[[0.61271673 0.5        0.         ... 0.         0.68503934 0.8587018 ]\n",
      "  [0.716763   0.         0.         ... 0.         0.5984252  0.7786281 ]\n",
      "  [0.24855492 0.5833333  0.         ... 0.         0.6614173  0.77565193]\n",
      "  ...\n",
      "  [0.44508672 0.25       0.         ... 0.         0.63779527 0.759212  ]\n",
      "  [0.53757226 0.6666667  0.         ... 0.         0.7007874  0.58985263]\n",
      "  [0.47976878 0.33333334 0.         ... 0.         0.51968503 0.72349775]]]\n",
      "(160, 25)\n",
      "seq_array_test_k:  [[[0.5202312  0.5833333  0.         ... 0.         0.77165353 0.79761904]\n",
      "  [0.5549133  0.08333334 0.         ... 0.         0.7480315  0.7402211 ]\n",
      "  [0.58381504 0.5833333  0.         ... 0.         0.6456693  0.71924603]\n",
      "  ...\n",
      "  [0.4566474  0.6666667  0.         ... 0.         0.54330707 0.55739796]\n",
      "  [0.3815029  0.5833333  0.         ... 0.         0.503937   0.67545354]\n",
      "  [0.60115606 0.75       0.         ... 0.         0.5748032  0.62896824]]]\n",
      "(170, 25)\n",
      "seq_array_test_k:  [[[0.50289017 0.41666666 0.         ... 0.         0.6929134  0.76048756]\n",
      "  [0.4913295  0.6666667  0.         ... 0.         0.56692916 0.6669501 ]\n",
      "  [0.5895954  0.6666667  0.         ... 0.         0.5748032  0.6336451 ]\n",
      "  ...\n",
      "  [0.5260116  0.5833333  0.         ... 0.         0.43307087 0.545068  ]\n",
      "  [0.5606936  0.5        0.         ... 0.         0.6692913  0.524093  ]\n",
      "  [0.42196533 0.5        0.         ... 0.         0.54330707 0.517432  ]]]\n",
      "(180, 25)\n",
      "seq_array_test_k:  [[[0.433526   0.75       0.         ... 0.         0.5748032  0.54095805]\n",
      "  [0.6820809  0.33333334 0.         ... 0.         0.61417323 0.7056406 ]\n",
      "  [0.49710983 0.5        0.         ... 0.         0.62204725 0.7322846 ]\n",
      "  ...\n",
      "  [0.5780347  0.25       0.         ... 0.         0.5511811  0.43721655]\n",
      "  [0.49710983 0.16666667 0.         ... 0.         0.5748032  0.44373584]\n",
      "  [0.5606936  0.75       0.         ... 0.         0.46456692 0.63761336]]]\n",
      "(190, 25)\n",
      "seq_array_test_k:  [[[0.5202312  0.16666667 0.         ... 0.         0.5826772  0.5155896 ]\n",
      "  [0.60115606 0.75       0.         ... 0.         0.46456692 0.60374147]\n",
      "  [0.9132948  0.16666667 0.         ... 0.         0.6456693  0.63095236]\n",
      "  ...\n",
      "  [0.61271673 0.5        0.         ... 0.         0.37007874 0.40249434]\n",
      "  [0.4913295  0.5        0.         ... 0.         0.4566929  0.52933675]\n",
      "  [0.54913294 0.33333334 0.         ... 0.         0.56692916 0.49730727]]]\n",
      "(200, 25)\n",
      "seq_array_test_k:  [[[0.5086705  0.5        0.         ... 0.         0.61417323 0.78174603]\n",
      "  [0.5202312  0.75       0.         ... 0.         0.6929134  0.7138606 ]\n",
      "  [0.23121387 0.5        0.         ... 0.         0.5984252  0.64484125]\n",
      "  ...\n",
      "  [0.5260116  0.33333334 0.         ... 0.         0.20472442 0.33545917]\n",
      "  [0.3583815  0.8333333  0.         ... 0.         0.511811   0.24489796]\n",
      "  [0.53757226 0.16666667 0.         ... 0.         0.43307087 0.38548753]]]\n",
      "(210, 25)\n",
      "seq_array_test_k:  [[[0.46242774 0.6666667  0.         ... 0.         0.5984252  0.55711454]\n",
      "  [0.5260116  0.08333334 0.         ... 0.         0.5826772  0.5269274 ]\n",
      "  [0.6416185  0.33333334 0.         ... 0.         0.5748032  0.7719671 ]\n",
      "  ...\n",
      "  [0.37572256 0.5        0.         ... 0.         0.22047244 0.2912415 ]\n",
      "  [0.5317919  0.6666667  0.         ... 0.         0.22047244 0.19316894]\n",
      "  [0.5086705  0.08333334 0.         ... 0.         0.23622048 0.22222222]]]\n",
      "(50, 25)\n",
      "seq_array_test_k:  [[[0.20231214 0.5        0.         ... 0.         0.7637795  0.6656746 ]\n",
      "  [0.41040462 0.41666666 0.         ... 0.         0.8110236  0.5841837 ]\n",
      "  [0.61271673 0.08333334 0.         ... 0.         0.6692913  0.74007934]\n",
      "  ...\n",
      "  [0.43930635 0.8333333  0.         ... 0.         0.5984252  0.7536848 ]\n",
      "  [0.42774567 0.6666667  0.         ... 0.         0.70866144 0.8526077 ]\n",
      "  [0.25433525 0.16666667 0.         ... 0.         0.8582677  0.88506234]]]\n",
      "(60, 25)\n",
      "seq_array_test_k:  [[[0.37572256 0.16666667 0.         ... 0.         0.6614173  0.67701244]\n",
      "  [0.5895954  0.33333334 0.         ... 0.         0.5905512  0.76870745]\n",
      "  [0.4913295  0.75       0.         ... 0.         0.8110236  0.7196712 ]\n",
      "  ...\n",
      "  [0.44508672 0.5        0.         ... 0.         0.70866144 0.6602891 ]\n",
      "  [0.23699422 0.25       0.         ... 0.         0.77165353 0.9394841 ]\n",
      "  [0.39306358 0.5833333  0.         ... 0.         0.7637795  0.6177721 ]]]\n",
      "(70, 25)\n",
      "seq_array_test_k:  [[[0.49710983 0.25       0.         ... 0.         0.8582677  0.7505669 ]\n",
      "  [0.5953757  0.5833333  0.         ... 0.         0.7007874  0.67687076]\n",
      "  [0.5260116  0.6666667  0.         ... 0.         0.7007874  0.805839  ]\n",
      "  ...\n",
      "  [0.48554912 0.8333333  0.         ... 0.         0.62204725 0.7716837 ]\n",
      "  [0.40462428 0.41666666 0.         ... 0.         0.7322835  0.78854877]\n",
      "  [0.5780347  0.33333334 0.         ... 0.         0.72440946 0.6927438 ]]]\n",
      "(80, 25)\n",
      "seq_array_test_k:  [[[0.5202312  0.5        0.         ... 0.         0.6771653  0.81930274]\n",
      "  [0.6242775  0.41666666 0.         ... 0.         0.62992126 0.5882937 ]\n",
      "  [0.56647396 0.41666666 0.         ... 0.         0.6456693  0.97959185]\n",
      "  ...\n",
      "  [0.42774567 0.8333333  0.         ... 0.         0.6456693  0.72874147]\n",
      "  [0.5953757  0.5        0.         ... 0.         0.6614173  0.72619045]\n",
      "  [0.4682081  0.8333333  0.         ... 0.         0.7480315  0.7755102 ]]]\n",
      "(90, 25)\n",
      "seq_array_test_k:  [[[0.3468208  0.33333334 0.         ... 0.         0.7480315  0.66156465]\n",
      "  [0.50289017 0.33333334 0.         ... 0.         0.72440946 0.63435376]\n",
      "  [0.4566474  0.5        0.         ... 0.         0.78740156 0.747449  ]\n",
      "  ...\n",
      "  [0.433526   0.41666666 0.         ... 0.         0.81889766 0.6838152 ]\n",
      "  [0.6473988  0.5        0.         ... 0.         0.62992126 0.6536281 ]\n",
      "  [0.4913295  0.33333334 0.         ... 0.         0.6929134  0.70422333]]]\n",
      "(100, 25)\n",
      "seq_array_test_k:  [[[0.3468208  0.5833333  0.         ... 0.         0.77952754 0.76318026]\n",
      "  [0.5895954  0.08333334 0.         ... 0.         0.7401575  0.8136338 ]\n",
      "  [0.4566474  0.41666666 0.         ... 0.         0.87401575 0.9366497 ]\n",
      "  ...\n",
      "  [0.5317919  0.16666667 0.         ... 0.         0.5984252  0.77380955]\n",
      "  [0.5606936  0.33333334 0.         ... 0.         0.6692913  0.7867063 ]\n",
      "  [0.42196533 0.16666667 0.         ... 0.         0.52755904 0.81235826]]]\n",
      "(110, 25)\n",
      "seq_array_test_k:  [[[0.48554912 0.41666666 0.         ... 0.         0.6692913  0.68466556]\n",
      "  [0.4913295  0.9166667  0.         ... 0.         0.6771653  0.7742347 ]\n",
      "  [0.49710983 0.5833333  0.         ... 0.         0.71653545 0.55371314]\n",
      "  ...\n",
      "  [0.43930635 0.9166667  0.         ... 0.         0.6456693  0.7322846 ]\n",
      "  [0.5953757  0.9166667  0.         ... 0.         0.7480315  0.58205783]\n",
      "  [0.61271673 0.5833333  0.         ... 0.         0.51968503 0.8052721 ]]]\n",
      "(120, 25)\n",
      "seq_array_test_k:  [[[0.5317919  0.75       0.         ... 0.         0.6771653  0.6663832 ]\n",
      "  [0.39884394 0.5833333  0.         ... 0.         0.56692916 0.65433675]\n",
      "  [0.6069364  0.33333334 0.         ... 0.         0.6929134  0.7723923 ]\n",
      "  ...\n",
      "  [0.47398844 0.41666666 0.         ... 0.         0.4488189  0.71031743]\n",
      "  [0.7109827  0.5        0.         ... 0.         0.53543305 0.71201813]\n",
      "  [0.6473988  0.08333334 0.         ... 0.         0.6614173  0.68877554]]]\n",
      "(130, 25)\n",
      "seq_array_test_k:  [[[0.5086705  0.5        0.         ... 0.         0.7007874  0.864229  ]\n",
      "  [0.5953757  0.75       0.         ... 0.         0.8110236  0.6984127 ]\n",
      "  [0.61849713 0.75       0.         ... 0.         0.6692913  0.82653064]\n",
      "  ...\n",
      "  [0.30057803 0.5833333  0.         ... 0.         0.54330707 0.50992066]\n",
      "  [0.31791908 0.5833333  0.         ... 0.         0.6062992  0.75014174]\n",
      "  [0.3815029  0.5833333  0.         ... 0.         0.6692913  0.8055556 ]]]\n",
      "(140, 25)\n",
      "seq_array_test_k:  [[[0.42196533 0.6666667  0.         ... 0.         0.7480315  0.776644  ]\n",
      "  [0.38728324 0.75       0.         ... 0.         0.62204725 0.77820295]\n",
      "  [0.17919075 0.75       0.         ... 0.         0.62204725 0.6235828 ]\n",
      "  ...\n",
      "  [0.4682081  0.75       0.         ... 0.         0.6692913  0.7590703 ]\n",
      "  [0.6242775  0.41666666 0.         ... 0.         0.63779527 0.7919501 ]\n",
      "  [0.76878613 0.75       0.         ... 0.         0.6929134  0.6044501 ]]]\n",
      "(150, 25)\n",
      "seq_array_test_k:  [[[0.4566474  0.41666666 0.         ... 0.         0.62204725 0.5975057 ]\n",
      "  [0.48554912 0.8333333  0.         ... 0.         0.63779527 0.8538832 ]\n",
      "  [0.4913295  0.75       0.         ... 0.         0.6692913  0.7230726 ]\n",
      "  ...\n",
      "  [0.5953757  0.41666666 0.         ... 0.         0.62204725 0.6225907 ]\n",
      "  [0.4566474  0.25       0.         ... 0.         0.5826772  0.5986394 ]\n",
      "  [0.61271673 0.16666667 0.         ... 0.         0.77165353 0.64214855]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 25)\n",
      "seq_array_test_k:  [[[0.4566474  0.8333333  0.         ... 0.         0.62992126 0.7397959 ]\n",
      "  [0.40462428 0.8333333  0.         ... 0.         0.6692913  0.7215136 ]\n",
      "  [0.61849713 0.8333333  0.         ... 0.         0.7480315  0.65121883]\n",
      "  ...\n",
      "  [0.50289017 0.5        0.         ... 0.         0.7480315  0.42729592]\n",
      "  [0.28323698 0.25       0.         ... 0.         0.52755904 0.7361111 ]\n",
      "  [0.5260116  0.75       0.         ... 0.         0.62992126 0.55045354]]]\n",
      "(170, 25)\n",
      "seq_array_test_k:  [[[0.53757226 0.6666667  0.         ... 0.         0.5905512  0.9091553 ]\n",
      "  [0.4682081  0.5833333  0.         ... 0.         0.79527557 0.64597505]\n",
      "  [0.39306358 0.6666667  0.         ... 0.         0.52755904 0.76176304]\n",
      "  ...\n",
      "  [0.5086705  0.75       0.         ... 0.         0.61417323 0.6789966 ]\n",
      "  [0.4913295  0.5        0.         ... 0.         0.7322835  0.76119614]\n",
      "  [0.26589596 0.5        0.         ... 0.         0.6771653  0.50566894]]]\n",
      "(180, 25)\n",
      "seq_array_test_k:  [[[0.4682081  0.8333333  0.         ... 0.         0.63779527 0.73015875]\n",
      "  [0.48554912 0.41666666 0.         ... 0.         0.6692913  0.65008503]\n",
      "  [0.6473988  0.5833333  0.         ... 0.         0.7559055  0.7363946 ]\n",
      "  ...\n",
      "  [0.61849713 0.25       0.         ... 0.         0.5984252  0.67148525]\n",
      "  [0.5549133  0.08333334 0.         ... 0.         0.72440946 0.5127551 ]\n",
      "  [0.57225436 0.8333333  0.         ... 0.         0.77952754 0.6044501 ]]]\n",
      "(190, 25)\n",
      "seq_array_test_k:  [[[0.42774567 0.5        0.         ... 0.         0.7480315  0.6298186 ]\n",
      "  [0.19075145 0.33333334 0.         ... 0.         0.7401575  0.6493764 ]\n",
      "  [0.6647399  0.33333334 0.         ... 0.         0.5590551  0.63761336]\n",
      "  ...\n",
      "  [0.38728324 0.25       0.         ... 0.         0.6614173  0.6972789 ]\n",
      "  [0.433526   0.16666667 0.         ... 0.         0.6692913  0.73214287]\n",
      "  [0.50289017 0.16666667 0.         ... 0.         0.53543305 0.66099775]]]\n",
      "(200, 25)\n",
      "seq_array_test_k:  [[[0.47398844 0.25       0.         ... 0.         0.71653545 0.6758787 ]\n",
      "  [0.57225436 0.5        0.         ... 0.         0.77165353 0.7066327 ]\n",
      "  [0.51445085 0.75       0.         ... 0.         0.6771653  0.6492347 ]\n",
      "  ...\n",
      "  [0.50289017 0.6666667  0.         ... 0.         0.51968503 0.6296769 ]\n",
      "  [0.3236994  0.08333334 0.         ... 0.         0.37007874 0.6305272 ]\n",
      "  [0.4566474  0.33333334 0.         ... 0.         0.5905512  0.51374716]]]\n",
      "(210, 25)\n",
      "seq_array_test_k:  [[[0.36416185 0.08333334 0.         ... 0.         0.6456693  0.72293085]\n",
      "  [0.39884394 0.5        0.         ... 0.         0.46456692 0.57199544]\n",
      "  [0.57225436 0.16666667 0.         ... 0.         0.5905512  0.7736678 ]\n",
      "  ...\n",
      "  [0.3468208  0.75       0.         ... 0.         0.38582677 0.5369898 ]\n",
      "  [0.3815029  0.16666667 0.         ... 0.         0.56692916 0.53656465]\n",
      "  [0.7283237  0.6666667  0.         ... 0.         0.5984252  0.5941043 ]]]\n",
      "(220, 25)\n",
      "seq_array_test_k:  [[[0.44508672 0.41666666 0.         ... 0.         0.5511811  0.5500283 ]\n",
      "  [0.36416185 0.6666667  0.         ... 0.         0.496063   0.6960034 ]\n",
      "  [0.50289017 0.8333333  0.         ... 0.         0.6929134  0.89597505]\n",
      "  ...\n",
      "  [0.2601156  0.75       0.         ... 0.         0.36220473 0.55839   ]\n",
      "  [0.4682081  0.41666666 0.         ... 0.         0.62992126 0.67035145]\n",
      "  [0.31791908 0.75       0.         ... 0.         0.6771653  0.63236964]]]\n",
      "(230, 25)\n",
      "seq_array_test_k:  [[[0.42774567 0.6666667  0.         ... 0.         0.61417323 0.9088719 ]\n",
      "  [0.3583815  0.5833333  0.         ... 0.         0.77165353 0.64625853]\n",
      "  [0.6300578  0.41666666 0.         ... 0.         0.503937   0.53075397]\n",
      "  ...\n",
      "  [0.3236994  0.8333333  0.         ... 0.         0.43307087 0.6053004 ]\n",
      "  [0.41618496 0.33333334 0.         ... 0.         0.496063   0.5277778 ]\n",
      "  [0.49710983 0.5833333  0.         ... 0.         0.53543305 0.48767006]]]\n",
      "(240, 25)\n",
      "seq_array_test_k:  [[[0.5549133  0.5        0.         ... 0.         0.48031497 0.61621314]\n",
      "  [0.3583815  0.8333333  0.         ... 0.         0.7559055  0.477466  ]\n",
      "  [0.4682081  0.8333333  0.         ... 0.         0.5905512  0.38732994]\n",
      "  ...\n",
      "  [0.6589595  0.41666666 0.         ... 0.         0.44094488 0.50340134]\n",
      "  [0.58381504 0.41666666 0.         ... 0.         0.44094488 0.5721372 ]\n",
      "  [0.28901735 0.6666667  0.         ... 0.         0.52755904 0.48568594]]]\n",
      "(250, 25)\n",
      "seq_array_test_k:  [[[0.42196533 0.41666666 0.         ... 0.         0.6062992  0.5575397 ]\n",
      "  [0.39306358 0.75       0.         ... 0.         0.5511811  0.7124433 ]\n",
      "  [0.46242774 0.33333334 0.         ... 0.         0.41732284 0.65150225]\n",
      "  ...\n",
      "  [0.6069364  0.9166667  0.         ... 0.         0.39370078 0.4088719 ]\n",
      "  [0.47398844 0.75       0.         ... 0.         0.41732284 0.3870465 ]\n",
      "  [0.42774567 0.41666666 0.         ... 0.         0.35433072 0.4162415 ]]]\n",
      "(260, 25)\n",
      "seq_array_test_k:  [[[0.38728324 0.25       0.         ... 0.         0.5748032  0.66822565]\n",
      "  [0.28323698 0.75       0.         ... 0.         0.51968503 0.6485261 ]\n",
      "  [0.6589595  0.5        0.         ... 0.         0.5984252  0.45677438]\n",
      "  ...\n",
      "  [0.3583815  0.25       0.         ... 0.         0.5905512  0.3446712 ]\n",
      "  [0.3815029  0.25       0.         ... 0.         0.4488189  0.5605159 ]\n",
      "  [0.51445085 0.9166667  0.         ... 0.         0.27559054 0.45337301]]]\n",
      "(270, 25)\n",
      "seq_array_test_k:  [[[0.6647399  0.16666667 0.         ... 0.         0.6535433  0.58871883]\n",
      "  [0.6936416  0.41666666 0.         ... 0.         0.6062992  0.5882937 ]\n",
      "  [0.45086706 0.16666667 0.         ... 0.         0.5748032  0.595805  ]\n",
      "  ...\n",
      "  [0.38728324 0.75       0.         ... 0.         0.4015748  0.37783447]\n",
      "  [0.7109827  0.75       0.         ... 0.         0.31496063 0.31420067]\n",
      "  [0.41618496 0.75       0.         ... 0.         0.36220473 0.3463719 ]]]\n",
      "(280, 25)\n",
      "seq_array_test_k:  [[[0.58381504 0.08333334 0.         ... 0.         0.4566929  0.50736964]\n",
      "  [0.32947975 0.41666666 0.         ... 0.         0.43307087 0.5728458 ]\n",
      "  [0.49710983 0.8333333  0.         ... 0.         0.44094488 0.60515875]\n",
      "  ...\n",
      "  [0.46242774 0.41666666 0.         ... 0.         0.16535433 0.31746033]\n",
      "  [0.3468208  0.5833333  0.         ... 0.         0.2992126  0.2505669 ]\n",
      "  [0.7456647  0.41666666 0.         ... 0.         0.28346458 0.4084467 ]]]\n",
      "(290, 25)\n",
      "seq_array_test_k:  [[[0.6300578  0.41666666 0.         ... 0.         0.42519686 0.42913833]\n",
      "  [0.3583815  0.5833333  0.         ... 0.         0.503937   0.36975622]\n",
      "  [0.32947975 0.16666667 0.         ... 0.         0.53543305 0.4156746 ]\n",
      "  ...\n",
      "  [0.36416185 0.16666667 0.         ... 0.         0.30708662 0.20890023]\n",
      "  [0.53757226 0.5833333  0.         ... 0.         0.33070865 0.36394557]\n",
      "  [0.3583815  0.33333334 0.         ... 0.         0.26771653 0.285856  ]]]\n",
      "(50, 25)\n",
      "seq_array_test_k:  [[[0.53757226 0.6666667  0.         ... 0.         0.41732284 0.4642857 ]\n",
      "  [0.57225436 0.5833333  0.         ... 0.         0.5511811  0.5654762 ]\n",
      "  [0.31791908 0.16666667 0.         ... 0.         0.48818898 0.47477323]\n",
      "  ...\n",
      "  [0.30057803 0.5833333  0.         ... 0.         0.47244096 0.52933675]\n",
      "  [0.5606936  0.75       0.         ... 0.         0.52755904 0.39172336]\n",
      "  [0.30635837 0.6666667  0.         ... 0.         0.496063   0.5769558 ]]]\n",
      "(60, 25)\n",
      "seq_array_test_k:  [[[0.6763006  0.75       0.         ... 0.         0.48031497 0.48880386]\n",
      "  [0.39884394 0.33333334 0.         ... 0.         0.46456692 0.43523243]\n",
      "  [0.5086705  0.33333334 0.         ... 0.         0.5748032  0.48625284]\n",
      "  ...\n",
      "  [0.4566474  0.25       0.         ... 0.         0.4566929  0.4873866 ]\n",
      "  [0.57225436 0.33333334 0.         ... 0.         0.47244096 0.5185658 ]\n",
      "  [0.25433525 0.41666666 0.         ... 0.         0.51968503 0.58843535]]]\n",
      "(70, 25)\n",
      "seq_array_test_k:  [[[0.39884394 0.8333333  0.         ... 0.         0.5905512  0.5549887 ]\n",
      "  [0.38728324 0.6666667  0.         ... 0.         0.62204725 0.41326532]\n",
      "  [0.51445085 0.6666667  0.         ... 0.         0.43307087 0.4321145 ]\n",
      "  ...\n",
      "  [0.6820809  0.5833333  0.         ... 0.         0.42519686 0.5576814 ]\n",
      "  [0.5549133  0.8333333  0.         ... 0.         0.56692916 0.43466553]\n",
      "  [0.5606936  0.6666667  0.         ... 0.         0.503937   0.585034  ]]]\n",
      "(80, 25)\n",
      "seq_array_test_k:  [[[0.38728324 0.41666666 0.         ... 0.         0.51968503 0.5236678 ]\n",
      "  [0.24855492 0.25       0.         ... 0.         0.62204725 0.58758503]\n",
      "  [0.47398844 0.08333334 0.         ... 0.         0.5511811  0.46272677]\n",
      "  ...\n",
      "  [0.39306358 0.6666667  0.         ... 0.         0.48818898 0.6308107 ]\n",
      "  [0.6300578  0.08333334 0.         ... 0.         0.6456693  0.6588719 ]\n",
      "  [0.48554912 0.16666667 0.         ... 0.         0.6535433  0.56816894]]]\n",
      "(90, 25)\n",
      "seq_array_test_k:  [[[0.49710983 0.5833333  0.         ... 0.         0.43307087 0.54350907]\n",
      "  [0.5953757  0.41666666 0.         ... 0.         0.503937   0.42375284]\n",
      "  [0.5317919  0.8333333  0.         ... 0.         0.63779527 0.4156746 ]\n",
      "  ...\n",
      "  [0.45086706 0.16666667 0.         ... 0.         0.511811   0.47293085]\n",
      "  [0.4682081  0.16666667 0.         ... 0.         0.4488189  0.4659864 ]\n",
      "  [0.37572256 0.5833333  0.         ... 0.         0.3464567  0.49858278]]]\n",
      "(100, 25)\n",
      "seq_array_test_k:  [[[0.43930635 0.16666667 0.         ... 0.         0.48818898 0.67134356]\n",
      "  [0.39306358 0.8333333  0.         ... 0.         0.52755904 0.493339  ]\n",
      "  [0.40462428 0.41666666 0.         ... 0.         0.48818898 0.3731576 ]\n",
      "  ...\n",
      "  [0.5433526  0.5        0.         ... 0.         0.53543305 0.5022676 ]\n",
      "  [0.30635837 0.25       0.         ... 0.         0.54330707 0.5941043 ]\n",
      "  [0.56647396 0.8333333  0.         ... 0.         0.51968503 0.5375567 ]]]\n",
      "(110, 25)\n",
      "seq_array_test_k:  [[[0.28323698 0.16666667 0.         ... 0.         0.4566929  0.5552721 ]\n",
      "  [0.47976878 0.6666667  0.         ... 0.         0.4488189  0.53174603]\n",
      "  [0.5549133  0.75       0.         ... 0.         0.41732284 0.5456349 ]\n",
      "  ...\n",
      "  [0.47976878 0.6666667  0.         ... 0.         0.4015748  0.6536281 ]\n",
      "  [0.53757226 0.16666667 0.         ... 0.         0.41732284 0.58786845]\n",
      "  [0.68786126 0.75       0.         ... 0.         0.48031497 0.46230158]]]\n",
      "(120, 25)\n",
      "seq_array_test_k:  [[[0.6069364  0.16666667 0.         ... 0.         0.51968503 0.54209185]\n",
      "  [0.61849713 0.5        0.         ... 0.         0.48818898 0.50736964]\n",
      "  [0.49710983 0.6666667  0.         ... 0.         0.46456692 0.52069163]\n",
      "  ...\n",
      "  [0.47976878 0.41666666 0.         ... 0.         0.47244096 0.5688776 ]\n",
      "  [0.6473988  0.75       0.         ... 0.         0.52755904 0.5443594 ]\n",
      "  [0.6416185  0.16666667 0.         ... 0.         0.53543305 0.4452948 ]]]\n",
      "(130, 25)\n",
      "seq_array_test_k:  [[[0.5780347  0.33333334 0.         ... 0.         0.4488189  0.58843535]\n",
      "  [0.41618496 0.33333334 0.         ... 0.         0.61417323 0.470805  ]\n",
      "  [0.5202312  0.8333333  0.         ... 0.         0.4566929  0.5422336 ]\n",
      "  ...\n",
      "  [0.5953757  0.08333334 0.         ... 0.         0.4488189  0.3901644 ]\n",
      "  [0.48554912 0.6666667  0.         ... 0.         0.2913386  0.41850907]\n",
      "  [0.433526   0.41666666 0.         ... 0.         0.46456692 0.31831065]]]\n",
      "(140, 25)\n",
      "seq_array_test_k:  [[[0.5086705  0.5        0.         ... 0.         0.5748032  0.54265875]\n",
      "  [0.47398844 0.5        0.         ... 0.         0.511811   0.36323696]\n",
      "  [0.61849713 0.41666666 0.         ... 0.         0.511811   0.55980724]\n",
      "  ...\n",
      "  [0.4566474  0.16666667 0.         ... 0.         0.42519686 0.5229592 ]\n",
      "  [0.5086705  0.6666667  0.         ... 0.         0.46456692 0.4443027 ]\n",
      "  [0.37572256 0.25       0.         ... 0.         0.42519686 0.42318594]]]\n",
      "(150, 25)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq_array_test_k:  [[[0.5895954  0.8333333  0.         ... 0.         0.68503934 0.48979592]\n",
      "  [0.33526012 0.33333334 0.         ... 0.         0.41732284 0.51615644]\n",
      "  [0.47398844 0.8333333  0.         ... 0.         0.4488189  0.4369331 ]\n",
      "  ...\n",
      "  [0.3236994  0.5833333  0.         ... 0.         0.31496063 0.46045917]\n",
      "  [0.47398844 0.08333334 0.         ... 0.         0.62204725 0.49291384]\n",
      "  [0.6242775  0.25       0.         ... 0.         0.56692916 0.48809522]]]\n",
      "(160, 25)\n",
      "seq_array_test_k:  [[[0.33526012 0.33333334 0.         ... 0.         0.33070865 0.4314059 ]\n",
      "  [0.41618496 0.75       0.         ... 0.         0.51968503 0.50708616]\n",
      "  [0.32947975 0.8333333  0.         ... 0.         0.38582677 0.57738096]\n",
      "  ...\n",
      "  [0.3815029  0.08333334 0.         ... 0.         0.4488189  0.42984694]\n",
      "  [0.5202312  0.75       0.         ... 0.         0.35433072 0.5355726 ]\n",
      "  [0.48554912 0.33333334 0.         ... 0.         0.51968503 0.43537414]]]\n",
      "(170, 25)\n",
      "seq_array_test_k:  [[[0.33526012 0.16666667 0.         ... 0.         0.54330707 0.46839568]\n",
      "  [0.38728324 0.41666666 0.         ... 0.         0.38582677 0.4155329 ]\n",
      "  [0.5202312  0.6666667  0.         ... 0.         0.27559054 0.5780896 ]\n",
      "  ...\n",
      "  [0.4913295  0.16666667 0.         ... 0.         0.46456692 0.4047619 ]\n",
      "  [0.6069364  0.16666667 0.         ... 0.         0.47244096 0.5352891 ]\n",
      "  [0.43930635 0.8333333  0.         ... 0.         0.46456692 0.5963719 ]]]\n",
      "(180, 25)\n",
      "seq_array_test_k:  [[[0.44508672 0.25       0.         ... 0.         0.5511811  0.52876985]\n",
      "  [0.47398844 0.5        0.         ... 0.         0.38582677 0.47604877]\n",
      "  [0.33526012 0.41666666 0.         ... 0.         0.4566929  0.5789399 ]\n",
      "  ...\n",
      "  [0.4682081  0.33333334 0.         ... 0.         0.6929134  0.31618482]\n",
      "  [0.57225436 0.16666667 0.         ... 0.         0.48818898 0.5449263 ]\n",
      "  [0.5317919  0.6666667  0.         ... 0.         0.38582677 0.2512755 ]]]\n",
      "(190, 25)\n",
      "seq_array_test_k:  [[[0.5433526  0.8333333  0.         ... 0.         0.4015748  0.46867913]\n",
      "  [0.50289017 0.25       0.         ... 0.         0.41732284 0.6153628 ]\n",
      "  [0.4682081  0.33333334 0.         ... 0.         0.4015748  0.51119614]\n",
      "  ...\n",
      "  [0.5202312  0.8333333  0.         ... 0.         0.3464567  0.46386054]\n",
      "  [0.3583815  0.41666666 0.         ... 0.         0.42519686 0.46286848]\n",
      "  [0.41618496 0.25       0.         ... 0.         0.41732284 0.44189343]]]\n",
      "(200, 25)\n",
      "seq_array_test_k:  [[[0.4566474  0.5        0.         ... 0.         0.47244096 0.42984694]\n",
      "  [0.75722545 0.16666667 0.         ... 0.         0.46456692 0.36493763]\n",
      "  [0.61849713 0.16666667 0.         ... 0.         0.41732284 0.54634356]\n",
      "  ...\n",
      "  [0.3236994  0.25       0.         ... 0.         0.47244096 0.3598356 ]\n",
      "  [0.53757226 0.16666667 0.         ... 0.         0.41732284 0.51346374]\n",
      "  [0.20809248 0.5        0.         ... 0.         0.47244096 0.30683106]]]\n",
      "(210, 25)\n",
      "seq_array_test_k:  [[[0.50289017 0.75       0.         ... 0.         0.44094488 0.4260204 ]\n",
      "  [0.43930635 0.5        0.         ... 0.         0.5511811  0.39356577]\n",
      "  [0.67052025 0.75       0.         ... 0.         0.4015748  0.40646258]\n",
      "  ...\n",
      "  [0.5606936  0.9166667  0.         ... 0.         0.38582677 0.32199547]\n",
      "  [0.42196533 0.33333334 0.         ... 0.         0.38582677 0.44047618]\n",
      "  [0.76878613 0.33333334 0.         ... 0.         0.46456692 0.45904195]]]\n",
      "(220, 25)\n",
      "seq_array_test_k:  [[[0.6473988  0.33333334 0.         ... 0.         0.48031497 0.38747165]\n",
      "  [0.8959538  0.5833333  0.         ... 0.         0.47244096 0.2760771 ]\n",
      "  [0.46242774 0.16666667 0.         ... 0.         0.40944883 0.50510204]\n",
      "  ...\n",
      "  [0.6820809  0.33333334 0.         ... 0.         0.44094488 0.5941043 ]\n",
      "  [0.5317919  0.16666667 0.         ... 0.         0.42519686 0.3955499 ]\n",
      "  [0.60115606 0.8333333  0.         ... 0.         0.40944883 0.37939343]]]\n",
      "(230, 25)\n",
      "seq_array_test_k:  [[[0.36416185 0.75       0.         ... 0.         0.31496063 0.3136338 ]\n",
      "  [0.42774567 0.33333334 0.         ... 0.         0.32283464 0.37996033]\n",
      "  [0.40462428 0.9166667  0.         ... 0.         0.4488189  0.4243197 ]\n",
      "  ...\n",
      "  [0.48554912 0.08333334 0.         ... 0.         0.39370078 0.2910998 ]\n",
      "  [0.4682081  0.08333334 0.         ... 0.         0.3464567  0.46584466]\n",
      "  [0.24855492 0.5833333  0.         ... 0.         0.40944883 0.30116212]]]\n",
      "(240, 25)\n",
      "seq_array_test_k:  [[[0.47398844 0.25       0.         ... 0.         0.51968503 0.39795917]\n",
      "  [0.39884394 0.6666667  0.         ... 0.         0.503937   0.6003401 ]\n",
      "  [0.42774567 0.41666666 0.         ... 0.         0.44094488 0.28684807]\n",
      "  ...\n",
      "  [0.37572256 0.33333334 0.         ... 0.         0.25984251 0.39597505]\n",
      "  [0.32947975 0.16666667 0.         ... 0.         0.3464567  0.30385488]\n",
      "  [0.5953757  0.08333334 0.         ... 0.         0.37795275 0.3938492 ]]]\n",
      "(250, 25)\n",
      "seq_array_test_k:  [[[0.46242774 0.16666667 0.         ... 0.         0.31496063 0.35161564]\n",
      "  [0.41618496 0.5        0.         ... 0.         0.23622048 0.26558957]\n",
      "  [0.56647396 0.5        0.         ... 0.         0.26771653 0.54209185]\n",
      "  ...\n",
      "  [0.57225436 0.33333334 0.         ... 0.         0.48031497 0.2568027 ]\n",
      "  [0.3815029  0.25       0.         ... 0.         0.24409449 0.29421768]\n",
      "  [0.5606936  0.5        0.         ... 0.         0.07874016 0.28004536]]]\n",
      "(260, 25)\n",
      "seq_array_test_k:  [[[0.68786126 0.9166667  0.         ... 0.         0.35433072 0.38917235]\n",
      "  [0.53757226 0.25       0.         ... 0.         0.3464567  0.39101472]\n",
      "  [0.34104046 0.16666667 0.         ... 0.         0.31496063 0.48015872]\n",
      "  ...\n",
      "  [0.68786126 0.25       0.         ... 0.         0.09448819 0.2020975 ]\n",
      "  [0.433526   0.33333334 0.         ... 0.         0.21259843 0.26729023]\n",
      "  [0.43930635 0.08333334 0.         ... 0.         0.22047244 0.12825964]]]\n",
      "(50, 25)\n",
      "seq_array_test_k:  [[[0.6473988  0.75       0.         ... 0.         0.62204725 0.6038832 ]\n",
      "  [0.39884394 0.6666667  0.         ... 0.         0.62992126 0.6414399 ]\n",
      "  [0.41618496 0.33333334 0.         ... 0.         0.53543305 0.5844671 ]\n",
      "  ...\n",
      "  [0.3583815  0.33333334 0.         ... 0.         0.70866144 0.7722506 ]\n",
      "  [0.5086705  0.5833333  0.         ... 0.         0.54330707 0.5847506 ]\n",
      "  [0.60115606 0.16666667 0.         ... 0.         0.63779527 0.67800456]]]\n",
      "(60, 25)\n",
      "seq_array_test_k:  [[[0.7630058  0.33333334 0.         ... 0.         0.61417323 0.6285431 ]\n",
      "  [0.42774567 0.8333333  0.         ... 0.         0.48031497 0.5405329 ]\n",
      "  [0.42196533 0.6666667  0.         ... 0.         0.5826772  0.6074263 ]\n",
      "  ...\n",
      "  [0.24855492 0.16666667 0.         ... 0.         0.56692916 0.62712586]\n",
      "  [0.61849713 0.75       0.         ... 0.         0.6929134  0.6496599 ]\n",
      "  [0.27745664 0.08333334 0.         ... 0.         0.5905512  0.5447846 ]]]\n",
      "(70, 25)\n",
      "seq_array_test_k:  [[[0.42774567 0.5        0.         ... 0.         0.6614173  0.46697846]\n",
      "  [0.49710983 0.5833333  0.         ... 0.         0.61417323 0.6163549 ]\n",
      "  [0.8265896  0.75       0.         ... 0.         0.5905512  0.4780329 ]\n",
      "  ...\n",
      "  [0.5202312  0.9166667  0.         ... 0.         0.6062992  0.52876985]\n",
      "  [0.5895954  0.75       0.         ... 0.         0.5905512  0.553288  ]\n",
      "  [0.5549133  0.75       0.         ... 0.         0.54330707 0.6461168 ]]]\n",
      "(80, 25)\n",
      "seq_array_test_k:  [[[0.63583815 0.5        0.         ... 0.         0.5748032  0.7124433 ]\n",
      "  [0.4913295  0.41666666 0.         ... 0.         0.62992126 0.7098923 ]\n",
      "  [0.49710983 0.8333333  0.         ... 0.         0.5748032  0.6856576 ]\n",
      "  ...\n",
      "  [0.36416185 0.75       0.         ... 0.         0.5590551  0.5928288 ]\n",
      "  [0.5953757  0.75       0.         ... 0.         0.4488189  0.63038546]\n",
      "  [0.6242775  0.5833333  0.         ... 0.         0.5748032  0.64399093]]]\n",
      "(90, 25)\n",
      "seq_array_test_k:  [[[0.33526012 0.25       0.         ... 0.         0.503937   0.457483  ]\n",
      "  [0.37572256 0.25       0.         ... 0.         0.4566929  0.66014737]\n",
      "  [0.43930635 0.25       0.         ... 0.         0.54330707 0.74291384]\n",
      "  ...\n",
      "  [0.5202312  0.6666667  0.         ... 0.         0.503937   0.551729  ]\n",
      "  [0.7630058  0.33333334 0.         ... 0.         0.54330707 0.5935374 ]\n",
      "  [0.31791908 0.33333334 0.         ... 0.         0.5511811  0.7019558 ]]]\n",
      "(100, 25)\n",
      "seq_array_test_k:  [[[0.48554912 0.41666666 0.         ... 0.         0.62204725 0.5136054 ]\n",
      "  [0.5202312  0.08333334 0.         ... 0.         0.48818898 0.5488946 ]\n",
      "  [0.65317917 0.33333334 0.         ... 0.         0.52755904 0.67134356]\n",
      "  ...\n",
      "  [0.39884394 0.75       0.         ... 0.         0.54330707 0.57426304]\n",
      "  [0.38728324 0.75       0.         ... 0.         0.4015748  0.66043085]\n",
      "  [0.433526   0.9166667  0.         ... 0.         0.503937   0.6466837 ]]]\n",
      "(110, 25)\n",
      "seq_array_test_k:  [[[0.45086706 0.41666666 0.         ... 0.         0.5511811  0.7213719 ]\n",
      "  [0.69942194 0.25       0.         ... 0.         0.6692913  0.5935374 ]\n",
      "  [0.41618496 0.33333334 0.         ... 0.         0.52755904 0.65561223]\n",
      "  ...\n",
      "  [0.49710983 0.8333333  0.         ... 0.         0.511811   0.7869898 ]\n",
      "  [0.5086705  0.33333334 0.         ... 0.         0.53543305 0.55257934]\n",
      "  [0.06936416 0.6666667  0.         ... 0.         0.5511811  0.5413832 ]]]\n",
      "(120, 25)\n",
      "seq_array_test_k:  [[[0.5895954  0.41666666 0.         ... 0.         0.5511811  0.5952381 ]\n",
      "  [0.56647396 0.16666667 0.         ... 0.         0.68503934 0.6510771 ]\n",
      "  [0.6300578  0.6666667  0.         ... 0.         0.54330707 0.5127551 ]\n",
      "  ...\n",
      "  [0.50289017 0.8333333  0.         ... 0.         0.51968503 0.4423186 ]\n",
      "  [0.69942194 0.25       0.         ... 0.         0.47244096 0.67687076]\n",
      "  [0.5433526  0.41666666 0.         ... 0.         0.48031497 0.5375567 ]]]\n",
      "(130, 25)\n",
      "seq_array_test_k:  [[[0.5780347  0.5833333  0.         ... 0.         0.5590551  0.59552157]\n",
      "  [0.42196533 0.5        0.         ... 0.         0.63779527 0.63492066]\n",
      "  [0.60115606 0.9166667  0.         ... 0.         0.4015748  0.7342687 ]\n",
      "  ...\n",
      "  [0.37572256 0.33333334 0.         ... 0.         0.48031497 0.5766723 ]\n",
      "  [0.63583815 0.16666667 0.         ... 0.         0.61417323 0.4998583 ]\n",
      "  [0.37572256 0.6666667  0.         ... 0.         0.48818898 0.4375    ]]]\n",
      "(140, 25)\n",
      "seq_array_test_k:  [[[0.42196533 0.16666667 0.         ... 0.         0.5590551  0.56094104]\n",
      "  [0.35260117 0.33333334 0.         ... 0.         0.62992126 0.559949  ]\n",
      "  [0.42774567 0.6666667  0.         ... 0.         0.4566929  0.5381236 ]\n",
      "  ...\n",
      "  [0.6069364  0.5        0.         ... 0.         0.53543305 0.45649093]\n",
      "  [0.49710983 0.8333333  0.         ... 0.         0.511811   0.44940478]\n",
      "  [0.6589595  0.8333333  0.         ... 0.         0.4488189  0.34495464]]]\n",
      "(150, 25)\n",
      "seq_array_test_k:  [[[0.51445085 0.33333334 0.         ... 0.         0.6614173  0.46910432]\n",
      "  [0.69942194 0.9166667  0.         ... 0.         0.6456693  0.41454083]\n",
      "  [0.30057803 0.08333334 0.         ... 0.         0.33858266 0.55017006]\n",
      "  ...\n",
      "  [0.45086706 0.8333333  0.         ... 0.         0.511811   0.26530612]\n",
      "  [0.4566474  0.75       0.         ... 0.         0.39370078 0.45649093]\n",
      "  [0.433526   0.5833333  0.         ... 0.         0.4566929  0.4430272 ]]]\n",
      "(160, 25)\n",
      "seq_array_test_k:  [[[0.37572256 0.41666666 0.         ... 0.         0.61417323 0.38392857]\n",
      "  [0.16763006 0.6666667  0.         ... 0.         0.496063   0.48412699]\n",
      "  [0.5260116  0.33333334 0.         ... 0.         0.48818898 0.50651926]\n",
      "  ...\n",
      "  [0.7109827  0.08333334 0.         ... 0.         0.37795275 0.3731576 ]\n",
      "  [0.61849713 0.9166667  0.         ... 0.         0.44094488 0.4428855 ]\n",
      "  [0.51445085 0.5833333  0.         ... 0.         0.2992126  0.36507937]]]\n",
      "(170, 25)\n",
      "seq_array_test_k:  [[[0.45086706 0.16666667 0.         ... 0.         0.54330707 0.37698412]\n",
      "  [0.49710983 0.75       0.         ... 0.         0.46456692 0.6927438 ]\n",
      "  [0.60115606 0.8333333  0.         ... 0.         0.54330707 0.6546202 ]\n",
      "  ...\n",
      "  [0.51445085 0.9166667  0.         ... 0.         0.37007874 0.23738661]\n",
      "  [0.42196533 0.33333334 0.         ... 0.         0.37795275 0.45578232]\n",
      "  [0.73410404 0.5833333  0.         ... 0.         0.33858266 0.40674603]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(180, 25)\n",
      "seq_array_test_k:  [[[0.54913294 0.25       0.         ... 0.         0.5511811  0.42318594]\n",
      "  [0.61271673 0.6666667  0.         ... 0.         0.52755904 0.53911567]\n",
      "  [0.5202312  0.16666667 0.         ... 0.         0.44094488 0.5048186 ]\n",
      "  ...\n",
      "  [0.34104046 0.9166667  0.         ... 0.         0.21259843 0.33673468]\n",
      "  [0.44508672 0.41666666 0.         ... 0.         0.28346458 0.22179705]\n",
      "  [0.73410404 0.25       0.         ... 0.         0.31496063 0.2936508 ]]]\n",
      "(50, 25)\n",
      "seq_array_test_k:  [[[0.5780347  0.5        0.         ... 0.         0.51968503 0.7121599 ]\n",
      "  [0.6936416  0.08333334 0.         ... 0.         0.63779527 0.5633503 ]\n",
      "  [0.47398844 0.5        0.         ... 0.         0.5748032  0.57426304]\n",
      "  ...\n",
      "  [0.5953757  0.6666667  0.         ... 0.         0.6692913  0.5680272 ]\n",
      "  [0.3583815  0.5833333  0.         ... 0.         0.496063   0.7005386 ]\n",
      "  [0.42196533 0.5833333  0.         ... 0.         0.5748032  0.7097506 ]]]\n",
      "(60, 25)\n",
      "seq_array_test_k:  [[[0.5549133  0.8333333  0.         ... 0.         0.5511811  0.54903626]\n",
      "  [0.39306358 0.8333333  0.         ... 0.         0.5748032  0.8289399 ]\n",
      "  [0.7803468  0.16666667 0.         ... 0.         0.6771653  0.63492066]\n",
      "  ...\n",
      "  [0.20231214 0.6666667  0.         ... 0.         0.6692913  0.54790246]\n",
      "  [0.30635837 0.8333333  0.         ... 0.         0.62204725 0.65759635]\n",
      "  [0.2947977  0.5833333  0.         ... 0.         0.6456693  0.5861678 ]]]\n",
      "(70, 25)\n",
      "seq_array_test_k:  [[[0.3583815  0.5833333  0.         ... 0.         0.5826772  0.75396824]\n",
      "  [0.44508672 0.5        0.         ... 0.         0.496063   0.6125283 ]\n",
      "  [0.43930635 0.5        0.         ... 0.         0.62204725 0.6566043 ]\n",
      "  ...\n",
      "  [0.45086706 0.33333334 0.         ... 0.         0.6456693  0.5793651 ]\n",
      "  [0.5895954  0.33333334 0.         ... 0.         0.4566929  0.56377554]\n",
      "  [0.35260117 0.33333334 0.         ... 0.         0.6614173  0.5327381 ]]]\n",
      "(80, 25)\n",
      "seq_array_test_k:  [[[0.5606936  0.9166667  0.         ... 0.         0.53543305 0.59552157]\n",
      "  [0.46242774 0.16666667 0.         ... 0.         0.62204725 0.55130386]\n",
      "  [0.5260116  0.8333333  0.         ... 0.         0.5511811  0.5642007 ]\n",
      "  ...\n",
      "  [0.4566474  0.5833333  0.         ... 0.         0.52755904 0.59126985]\n",
      "  [0.3699422  0.33333334 0.         ... 0.         0.47244096 0.6761621 ]\n",
      "  [0.42196533 0.8333333  0.         ... 0.         0.63779527 0.4861111 ]]]\n",
      "(90, 25)\n",
      "seq_array_test_k:  [[[0.54913294 0.33333334 0.         ... 0.         0.52755904 0.60374147]\n",
      "  [0.3468208  0.25       0.         ... 0.         0.503937   0.6213152 ]\n",
      "  [0.42196533 0.33333334 0.         ... 0.         0.2992126  0.45252267]\n",
      "  ...\n",
      "  [0.45086706 0.5833333  0.         ... 0.         0.48818898 0.62457484]\n",
      "  [0.44508672 0.9166667  0.         ... 0.         0.61417323 0.638322  ]\n",
      "  [0.4913295  0.41666666 0.         ... 0.         0.503937   0.55017006]]]\n",
      "(100, 25)\n",
      "seq_array_test_k:  [[[0.36416185 0.5833333  0.         ... 0.         0.54330707 0.5419501 ]\n",
      "  [0.5895954  0.8333333  0.         ... 0.         0.62992126 0.5816327 ]\n",
      "  [0.5433526  0.6666667  0.         ... 0.         0.47244096 0.5871599 ]\n",
      "  ...\n",
      "  [0.47976878 0.8333333  0.         ... 0.         0.7007874  0.55541384]\n",
      "  [0.42196533 0.6666667  0.         ... 0.         0.511811   0.48341838]\n",
      "  [0.433526   0.5        0.         ... 0.         0.62204725 0.7236394 ]]]\n",
      "(110, 25)\n",
      "seq_array_test_k:  [[[0.5780347  0.6666667  0.         ... 0.         0.40944883 0.5219671 ]\n",
      "  [0.5780347  0.6666667  0.         ... 0.         0.5905512  0.6651077 ]\n",
      "  [0.4682081  0.16666667 0.         ... 0.         0.5748032  0.5338719 ]\n",
      "  ...\n",
      "  [0.6242775  0.8333333  0.         ... 0.         0.511811   0.65036845]\n",
      "  [0.60115606 0.33333334 0.         ... 0.         0.5590551  0.50992066]\n",
      "  [0.73410404 0.6666667  0.         ... 0.         0.56692916 0.65575397]]]\n",
      "(120, 25)\n",
      "seq_array_test_k:  [[[0.6069364  0.5        0.         ... 0.         0.4488189  0.6230159 ]\n",
      "  [0.45086706 0.6666667  0.         ... 0.         0.54330707 0.5766723 ]\n",
      "  [0.61849713 0.16666667 0.         ... 0.         0.6062992  0.6135204 ]\n",
      "  ...\n",
      "  [0.39306358 0.41666666 0.         ... 0.         0.48818898 0.60827667]\n",
      "  [0.51445085 0.33333334 0.         ... 0.         0.5748032  0.5593821 ]\n",
      "  [0.47976878 0.5833333  0.         ... 0.         0.46456692 0.50155896]]]\n",
      "(130, 25)\n",
      "seq_array_test_k:  [[[0.4682081  0.33333334 0.         ... 0.         0.6062992  0.66794217]\n",
      "  [0.6589595  0.8333333  0.         ... 0.         0.48031497 0.66652495]\n",
      "  [0.5433526  0.41666666 0.         ... 0.         0.6456693  0.59509635]\n",
      "  ...\n",
      "  [0.58381504 0.6666667  0.         ... 0.         0.5826772  0.5894274 ]\n",
      "  [0.5433526  0.9166667  0.         ... 0.         0.53543305 0.6180556 ]\n",
      "  [0.7514451  0.08333334 0.         ... 0.         0.51968503 0.60770977]]]\n",
      "(140, 25)\n",
      "seq_array_test_k:  [[[0.45086706 0.08333334 0.         ... 0.         0.503937   0.44005102]\n",
      "  [0.37572256 0.6666667  0.         ... 0.         0.51968503 0.6058673 ]\n",
      "  [0.46242774 0.33333334 0.         ... 0.         0.62992126 0.6971372 ]\n",
      "  ...\n",
      "  [0.42196533 0.75       0.         ... 0.         0.4015748  0.4593254 ]\n",
      "  [0.37572256 0.8333333  0.         ... 0.         0.61417323 0.56150794]\n",
      "  [0.65317917 0.16666667 0.         ... 0.         0.62992126 0.66425735]]]\n",
      "(150, 25)\n",
      "seq_array_test_k:  [[[0.30057803 0.5        0.         ... 0.         0.5511811  0.5528628 ]\n",
      "  [0.433526   0.16666667 0.         ... 0.         0.496063   0.6689342 ]\n",
      "  [0.34104046 0.9166667  0.         ... 0.         0.56692916 0.66539115]\n",
      "  ...\n",
      "  [0.57225436 0.16666667 0.         ... 0.         0.40944883 0.5622166 ]\n",
      "  [0.4913295  0.41666666 0.         ... 0.         0.3464567  0.649093  ]\n",
      "  [0.433526   0.41666666 0.         ... 0.         0.61417323 0.53656465]]]\n",
      "(160, 25)\n",
      "seq_array_test_k:  [[[0.1618497  0.5833333  0.         ... 0.         0.41732284 0.5899943 ]\n",
      "  [0.4682081  0.41666666 0.         ... 0.         0.38582677 0.5393991 ]\n",
      "  [0.6936416  0.33333334 0.         ... 0.         0.47244096 0.7375283 ]\n",
      "  ...\n",
      "  [0.5953757  0.16666667 0.         ... 0.         0.56692916 0.6412982 ]\n",
      "  [0.4682081  0.5833333  0.         ... 0.         0.47244096 0.5436508 ]\n",
      "  [0.5606936  0.16666667 0.         ... 0.         0.52755904 0.5807823 ]]]\n",
      "(170, 25)\n",
      "seq_array_test_k:  [[[0.433526   0.41666666 0.         ... 0.         0.37007874 0.4460034 ]\n",
      "  [0.24277456 0.75       0.         ... 0.         0.61417323 0.6053004 ]\n",
      "  [0.5953757  0.5        0.         ... 0.         0.5511811  0.6013322 ]\n",
      "  ...\n",
      "  [0.49710983 0.16666667 0.         ... 0.         0.503937   0.4873866 ]\n",
      "  [0.30057803 0.25       0.         ... 0.         0.44094488 0.4868197 ]\n",
      "  [0.5086705  0.25       0.         ... 0.         0.6614173  0.48129252]]]\n",
      "(180, 25)\n",
      "seq_array_test_k:  [[[0.43930635 0.6666667  0.         ... 0.         0.7322835  0.69090134]\n",
      "  [0.57225436 0.33333334 0.         ... 0.         0.6614173  0.58290815]\n",
      "  [0.7919075  0.16666667 0.         ... 0.         0.496063   0.55654764]\n",
      "  ...\n",
      "  [0.43930635 0.25       0.         ... 0.         0.48031497 0.4994331 ]\n",
      "  [0.56647396 0.6666667  0.         ... 0.         0.511811   0.41964287]\n",
      "  [0.5202312  0.5833333  0.         ... 0.         0.5590551  0.5072279 ]]]\n",
      "(190, 25)\n",
      "seq_array_test_k:  [[[0.1734104  0.8333333  0.         ... 0.         0.61417323 0.4369331 ]\n",
      "  [0.5202312  0.5        0.         ... 0.         0.51968503 0.50070864]\n",
      "  [0.44508672 0.5833333  0.         ... 0.         0.37007874 0.4297052 ]\n",
      "  ...\n",
      "  [0.4682081  0.8333333  0.         ... 0.         0.41732284 0.5314626 ]\n",
      "  [0.32947975 0.8333333  0.         ... 0.         0.33070865 0.43253967]\n",
      "  [0.50289017 0.5        0.         ... 0.         0.4488189  0.38931406]]]\n",
      "(200, 25)\n",
      "seq_array_test_k:  [[[0.3583815  0.8333333  0.         ... 0.         0.503937   0.59934807]\n",
      "  [0.3815029  0.8333333  0.         ... 0.         0.4566929  0.54322565]\n",
      "  [0.39884394 0.5833333  0.         ... 0.         0.5590551  0.56235826]\n",
      "  ...\n",
      "  [0.24277456 0.6666667  0.         ... 0.         0.496063   0.50127554]\n",
      "  [0.44508672 0.8333333  0.         ... 0.         0.4566929  0.49376416]\n",
      "  [0.5086705  0.25       0.         ... 0.         0.503937   0.30895692]]]\n",
      "(210, 25)\n",
      "seq_array_test_k:  [[[0.4913295  0.16666667 0.         ... 0.         0.6771653  0.7285998 ]\n",
      "  [0.47976878 0.5        0.         ... 0.         0.503937   0.70649093]\n",
      "  [0.2947977  0.8333333  0.         ... 0.         0.53543305 0.5921202 ]\n",
      "  ...\n",
      "  [0.47976878 0.5833333  0.         ... 0.         0.47244096 0.37698412]\n",
      "  [0.2601156  0.5833333  0.         ... 0.         0.39370078 0.5014172 ]\n",
      "  [0.433526   0.33333334 0.         ... 0.         0.47244096 0.42191043]]]\n",
      "(220, 25)\n",
      "seq_array_test_k:  [[[0.41040462 0.6666667  0.         ... 0.         0.6771653  0.46697846]\n",
      "  [0.3699422  0.33333334 0.         ... 0.         0.37795275 0.30201247]\n",
      "  [0.3699422  0.5        0.         ... 0.         0.5590551  0.58404195]\n",
      "  ...\n",
      "  [0.5606936  0.33333334 0.         ... 0.         0.4015748  0.38917235]\n",
      "  [0.47398844 0.41666666 0.         ... 0.         0.53543305 0.44586167]\n",
      "  [0.6300578  0.41666666 0.         ... 0.         0.33070865 0.6238662 ]]]\n",
      "(230, 25)\n",
      "seq_array_test_k:  [[[0.6820809  0.25       0.         ... 0.         0.6692913  0.417517  ]\n",
      "  [0.32947975 0.41666666 0.         ... 0.         0.71653545 0.27565193]\n",
      "  [0.39884394 0.6666667  0.         ... 0.         0.41732284 0.5739796 ]\n",
      "  ...\n",
      "  [0.72254336 0.41666666 0.         ... 0.         0.30708662 0.4319728 ]\n",
      "  [0.45086706 0.75       0.         ... 0.         0.28346458 0.38506237]\n",
      "  [0.3815029  0.6666667  0.         ... 0.         0.42519686 0.3295068 ]]]\n",
      "(240, 25)\n",
      "seq_array_test_k:  [[[0.21965317 0.75       0.         ... 0.         0.44094488 0.4088719 ]\n",
      "  [0.37572256 0.5833333  0.         ... 0.         0.35433072 0.47477323]\n",
      "  [0.31213874 0.5        0.         ... 0.         0.31496063 0.4829932 ]\n",
      "  ...\n",
      "  [0.47976878 0.5        0.         ... 0.         0.46456692 0.22392291]\n",
      "  [0.24855492 0.5833333  0.         ... 0.         0.40944883 0.3805272 ]\n",
      "  [0.5202312  0.8333333  0.         ... 0.         0.44094488 0.29832765]]]\n",
      "(250, 25)\n",
      "seq_array_test_k:  [[[0.5086705  0.8333333  0.         ... 0.         0.51968503 0.5734127 ]\n",
      "  [0.48554912 0.8333333  0.         ... 0.         0.36220473 0.539966  ]\n",
      "  [0.5780347  0.5833333  0.         ... 0.         0.496063   0.5933957 ]\n",
      "  ...\n",
      "  [0.68786126 0.5        0.         ... 0.         0.22047244 0.45521542]\n",
      "  [0.3583815  0.75       0.         ... 0.         0.3464567  0.2002551 ]\n",
      "  [0.30057803 0.9166667  0.         ... 0.         0.36220473 0.28897393]]]\n",
      "(260, 25)\n",
      "seq_array_test_k:  [[[0.39306358 0.33333334 0.         ... 0.         0.2913386  0.37003967]\n",
      "  [0.7976879  0.9166667  0.         ... 0.         0.43307087 0.39342403]\n",
      "  [0.5086705  0.5        0.         ... 0.         0.4566929  0.3840703 ]\n",
      "  ...\n",
      "  [0.3468208  0.25       0.         ... 0.         0.36220473 0.27820295]\n",
      "  [0.56647396 0.75       0.         ... 0.         0.40944883 0.29620183]\n",
      "  [0.67052025 0.25       0.         ... 0.         0.25984251 0.40334466]]]\n",
      "(270, 25)\n",
      "seq_array_test_k:  [[[0.49710983 0.9166667  0.         ... 0.         0.46456692 0.29747733]\n",
      "  [0.6647399  0.75       0.         ... 0.         0.20472442 0.48866212]\n",
      "  [0.40462428 0.25       0.         ... 0.         0.2519685  0.4097222 ]\n",
      "  ...\n",
      "  [0.24277456 0.33333334 0.         ... 0.         0.26771653 0.38548753]\n",
      "  [0.41618496 0.33333334 0.         ... 0.         0.22047244 0.2293084 ]\n",
      "  [0.43930635 0.5833333  0.         ... 0.         0.22834645 0.3392857 ]]]\n",
      "(50, 25)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq_array_test_k:  [[[0.4566474  0.16666667 0.         ... 0.         0.5590551  0.58956915]\n",
      "  [0.47398844 0.08333334 0.         ... 0.         0.61417323 0.63846374]\n",
      "  [0.7398844  0.9166667  0.         ... 0.         0.62992126 0.49248865]\n",
      "  ...\n",
      "  [0.3815029  0.41666666 0.         ... 0.         0.37795275 0.53202945]\n",
      "  [0.68786126 0.5        0.         ... 0.         0.496063   0.43395692]\n",
      "  [0.28901735 0.16666667 0.         ... 0.         0.5905512  0.5841837 ]]]\n",
      "(60, 25)\n",
      "seq_array_test_k:  [[[0.5953757  0.25       0.         ... 0.         0.7007874  0.59906465]\n",
      "  [0.49710983 0.16666667 0.         ... 0.         0.5905512  0.60119045]\n",
      "  [0.46242774 0.41666666 0.         ... 0.         0.53543305 0.72845805]\n",
      "  ...\n",
      "  [0.85549134 0.5833333  0.         ... 0.         0.5590551  0.5185658 ]\n",
      "  [0.41040462 0.9166667  0.         ... 0.         0.39370078 0.57426304]\n",
      "  [0.3236994  0.5        0.         ... 0.         0.54330707 0.5705782 ]]]\n",
      "(70, 25)\n",
      "seq_array_test_k:  [[[0.53757226 0.6666667  0.         ... 0.         0.5590551  0.38477892]\n",
      "  [0.5202312  0.5833333  0.         ... 0.         0.56692916 0.586593  ]\n",
      "  [0.35260117 0.5        0.         ... 0.         0.46456692 0.70096374]\n",
      "  ...\n",
      "  [0.61849713 0.5833333  0.         ... 0.         0.36220473 0.52210885]\n",
      "  [0.39306358 0.33333334 0.         ... 0.         0.62992126 0.6194728 ]\n",
      "  [0.433526   0.25       0.         ... 0.         0.44094488 0.53514737]]]\n",
      "(80, 25)\n",
      "seq_array_test_k:  [[[0.40462428 0.5833333  0.         ... 0.         0.4566929  0.5766723 ]\n",
      "  [0.47398844 0.16666667 0.         ... 0.         0.63779527 0.64625853]\n",
      "  [0.40462428 0.33333334 0.         ... 0.         0.6535433  0.6044501 ]\n",
      "  ...\n",
      "  [0.36416185 0.25       0.         ... 0.         0.43307087 0.57256234]\n",
      "  [0.6416185  0.5        0.         ... 0.         0.63779527 0.55909866]\n",
      "  [0.3583815  0.41666666 0.         ... 0.         0.6535433  0.6347789 ]]]\n",
      "(90, 25)\n",
      "seq_array_test_k:  [[[0.6763006  0.16666667 0.         ... 0.         0.54330707 0.5661848 ]\n",
      "  [0.72254336 0.16666667 0.         ... 0.         0.5984252  0.5236678 ]\n",
      "  [0.49710983 0.25       0.         ... 0.         0.5511811  0.54265875]\n",
      "  ...\n",
      "  [0.3583815  0.6666667  0.         ... 0.         0.44094488 0.53202945]\n",
      "  [0.3236994  0.25       0.         ... 0.         0.46456692 0.61933106]\n",
      "  [0.47398844 0.5833333  0.         ... 0.         0.44094488 0.69161   ]]]\n",
      "(100, 25)\n",
      "seq_array_test_k:  [[[0.38728324 0.6666667  0.         ... 0.         0.7322835  0.5283447 ]\n",
      "  [0.5202312  0.41666666 0.         ... 0.         0.62204725 0.5185658 ]\n",
      "  [0.60115606 0.6666667  0.         ... 0.         0.6062992  0.69075966]\n",
      "  ...\n",
      "  [0.2601156  0.25       0.         ... 0.         0.5511811  0.6643991 ]\n",
      "  [0.54913294 0.5        0.         ... 0.         0.5748032  0.55739796]\n",
      "  [0.6473988  0.8333333  0.         ... 0.         0.5511811  0.5367063 ]]]\n",
      "(110, 25)\n",
      "seq_array_test_k:  [[[0.43930635 0.25       0.         ... 0.         0.5905512  0.6594388 ]\n",
      "  [0.33526012 0.16666667 0.         ... 0.         0.5984252  0.48143423]\n",
      "  [0.44508672 0.8333333  0.         ... 0.         0.54330707 0.40873015]\n",
      "  ...\n",
      "  [0.57225436 0.75       0.         ... 0.         0.5748032  0.46173468]\n",
      "  [0.5606936  0.41666666 0.         ... 0.         0.39370078 0.4027778 ]\n",
      "  [0.6473988  0.08333334 0.         ... 0.         0.30708662 0.60175735]]]\n",
      "(120, 25)\n",
      "seq_array_test_k:  [[[0.20231214 0.8333333  0.         ... 0.         0.46456692 0.53373015]\n",
      "  [0.51445085 0.16666667 0.         ... 0.         0.63779527 0.60572565]\n",
      "  [0.6069364  0.9166667  0.         ... 0.         0.6692913  0.55513036]\n",
      "  ...\n",
      "  [0.4566474  0.33333334 0.         ... 0.         0.48031497 0.54634356]\n",
      "  [0.4682081  0.5833333  0.         ... 0.         0.54330707 0.4460034 ]\n",
      "  [0.6069364  0.25       0.         ... 0.         0.511811   0.5630669 ]]]\n",
      "(130, 25)\n",
      "seq_array_test_k:  [[[0.21965317 0.5        0.         ... 0.         0.5748032  0.63704646]\n",
      "  [0.39306358 0.9166667  0.         ... 0.         0.5826772  0.68296486]\n",
      "  [0.3815029  0.75       0.         ... 0.         0.496063   0.6628401 ]\n",
      "  ...\n",
      "  [0.4913295  0.6666667  0.         ... 0.         0.40944883 0.3914399 ]\n",
      "  [0.68786126 0.41666666 0.         ... 0.         0.496063   0.44997165]\n",
      "  [0.7109827  0.5833333  0.         ... 0.         0.32283464 0.45578232]]]\n",
      "(140, 25)\n",
      "seq_array_test_k:  [[[0.33526012 0.8333333  0.         ... 0.         0.503937   0.62103176]\n",
      "  [0.49710983 0.25       0.         ... 0.         0.37795275 0.47066328]\n",
      "  [0.5433526  0.25       0.         ... 0.         0.503937   0.4036281 ]\n",
      "  ...\n",
      "  [0.38728324 0.5        0.         ... 0.         0.503937   0.41893423]\n",
      "  [0.433526   0.9166667  0.         ... 0.         0.37795275 0.5888606 ]\n",
      "  [0.5433526  0.5833333  0.         ... 0.         0.48818898 0.51048756]]]\n",
      "(150, 25)\n",
      "seq_array_test_k:  [[[0.7398844  0.33333334 0.         ... 0.         0.46456692 0.35600907]\n",
      "  [0.27745664 0.33333334 0.         ... 0.         0.54330707 0.51459754]\n",
      "  [0.41040462 0.8333333  0.         ... 0.         0.61417323 0.42630386]\n",
      "  ...\n",
      "  [0.5780347  0.25       0.         ... 0.         0.31496063 0.48823696]\n",
      "  [0.45086706 0.9166667  0.         ... 0.         0.17322835 0.49971655]\n",
      "  [0.54913294 0.6666667  0.         ... 0.         0.42519686 0.3239796 ]]]\n",
      "(160, 25)\n",
      "seq_array_test_k:  [[[0.4566474  0.8333333  0.         ... 0.         0.4566929  0.5544218 ]\n",
      "  [0.54913294 0.33333334 0.         ... 0.         0.54330707 0.38973922]\n",
      "  [0.58381504 0.16666667 0.         ... 0.         0.36220473 0.49489796]\n",
      "  ...\n",
      "  [0.28901735 0.5833333  0.         ... 0.         0.27559054 0.38307822]\n",
      "  [0.49710983 0.25       0.         ... 0.         0.28346458 0.36366212]\n",
      "  [0.5549133  0.9166667  0.         ... 0.         0.27559054 0.29506803]]]\n",
      "(170, 25)\n",
      "seq_array_test_k:  [[[0.63583815 0.6666667  0.         ... 0.         0.41732284 0.42162699]\n",
      "  [0.46242774 0.41666666 0.         ... 0.         0.4015748  0.5521542 ]\n",
      "  [0.2716763  0.6666667  0.         ... 0.         0.2913386  0.58149093]\n",
      "  ...\n",
      "  [0.39884394 0.75       0.         ... 0.         0.2992126  0.23568594]\n",
      "  [0.3468208  0.6666667  0.         ... 0.         0.24409449 0.4005102 ]\n",
      "  [0.5606936  0.5        0.         ... 0.         0.27559054 0.24192177]]]\n",
      "(50, 25)\n",
      "seq_array_test_k:  [[[0.30057803 0.75       0.         ... 0.         0.7559055  0.62712586]\n",
      "  [0.5549133  0.16666667 0.         ... 0.         0.7559055  0.8015873 ]\n",
      "  [0.32947975 0.5833333  0.         ... 0.         0.5748032  0.61011904]\n",
      "  ...\n",
      "  [0.4682081  0.5833333  0.         ... 0.         0.6929134  0.63704646]\n",
      "  [0.39884394 0.5        0.         ... 0.         0.7007874  0.5607993 ]\n",
      "  [0.50289017 0.6666667  0.         ... 0.         0.6614173  0.5103458 ]]]\n",
      "(60, 25)\n",
      "seq_array_test_k:  [[[0.3699422  0.5833333  0.         ... 0.         0.5826772  0.7511338 ]\n",
      "  [0.5260116  0.25       0.         ... 0.         0.6062992  0.71513605]\n",
      "  [0.56647396 0.33333334 0.         ... 0.         0.63779527 0.76842403]\n",
      "  ...\n",
      "  [0.73410404 0.5833333  0.         ... 0.         0.61417323 0.6438492 ]\n",
      "  [0.5895954  0.16666667 0.         ... 0.         0.56692916 0.72930837]\n",
      "  [0.8150289  0.33333334 0.         ... 0.         0.6929134  0.59509635]]]\n",
      "(70, 25)\n",
      "seq_array_test_k:  [[[0.30057803 0.41666666 0.         ... 0.         0.6062992  0.58871883]\n",
      "  [0.51445085 0.75       0.         ... 0.         0.6771653  0.81179136]\n",
      "  [0.49710983 0.5833333  0.         ... 0.         0.71653545 0.7171202 ]\n",
      "  ...\n",
      "  [0.6069364  0.33333334 0.         ... 0.         0.5905512  0.6736111 ]\n",
      "  [0.21965317 0.5        0.         ... 0.         0.62204725 0.6333617 ]\n",
      "  [0.4682081  0.75       0.         ... 0.         0.6692913  0.59070295]]]\n",
      "(80, 25)\n",
      "seq_array_test_k:  [[[0.7919075  0.5        0.         ... 0.         0.6692913  0.6498016 ]\n",
      "  [0.37572256 0.08333334 0.         ... 0.         0.5748032  0.6551871 ]\n",
      "  [0.433526   0.41666666 0.         ... 0.         0.6929134  0.6213152 ]\n",
      "  ...\n",
      "  [0.41618496 0.16666667 0.         ... 0.         0.70866144 0.67403626]\n",
      "  [0.54913294 0.25       0.         ... 0.         0.5905512  0.63506234]\n",
      "  [0.46242774 0.5833333  0.         ... 0.         0.6535433  0.6991213 ]]]\n",
      "(90, 25)\n",
      "seq_array_test_k:  [[[0.56647396 0.5        0.         ... 0.         0.6456693  0.71626985]\n",
      "  [0.7109827  0.33333334 0.         ... 0.         0.40944883 0.81632656]\n",
      "  [0.16763006 0.5        0.         ... 0.         0.71653545 0.57865644]\n",
      "  ...\n",
      "  [0.67052025 0.33333334 0.         ... 0.         0.72440946 0.4648526 ]\n",
      "  [0.7803468  0.33333334 0.         ... 0.         0.52755904 0.64824265]\n",
      "  [0.41040462 0.9166667  0.         ... 0.         0.5826772  0.70620745]]]\n",
      "(100, 25)\n",
      "seq_array_test_k:  [[[0.61849713 0.33333334 0.         ... 0.         0.6692913  0.59764737]\n",
      "  [0.46242774 0.6666667  0.         ... 0.         0.5748032  0.5715703 ]\n",
      "  [0.38728324 0.6666667  0.         ... 0.         0.5826772  0.6602891 ]\n",
      "  ...\n",
      "  [0.4913295  0.16666667 0.         ... 0.         0.54330707 0.640873  ]\n",
      "  [0.60115606 0.16666667 0.         ... 0.         0.6692913  0.77040815]\n",
      "  [0.5086705  0.25       0.         ... 0.         0.4488189  0.56094104]]]\n",
      "(110, 25)\n",
      "seq_array_test_k:  [[[0.4682081  0.5        0.         ... 0.         0.503937   0.86096936]\n",
      "  [0.37572256 0.33333334 0.         ... 0.         0.7007874  0.6591553 ]\n",
      "  [0.5086705  0.33333334 0.         ... 0.         0.6456693  0.6996882 ]\n",
      "  ...\n",
      "  [0.47976878 0.33333334 0.         ... 0.         0.70866144 0.49418935]\n",
      "  [0.44508672 0.41666666 0.         ... 0.         0.56692916 0.59367913]\n",
      "  [0.5606936  0.5833333  0.         ... 0.         0.496063   0.4587585 ]]]\n",
      "(120, 25)\n",
      "seq_array_test_k:  [[[0.41618496 0.75       0.         ... 0.         0.51968503 0.62174034]\n",
      "  [0.40462428 0.6666667  0.         ... 0.         0.6692913  0.52706915]\n",
      "  [0.41618496 0.8333333  0.         ... 0.         0.53543305 0.5388322 ]\n",
      "  ...\n",
      "  [0.47976878 0.8333333  0.         ... 0.         0.6614173  0.68409866]\n",
      "  [0.3583815  0.33333334 0.         ... 0.         0.53543305 0.47236395]\n",
      "  [0.3815029  0.33333334 0.         ... 0.         0.5511811  0.60119045]]]\n",
      "(130, 25)\n",
      "seq_array_test_k:  [[[0.54913294 0.25       0.         ... 0.         0.53543305 0.55739796]\n",
      "  [0.39884394 0.25       0.         ... 0.         0.503937   0.74404764]\n",
      "  [0.44508672 0.41666666 0.         ... 0.         0.56692916 0.6558957 ]\n",
      "  ...\n",
      "  [0.48554912 0.5833333  0.         ... 0.         0.5511811  0.5547052 ]\n",
      "  [0.5317919  0.41666666 0.         ... 0.         0.6456693  0.5722789 ]\n",
      "  [0.61849713 0.5        0.         ... 0.         0.496063   0.51048756]]]\n",
      "(140, 25)\n",
      "seq_array_test_k:  [[[0.42774567 0.41666666 0.         ... 0.         0.6771653  0.70592403]\n",
      "  [0.5895954  0.16666667 0.         ... 0.         0.5905512  0.6991213 ]\n",
      "  [0.68786126 0.6666667  0.         ... 0.         0.6771653  0.79960316]\n",
      "  ...\n",
      "  [0.40462428 0.25       0.         ... 0.         0.39370078 0.48412699]\n",
      "  [0.433526   0.5833333  0.         ... 0.         0.5984252  0.5376984 ]\n",
      "  [0.6473988  0.16666667 0.         ... 0.         0.5590551  0.5196996 ]]]\n",
      "(150, 25)\n",
      "seq_array_test_k:  [[[0.54913294 0.5        0.         ... 0.         0.503937   0.4005102 ]\n",
      "  [0.38728324 0.33333334 0.         ... 0.         0.46456692 0.63676304]\n",
      "  [0.83815026 0.5833333  0.         ... 0.         0.43307087 0.67743766]\n",
      "  ...\n",
      "  [0.31213874 0.6666667  0.         ... 0.         0.5511811  0.5755386 ]\n",
      "  [0.41618496 0.9166667  0.         ... 0.         0.511811   0.48809522]\n",
      "  [0.4682081  0.6666667  0.         ... 0.         0.37007874 0.5223923 ]]]\n",
      "(160, 25)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq_array_test_k:  [[[0.6416185  0.8333333  0.         ... 0.         0.62204725 0.6214569 ]\n",
      "  [0.7514451  0.9166667  0.         ... 0.         0.46456692 0.53429705]\n",
      "  [0.63583815 0.5        0.         ... 0.         0.48031497 0.69812924]\n",
      "  ...\n",
      "  [0.2716763  0.16666667 0.         ... 0.         0.40944883 0.48469388]\n",
      "  [0.4682081  0.8333333  0.         ... 0.         0.63779527 0.5456349 ]\n",
      "  [0.39306358 0.5833333  0.         ... 0.         0.4488189  0.5654762 ]]]\n",
      "(170, 25)\n",
      "seq_array_test_k:  [[[0.41040462 0.41666666 0.         ... 0.         0.53543305 0.5744048 ]\n",
      "  [0.5260116  0.41666666 0.         ... 0.         0.43307087 0.54790246]\n",
      "  [0.5606936  0.5833333  0.         ... 0.         0.44094488 0.55243766]\n",
      "  ...\n",
      "  [0.65317917 0.41666666 0.         ... 0.         0.38582677 0.48880386]\n",
      "  [0.49710983 0.5833333  0.         ... 0.         0.54330707 0.3526077 ]\n",
      "  [0.42774567 0.25       0.         ... 0.         0.5511811  0.37188208]]]\n",
      "(180, 25)\n",
      "seq_array_test_k:  [[[0.6416185  0.16666667 0.         ... 0.         0.5826772  0.5965136 ]\n",
      "  [0.60115606 0.16666667 0.         ... 0.         0.54330707 0.6614229 ]\n",
      "  [0.6069364  0.5        0.         ... 0.         0.4488189  0.5075113 ]\n",
      "  ...\n",
      "  [0.40462428 0.41666666 0.         ... 0.         0.33858266 0.40731293]\n",
      "  [0.42196533 0.5833333  0.         ... 0.         0.37795275 0.39271542]\n",
      "  [0.39884394 0.08333334 0.         ... 0.         0.44094488 0.3476474 ]]]\n",
      "(190, 25)\n",
      "seq_array_test_k:  [[[0.33526012 0.8333333  0.         ... 0.         0.47244096 0.39526644]\n",
      "  [0.5317919  0.5833333  0.         ... 0.         0.54330707 0.51374716]\n",
      "  [0.67052025 0.5        0.         ... 0.         0.6771653  0.559949  ]\n",
      "  ...\n",
      "  [0.46242774 0.5833333  0.         ... 0.         0.39370078 0.375     ]\n",
      "  [0.36416185 0.8333333  0.         ... 0.         0.37007874 0.4036281 ]\n",
      "  [0.5606936  0.16666667 0.         ... 0.         0.2992126  0.34963152]]]\n",
      "(200, 25)\n",
      "seq_array_test_k:  [[[0.48554912 0.5        0.         ... 0.         0.48031497 0.6319444 ]\n",
      "  [0.22543353 0.41666666 0.         ... 0.         0.4566929  0.50269276]\n",
      "  [0.58381504 0.8333333  0.         ... 0.         0.5511811  0.57568026]\n",
      "  ...\n",
      "  [0.6473988  0.33333334 0.         ... 0.         0.1496063  0.39455783]\n",
      "  [0.3699422  0.75       0.         ... 0.         0.17322835 0.4448696 ]\n",
      "  [0.24855492 0.6666667  0.         ... 0.         0.32283464 0.32284582]]]\n",
      "(210, 25)\n",
      "seq_array_test_k:  [[[0.35260117 0.33333334 0.         ... 0.         0.48031497 0.4223356 ]\n",
      "  [0.5953757  0.16666667 0.         ... 0.         0.51968503 0.38449547]\n",
      "  [0.39884394 0.41666666 0.         ... 0.         0.33070865 0.55243766]\n",
      "  ...\n",
      "  [0.40462428 0.8333333  0.         ... 0.         0.22834645 0.3955499 ]\n",
      "  [0.5549133  0.8333333  0.         ... 0.         0.18110237 0.16170634]\n",
      "  [0.73410404 0.5833333  0.         ... 0.         0.32283464 0.1802721 ]]]\n",
      "(50, 25)\n",
      "seq_array_test_k:  [[[0.60115606 0.33333334 0.         ... 0.         0.6062992  0.6758787 ]\n",
      "  [0.39306358 0.5833333  0.         ... 0.         0.61417323 0.7314342 ]\n",
      "  [0.48554912 0.16666667 0.         ... 0.         0.77952754 0.6761621 ]\n",
      "  ...\n",
      "  [0.41618496 0.6666667  0.         ... 0.         0.6062992  0.5871599 ]\n",
      "  [0.4682081  0.5        0.         ... 0.         0.6692913  0.71130955]\n",
      "  [0.5086705  0.16666667 0.         ... 0.         0.72440946 0.7032313 ]]]\n",
      "(60, 25)\n",
      "seq_array_test_k:  [[[0.47398844 0.25       0.         ... 0.         0.6929134  0.5564059 ]\n",
      "  [0.42196533 0.41666666 0.         ... 0.         0.77952754 0.7291667 ]\n",
      "  [0.49710983 0.75       0.         ... 0.         0.6929134  0.69345236]\n",
      "  ...\n",
      "  [0.24277456 0.5833333  0.         ... 0.         0.7480315  0.7973356 ]\n",
      "  [0.65317917 0.5        0.         ... 0.         0.7559055  0.6960034 ]\n",
      "  [0.5086705  0.41666666 0.         ... 0.         0.68503934 0.6299603 ]]]\n",
      "(70, 25)\n",
      "seq_array_test_k:  [[[0.60115606 0.8333333  0.         ... 0.         0.5905512  0.7344104 ]\n",
      "  [0.30635837 0.08333334 0.         ... 0.         0.68503934 0.73795354]\n",
      "  [0.61271673 0.16666667 0.         ... 0.         0.6456693  0.73951244]\n",
      "  ...\n",
      "  [0.3583815  0.75       0.         ... 0.         0.511811   0.6152211 ]\n",
      "  [0.5317919  0.6666667  0.         ... 0.         0.5905512  0.68792516]\n",
      "  [0.65317917 0.5833333  0.         ... 0.         0.5905512  0.6825397 ]]]\n",
      "(80, 25)\n",
      "seq_array_test_k:  [[[0.49710983 0.16666667 0.         ... 0.         0.71653545 0.6380386 ]\n",
      "  [0.39306358 0.6666667  0.         ... 0.         0.68503934 0.75411   ]\n",
      "  [0.42774567 0.41666666 0.         ... 0.         0.68503934 0.68622446]\n",
      "  ...\n",
      "  [0.6300578  0.75       0.         ... 0.         0.70866144 0.5939626 ]\n",
      "  [0.30635837 0.5        0.         ... 0.         0.56692916 0.6268424 ]\n",
      "  [0.35260117 0.33333334 0.         ... 0.         0.61417323 0.65547055]]]\n",
      "(90, 25)\n",
      "seq_array_test_k:  [[[0.57225436 0.6666667  0.         ... 0.         0.68503934 0.67984694]\n",
      "  [0.3583815  0.33333334 0.         ... 0.         0.53543305 0.6978458 ]\n",
      "  [0.6300578  0.41666666 0.         ... 0.         0.5984252  0.5966553 ]\n",
      "  ...\n",
      "  [0.716763   0.33333334 0.         ... 0.         0.6456693  0.64824265]\n",
      "  [0.40462428 0.25       0.         ... 0.         0.7480315  0.6738946 ]\n",
      "  [0.6763006  0.8333333  0.         ... 0.         0.4566929  0.740788  ]]]\n",
      "(100, 25)\n",
      "seq_array_test_k:  [[[0.5260116  0.41666666 0.         ... 0.         0.6692913  0.79903626]\n",
      "  [0.4682081  0.75       0.         ... 0.         0.62992126 0.7383787 ]\n",
      "  [0.69942194 0.5833333  0.         ... 0.         0.62992126 0.54818594]\n",
      "  ...\n",
      "  [0.48554912 0.         0.         ... 0.         0.5590551  0.6894841 ]\n",
      "  [0.21387284 0.33333334 0.         ... 0.         0.51968503 0.55017006]\n",
      "  [0.47398844 0.75       0.         ... 0.         0.54330707 0.6831066 ]]]\n",
      "(110, 25)\n",
      "seq_array_test_k:  [[[0.35260117 0.16666667 0.         ... 0.         0.6062992  0.58900225]\n",
      "  [0.49710983 0.08333334 0.         ... 0.         0.7007874  0.6585884 ]\n",
      "  [0.5317919  0.8333333  0.         ... 0.         0.53543305 0.77565193]\n",
      "  ...\n",
      "  [0.35260117 0.25       0.         ... 0.         0.54330707 0.5141723 ]\n",
      "  [0.6763006  0.08333334 0.         ... 0.         0.51968503 0.62570864]\n",
      "  [0.50289017 0.16666667 0.         ... 0.         0.7007874  0.67800456]]]\n",
      "(120, 25)\n",
      "seq_array_test_k:  [[[0.44508672 0.5833333  0.         ... 0.         0.53543305 0.7288832 ]\n",
      "  [0.47976878 0.41666666 0.         ... 0.         0.53543305 0.56930274]\n",
      "  [0.5895954  0.41666666 0.         ... 0.         0.71653545 0.67261904]\n",
      "  ...\n",
      "  [0.4913295  0.16666667 0.         ... 0.         0.5590551  0.47732428]\n",
      "  [0.30635837 0.6666667  0.         ... 0.         0.7322835  0.6380386 ]\n",
      "  [0.41618496 0.8333333  0.         ... 0.         0.5905512  0.5443594 ]]]\n",
      "(130, 25)\n",
      "seq_array_test_k:  [[[0.31791908 0.41666666 0.         ... 0.         0.6614173  0.69401926]\n",
      "  [0.6416185  0.16666667 0.         ... 0.         0.48031497 0.6978458 ]\n",
      "  [0.6242775  0.8333333  0.         ... 0.         0.7559055  0.5382653 ]\n",
      "  ...\n",
      "  [0.57225436 0.16666667 0.         ... 0.         0.5826772  0.57922333]\n",
      "  [0.15606937 0.8333333  0.         ... 0.         0.56692916 0.50651926]\n",
      "  [0.3236994  0.5833333  0.         ... 0.         0.62204725 0.6761621 ]]]\n",
      "(140, 25)\n",
      "seq_array_test_k:  [[[0.51445085 0.5        0.         ... 0.         0.7007874  0.5660431 ]\n",
      "  [0.58381504 0.08333334 0.         ... 0.         0.48818898 0.6710601 ]\n",
      "  [0.47398844 0.5        0.         ... 0.         0.53543305 0.56661   ]\n",
      "  ...\n",
      "  [0.37572256 0.5833333  0.         ... 0.         0.6929134  0.6420068 ]\n",
      "  [0.5606936  0.25       0.         ... 0.         0.4566929  0.49971655]\n",
      "  [0.48554912 0.25       0.         ... 0.         0.5905512  0.53061223]]]\n",
      "(150, 25)\n",
      "seq_array_test_k:  [[[0.41040462 0.08333334 0.         ... 0.         0.61417323 0.53458047]\n",
      "  [0.31791908 0.75       0.         ... 0.         0.496063   0.7828798 ]\n",
      "  [0.43930635 0.08333334 0.         ... 0.         0.5984252  0.5361394 ]\n",
      "  ...\n",
      "  [0.36416185 0.16666667 0.         ... 0.         0.5984252  0.6313776 ]\n",
      "  [0.47976878 0.8333333  0.         ... 0.         0.6692913  0.5946712 ]\n",
      "  [0.6473988  0.33333334 0.         ... 0.         0.41732284 0.5810658 ]]]\n",
      "(160, 25)\n",
      "seq_array_test_k:  [[[0.39306358 0.8333333  0.         ... 0.         0.7007874  0.47604877]\n",
      "  [0.48554912 0.         0.         ... 0.         0.6614173  0.43537414]\n",
      "  [0.4913295  0.08333334 0.         ... 0.         0.54330707 0.64427435]\n",
      "  ...\n",
      "  [0.28901735 0.41666666 0.         ... 0.         0.46456692 0.6203231 ]\n",
      "  [0.3468208  0.6666667  0.         ... 0.         0.53543305 0.3969671 ]\n",
      "  [0.47398844 0.16666667 0.         ... 0.         0.4015748  0.5471939 ]]]\n",
      "(170, 25)\n",
      "seq_array_test_k:  [[[0.48554912 0.5        0.         ... 0.         0.61417323 0.6839569 ]\n",
      "  [0.6300578  0.16666667 0.         ... 0.         0.7007874  0.6296769 ]\n",
      "  [0.30057803 0.41666666 0.         ... 0.         0.496063   0.42446145]\n",
      "  ...\n",
      "  [0.6473988  0.6666667  0.         ... 0.         0.46456692 0.58319163]\n",
      "  [0.31213874 0.16666667 0.         ... 0.         0.33858266 0.5861678 ]\n",
      "  [0.41040462 0.5        0.         ... 0.         0.503937   0.51346374]]]\n",
      "(180, 25)\n",
      "seq_array_test_k:  [[[0.42196533 0.33333334 0.         ... 0.         0.6062992  0.48511904]\n",
      "  [0.48554912 0.33333334 0.         ... 0.         0.48818898 0.522534  ]\n",
      "  [0.47976878 0.6666667  0.         ... 0.         0.63779527 0.8752834 ]\n",
      "  ...\n",
      "  [0.47398844 0.08333334 0.         ... 0.         0.46456692 0.4447279 ]\n",
      "  [0.5086705  0.16666667 0.         ... 0.         0.48818898 0.49050453]\n",
      "  [0.3815029  0.5833333  0.         ... 0.         0.32283464 0.4934807 ]]]\n",
      "(190, 25)\n",
      "seq_array_test_k:  [[[0.5317919  0.6666667  0.         ... 0.         0.54330707 0.52947843]\n",
      "  [0.3815029  0.5833333  0.         ... 0.         0.63779527 0.53628117]\n",
      "  [0.6763006  0.75       0.         ... 0.         0.4488189  0.63449544]\n",
      "  ...\n",
      "  [0.3468208  0.25       0.         ... 0.         0.40944883 0.37159863]\n",
      "  [0.47398844 0.6666667  0.         ... 0.         0.40944883 0.3955499 ]\n",
      "  [0.54913294 0.75       0.         ... 0.         0.33858266 0.27650228]]]\n",
      "(200, 25)\n",
      "seq_array_test_k:  [[[0.716763   0.25       0.         ... 0.         0.5590551  0.53188777]\n",
      "  [0.54913294 0.33333334 0.         ... 0.         0.47244096 0.4798753 ]\n",
      "  [0.46242774 0.41666666 0.         ... 0.         0.5905512  0.44586167]\n",
      "  ...\n",
      "  [0.5202312  0.5        0.         ... 0.         0.43307087 0.3167517 ]\n",
      "  [0.42774567 0.08333334 0.         ... 0.         0.27559054 0.38492063]\n",
      "  [0.63583815 0.33333334 0.         ... 0.         0.2913386  0.33149093]]]\n",
      "(210, 25)\n",
      "seq_array_test_k:  [[[0.57225436 0.5        0.         ... 0.         0.5748032  0.5005669 ]\n",
      "  [0.3468208  0.5        0.         ... 0.         0.46456692 0.4655612 ]\n",
      "  [0.33526012 0.6666667  0.         ... 0.         0.496063   0.62429136]\n",
      "  ...\n",
      "  [0.38728324 0.33333334 0.         ... 0.         0.30708662 0.21612811]\n",
      "  [0.61271673 0.75       0.         ... 0.         0.39370078 0.42247733]\n",
      "  [0.6300578  0.6666667  0.         ... 0.         0.23622048 0.25963718]]]\n",
      "(50, 25)\n",
      "seq_array_test_k:  [[[0.42196533 0.16666667 0.         ... 0.         0.71653545 0.70819163]\n",
      "  [0.5086705  0.16666667 0.         ... 0.         0.8346457  0.6072846 ]\n",
      "  [0.6069364  0.6666667  0.         ... 0.         0.6692913  0.6007653 ]\n",
      "  ...\n",
      "  [0.45086706 0.5        0.         ... 0.         0.53543305 0.68296486]\n",
      "  [0.50289017 0.33333334 0.         ... 0.         0.7401575  0.62174034]\n",
      "  [0.46242774 0.41666666 0.         ... 0.         0.5590551  0.65702945]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 25)\n",
      "seq_array_test_k:  [[[0.58381504 0.16666667 0.         ... 0.         0.6929134  0.7651644 ]\n",
      "  [0.24277456 0.9166667  0.         ... 0.         0.7559055  0.888322  ]\n",
      "  [0.4682081  0.25       0.         ... 0.         0.7480315  0.5741213 ]\n",
      "  ...\n",
      "  [0.5317919  0.25       0.         ... 0.         0.6692913  0.5401077 ]\n",
      "  [0.5317919  0.5        0.         ... 0.         0.6062992  0.8139172 ]\n",
      "  [0.57225436 0.41666666 0.         ... 0.         0.56692916 0.68792516]]]\n",
      "(70, 25)\n",
      "seq_array_test_k:  [[[0.31213874 0.5833333  0.         ... 0.         0.6456693  0.7430556 ]\n",
      "  [0.3815029  0.5        0.         ... 0.         0.5984252  0.76544785]\n",
      "  [0.6242775  0.5        0.         ... 0.         0.7007874  0.6231576 ]\n",
      "  ...\n",
      "  [0.46242774 0.75       0.         ... 0.         0.62992126 0.4934807 ]\n",
      "  [0.2947977  0.25       0.         ... 0.         0.6062992  0.5807823 ]\n",
      "  [0.56647396 0.33333334 0.         ... 0.         0.61417323 0.44756237]]]\n",
      "(80, 25)\n",
      "seq_array_test_k:  [[[0.2947977  0.5833333  0.         ... 0.         0.7480315  0.73214287]\n",
      "  [0.433526   0.5833333  0.         ... 0.         0.6456693  0.6169218 ]\n",
      "  [0.63583815 0.16666667 0.         ... 0.         0.63779527 0.6551871 ]\n",
      "  ...\n",
      "  [0.4913295  0.25       0.         ... 0.         0.6692913  0.71697843]\n",
      "  [0.49710983 0.8333333  0.         ... 0.         0.5748032  0.651644  ]\n",
      "  [0.433526   0.9166667  0.         ... 0.         0.6614173  0.6706349 ]]]\n",
      "(90, 25)\n",
      "seq_array_test_k:  [[[0.34104046 0.5        0.         ... 0.         0.7401575  0.7962018 ]\n",
      "  [0.4682081  0.5        0.         ... 0.         0.68503934 0.7956349 ]\n",
      "  [0.5895954  0.5        0.         ... 0.         0.6062992  0.8341837 ]\n",
      "  ...\n",
      "  [0.48554912 0.41666666 0.         ... 0.         0.48818898 0.7389456 ]\n",
      "  [0.2716763  0.16666667 0.         ... 0.         0.46456692 0.6111111 ]\n",
      "  [0.45086706 0.5833333  0.         ... 0.         0.54330707 0.71428573]]]\n",
      "(100, 25)\n",
      "seq_array_test_k:  [[[0.5086705  0.9166667  0.         ... 0.         0.52755904 0.6655329 ]\n",
      "  [0.35260117 0.5833333  0.         ... 0.         0.53543305 0.6136621 ]\n",
      "  [0.42774567 0.5833333  0.         ... 0.         0.7401575  0.7032313 ]\n",
      "  ...\n",
      "  [0.44508672 0.5        0.         ... 0.         0.4488189  0.57185376]\n",
      "  [0.5260116  0.9166667  0.         ... 0.         0.6771653  0.6927438 ]\n",
      "  [0.8034682  0.5        0.         ... 0.         0.5748032  0.5297619 ]]]\n",
      "(110, 25)\n",
      "seq_array_test_k:  [[[0.73410404 0.9166667  0.         ... 0.         0.6771653  0.63704646]\n",
      "  [0.45086706 0.16666667 0.         ... 0.         0.62204725 0.43126416]\n",
      "  [0.39306358 0.8333333  0.         ... 0.         0.48031497 0.6904762 ]\n",
      "  ...\n",
      "  [0.47398844 0.6666667  0.         ... 0.         0.54330707 0.50453514]\n",
      "  [0.47398844 0.5833333  0.         ... 0.         0.5905512  0.7752268 ]\n",
      "  [0.60115606 0.6666667  0.         ... 0.         0.47244096 0.51318026]]]\n",
      "(120, 25)\n",
      "seq_array_test_k:  [[[0.6242775  0.6666667  0.         ... 0.         0.5984252  0.65958047]\n",
      "  [0.23121387 0.9166667  0.         ... 0.         0.63779527 0.783305  ]\n",
      "  [0.5086705  0.9166667  0.         ... 0.         0.5511811  0.48696145]\n",
      "  ...\n",
      "  [0.4566474  0.6666667  0.         ... 0.         0.48818898 0.53628117]\n",
      "  [0.45086706 0.33333334 0.         ... 0.         0.52755904 0.48809522]\n",
      "  [0.2947977  0.41666666 0.         ... 0.         0.5511811  0.5877268 ]]]\n",
      "(130, 25)\n",
      "seq_array_test_k:  [[[0.45086706 0.6666667  0.         ... 0.         0.6614173  0.47534013]\n",
      "  [0.40462428 0.41666666 0.         ... 0.         0.72440946 0.52933675]\n",
      "  [0.44508672 0.75       0.         ... 0.         0.5826772  0.62230724]\n",
      "  ...\n",
      "  [0.43930635 0.5833333  0.         ... 0.         0.40944883 0.5219671 ]\n",
      "  [0.48554912 1.         0.         ... 0.         0.5748032  0.56150794]\n",
      "  [0.46242774 0.5        0.         ... 0.         0.42519686 0.3664966 ]]]\n",
      "(140, 25)\n",
      "seq_array_test_k:  [[[0.20809248 0.6666667  0.         ... 0.         0.5511811  0.6600057 ]\n",
      "  [0.53757226 0.6666667  0.         ... 0.         0.5984252  0.5049603 ]\n",
      "  [0.3583815  0.16666667 0.         ... 0.         0.51968503 0.62882656]\n",
      "  ...\n",
      "  [0.4913295  0.6666667  0.         ... 0.         0.32283464 0.33276644]\n",
      "  [0.5433526  0.5833333  0.         ... 0.         0.28346458 0.16354875]\n",
      "  [0.31791908 0.16666667 0.         ... 0.         0.35433072 0.26190478]]]\n",
      "(150, 25)\n",
      "seq_array_test_k:  [[[0.5780347  0.9166667  0.         ... 0.         0.5511811  0.5018424 ]\n",
      "  [0.5780347  0.33333334 0.         ... 0.         0.52755904 0.7210884 ]\n",
      "  [0.42774567 0.41666666 0.         ... 0.         0.4566929  0.46626985]\n",
      "  ...\n",
      "  [0.47976878 0.33333334 0.         ... 0.         0.3464567  0.36791384]\n",
      "  [0.53757226 0.25       0.         ... 0.         0.28346458 0.2760771 ]\n",
      "  [0.67052025 0.41666666 0.         ... 0.         0.15748031 0.39880952]]]\n",
      "(50, 25)\n",
      "seq_array_test_k:  [[[0.48554912 0.41666666 0.         ... 0.         0.48031497 0.5369898 ]\n",
      "  [0.30057803 0.41666666 0.         ... 0.         0.38582677 0.5860261 ]\n",
      "  [0.5606936  0.5833333  0.         ... 0.         0.6929134  0.50538546]\n",
      "  ...\n",
      "  [0.33526012 0.9166667  0.         ... 0.         0.4015748  0.5229592 ]\n",
      "  [0.44508672 0.16666667 0.         ... 0.         0.48818898 0.40575397]\n",
      "  [0.51445085 0.5833333  0.         ... 0.         0.52755904 0.54407597]]]\n",
      "(60, 25)\n",
      "seq_array_test_k:  [[[0.47398844 0.6666667  0.         ... 0.         0.4566929  0.611678  ]\n",
      "  [0.49710983 0.6666667  0.         ... 0.         0.6062992  0.4393424 ]\n",
      "  [0.5606936  0.6666667  0.         ... 0.         0.54330707 0.57482994]\n",
      "  ...\n",
      "  [0.5202312  0.41666666 0.         ... 0.         0.4566929  0.4647109 ]\n",
      "  [0.6300578  0.25       0.         ... 0.         0.511811   0.49503967]\n",
      "  [0.41040462 0.16666667 0.         ... 0.         0.48031497 0.46258503]]]\n",
      "(70, 25)\n",
      "seq_array_test_k:  [[[0.3236994  0.41666666 0.         ... 0.         0.46456692 0.5382653 ]\n",
      "  [0.28901735 0.16666667 0.         ... 0.         0.52755904 0.5114796 ]\n",
      "  [0.3583815  0.6666667  0.         ... 0.         0.5748032  0.52706915]\n",
      "  ...\n",
      "  [0.5780347  0.75       0.         ... 0.         0.503937   0.533305  ]\n",
      "  [0.5895954  0.33333334 0.         ... 0.         0.4488189  0.335034  ]\n",
      "  [0.78612715 0.6666667  0.         ... 0.         0.53543305 0.36422902]]]\n",
      "(80, 25)\n",
      "seq_array_test_k:  [[[0.51445085 0.25       0.         ... 0.         0.6535433  0.47576532]\n",
      "  [0.5780347  0.25       0.         ... 0.         0.37795275 0.62230724]\n",
      "  [0.83815026 0.5        0.         ... 0.         0.25984251 0.5297619 ]\n",
      "  ...\n",
      "  [0.7398844  0.5        0.         ... 0.         0.41732284 0.4143991 ]\n",
      "  [0.21965317 0.5833333  0.         ... 0.         0.26771653 0.5185658 ]\n",
      "  [0.40462428 0.5        0.         ... 0.         0.4566929  0.450822  ]]]\n",
      "(90, 25)\n",
      "seq_array_test_k:  [[[0.7745665  0.41666666 0.         ... 0.         0.6062992  0.44756237]\n",
      "  [0.57225436 0.16666667 0.         ... 0.         0.4566929  0.74730724]\n",
      "  [0.24855492 0.75       0.         ... 0.         0.43307087 0.4722222 ]\n",
      "  ...\n",
      "  [0.5606936  0.8333333  0.         ... 0.         0.39370078 0.35005668]\n",
      "  [0.4913295  0.41666666 0.         ... 0.         0.503937   0.43466553]\n",
      "  [0.5549133  0.33333334 0.         ... 0.         0.52755904 0.5085034 ]]]\n",
      "(100, 25)\n",
      "seq_array_test_k:  [[[0.51445085 0.25       0.         ... 0.         0.43307087 0.5606576 ]\n",
      "  [0.7745665  0.41666666 0.         ... 0.         0.2913386  0.40589568]\n",
      "  [0.42774567 0.5833333  0.         ... 0.         0.4488189  0.4151077 ]\n",
      "  ...\n",
      "  [0.49710983 0.41666666 0.         ... 0.         0.2913386  0.57908165]\n",
      "  [0.5549133  0.16666667 0.         ... 0.         0.43307087 0.30215418]\n",
      "  [0.5780347  0.5        0.         ... 0.         0.35433072 0.44246033]]]\n",
      "(110, 25)\n",
      "seq_array_test_k:  [[[0.30057803 0.5833333  0.         ... 0.         0.63779527 0.4084467 ]\n",
      "  [0.38728324 0.41666666 0.         ... 0.         0.39370078 0.61437076]\n",
      "  [0.30057803 0.33333334 0.         ... 0.         0.48818898 0.49178004]\n",
      "  ...\n",
      "  [0.48554912 0.5833333  0.         ... 0.         0.32283464 0.3815193 ]\n",
      "  [0.5086705  0.33333334 0.         ... 0.         0.44094488 0.41213152]\n",
      "  [0.36416185 0.75       0.         ... 0.         0.37795275 0.48412699]]]\n",
      "(120, 25)\n",
      "seq_array_test_k:  [[[0.44508672 0.33333334 0.         ... 0.         0.33070865 0.50382656]\n",
      "  [0.3815029  0.6666667  0.         ... 0.         0.47244096 0.545068  ]\n",
      "  [0.3583815  0.8333333  0.         ... 0.         0.496063   0.38803855]\n",
      "  ...\n",
      "  [0.70520234 0.16666667 0.         ... 0.         0.54330707 0.24716553]\n",
      "  [0.69942194 0.33333334 0.         ... 0.         0.23622048 0.37188208]\n",
      "  [0.50289017 0.9166667  0.         ... 0.         0.25984251 0.35473356]]]\n",
      "(130, 25)\n",
      "seq_array_test_k:  [[[0.65317917 0.5833333  0.         ... 0.         0.496063   0.4793084 ]\n",
      "  [0.23121387 0.75       0.         ... 0.         0.2992126  0.5328798 ]\n",
      "  [0.6242775  0.6666667  0.         ... 0.         0.39370078 0.5376984 ]\n",
      "  ...\n",
      "  [0.433526   0.5        0.         ... 0.         0.2519685  0.1904762 ]\n",
      "  [0.6416185  0.75       0.         ... 0.         0.15748031 0.41326532]\n",
      "  [0.37572256 0.75       0.         ... 0.         0.33070865 0.25992063]]]\n",
      "(50, 25)\n",
      "seq_array_test_k:  [[[0.12138728 0.25       0.         ... 0.         0.5590551  0.7052154 ]\n",
      "  [0.5260116  0.41666666 0.         ... 0.         0.5511811  0.559949  ]\n",
      "  [0.5086705  0.41666666 0.         ... 0.         0.46456692 0.6003401 ]\n",
      "  ...\n",
      "  [0.5086705  0.16666667 0.         ... 0.         0.511811   0.42020977]\n",
      "  [0.6242775  0.9166667  0.         ... 0.         0.5984252  0.671627  ]\n",
      "  [0.28901735 0.25       0.         ... 0.         0.7322835  0.6797052 ]]]\n",
      "(60, 25)\n",
      "seq_array_test_k:  [[[0.3815029  0.41666666 0.         ... 0.         0.68503934 0.63761336]\n",
      "  [0.34104046 0.25       0.         ... 0.         0.6692913  0.53684807]\n",
      "  [0.39306358 0.8333333  0.         ... 0.         0.6614173  0.6832483 ]\n",
      "  ...\n",
      "  [0.5260116  0.16666667 0.         ... 0.         0.54330707 0.55839   ]\n",
      "  [0.02890173 0.8333333  0.         ... 0.         0.48031497 0.5036848 ]\n",
      "  [0.30057803 0.8333333  0.         ... 0.         0.51968503 0.6632653 ]]]\n",
      "(70, 25)\n",
      "seq_array_test_k:  [[[0.6647399  0.5        0.         ... 0.         0.6771653  0.6225907 ]\n",
      "  [0.65317917 0.33333334 0.         ... 0.         0.511811   0.55513036]\n",
      "  [0.433526   0.75       0.         ... 0.         0.56692916 0.72619045]\n",
      "  ...\n",
      "  [0.58381504 0.5833333  0.         ... 0.         0.71653545 0.5830499 ]\n",
      "  [0.5895954  0.6666667  0.         ... 0.         0.6692913  0.70479023]\n",
      "  [0.63583815 0.8333333  0.         ... 0.         0.5984252  0.5856009 ]]]\n",
      "(80, 25)\n",
      "seq_array_test_k:  [[[0.6242775  0.33333334 0.         ... 0.         0.6929134  0.6736111 ]\n",
      "  [0.3583815  0.9166667  0.         ... 0.         0.62204725 0.47661564]\n",
      "  [0.36416185 0.5833333  0.         ... 0.         0.51968503 0.70904195]\n",
      "  ...\n",
      "  [0.433526   0.33333334 0.         ... 0.         0.61417323 0.63931406]\n",
      "  [0.6300578  0.16666667 0.         ... 0.         0.46456692 0.5011338 ]\n",
      "  [0.54913294 0.9166667  0.         ... 0.         0.5984252  0.57539684]]]\n",
      "(90, 25)\n",
      "seq_array_test_k:  [[[0.6647399  0.41666666 0.         ... 0.         0.62992126 0.55924034]\n",
      "  [0.5780347  0.9166667  0.         ... 0.         0.5984252  0.74007934]\n",
      "  [0.65317917 0.25       0.         ... 0.         0.6062992  0.7651644 ]\n",
      "  ...\n",
      "  [0.41618496 0.75       0.         ... 0.         0.5590551  0.732568  ]\n",
      "  [0.5433526  0.8333333  0.         ... 0.         0.43307087 0.6394558 ]\n",
      "  [0.47398844 0.25       0.         ... 0.         0.5590551  0.58928573]]]\n",
      "(100, 25)\n",
      "seq_array_test_k:  [[[0.80924857 0.6666667  0.         ... 0.         0.5590551  0.55045354]\n",
      "  [0.78612715 0.9166667  0.         ... 0.         0.53543305 0.56533444]\n",
      "  [0.3468208  0.5833333  0.         ... 0.         0.511811   0.4321145 ]\n",
      "  ...\n",
      "  [0.76878613 0.41666666 0.         ... 0.         0.5905512  0.529195  ]\n",
      "  [0.6473988  0.5833333  0.         ... 0.         0.62204725 0.57128686]\n",
      "  [0.6242775  0.25       0.         ... 0.         0.56692916 0.7303004 ]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(110, 25)\n",
      "seq_array_test_k:  [[[0.37572256 0.41666666 0.         ... 0.         0.5984252  0.56930274]\n",
      "  [0.61271673 0.75       0.         ... 0.         0.48031497 0.65617913]\n",
      "  [0.44508672 0.9166667  0.         ... 0.         0.6614173  0.5352891 ]\n",
      "  ...\n",
      "  [0.28323698 0.41666666 0.         ... 0.         0.62992126 0.6472506 ]\n",
      "  [0.5433526  0.75       0.         ... 0.         0.511811   0.7850057 ]\n",
      "  [0.45086706 0.25       0.         ... 0.         0.72440946 0.7066327 ]]]\n",
      "(120, 25)\n",
      "seq_array_test_k:  [[[0.51445085 0.5833333  0.         ... 0.         0.6456693  0.6264172 ]\n",
      "  [0.4913295  0.9166667  0.         ... 0.         0.6692913  0.6096939 ]\n",
      "  [0.716763   0.5833333  0.         ... 0.         0.52755904 0.75765306]\n",
      "  ...\n",
      "  [0.58381504 0.33333334 0.         ... 0.         0.51968503 0.6923186 ]\n",
      "  [0.6763006  0.33333334 0.         ... 0.         0.52755904 0.6843821 ]\n",
      "  [0.13294798 0.16666667 0.         ... 0.         0.5984252  0.69798756]]]\n",
      "(130, 25)\n",
      "seq_array_test_k:  [[[0.44508672 0.75       0.         ... 0.         0.6535433  0.6269841 ]\n",
      "  [0.5202312  0.8333333  0.         ... 0.         0.6062992  0.7056406 ]\n",
      "  [0.4913295  0.9166667  0.         ... 0.         0.4488189  0.6695011 ]\n",
      "  ...\n",
      "  [0.5260116  0.33333334 0.         ... 0.         0.48818898 0.65263605]\n",
      "  [0.6069364  1.         0.         ... 0.         0.5826772  0.6991213 ]\n",
      "  [0.6589595  0.75       0.         ... 0.         0.5984252  0.6527778 ]]]\n",
      "(140, 25)\n",
      "seq_array_test_k:  [[[0.72254336 0.16666667 0.         ... 0.         0.56692916 0.53656465]\n",
      "  [0.6416185  0.16666667 0.         ... 0.         0.51968503 0.64540815]\n",
      "  [0.41040462 0.5        0.         ... 0.         0.6535433  0.7276077 ]\n",
      "  ...\n",
      "  [0.38728324 0.33333334 0.         ... 0.         0.6535433  0.67701244]\n",
      "  [0.6416185  0.8333333  0.         ... 0.         0.47244096 0.49787414]\n",
      "  [0.44508672 0.41666666 0.         ... 0.         0.47244096 0.67701244]]]\n",
      "(150, 25)\n",
      "seq_array_test_k:  [[[0.5953757  0.9166667  0.         ... 0.         0.5905512  0.67800456]\n",
      "  [0.6300578  0.6666667  0.         ... 0.         0.6456693  0.6026077 ]\n",
      "  [0.44508672 0.16666667 0.         ... 0.         0.56692916 0.5908447 ]\n",
      "  ...\n",
      "  [0.37572256 0.16666667 0.         ... 0.         0.6062992  0.625     ]\n",
      "  [0.5895954  0.5        0.         ... 0.         0.5590551  0.5610828 ]\n",
      "  [0.5086705  0.6666667  0.         ... 0.         0.63779527 0.63208616]]]\n",
      "(160, 25)\n",
      "seq_array_test_k:  [[[0.39884394 0.5        0.         ... 0.         0.53543305 0.6805556 ]\n",
      "  [0.61271673 0.5833333  0.         ... 0.         0.63779527 0.47037983]\n",
      "  [0.4682081  1.         0.         ... 0.         0.53543305 0.67318594]\n",
      "  ...\n",
      "  [0.3468208  0.5        0.         ... 0.         0.63779527 0.70181406]\n",
      "  [0.6242775  0.16666667 0.         ... 0.         0.52755904 0.6227324 ]\n",
      "  [0.5606936  0.5833333  0.         ... 0.         0.5905512  0.4606009 ]]]\n",
      "(170, 25)\n",
      "seq_array_test_k:  [[[0.58381504 0.33333334 0.         ... 0.         0.511811   0.6047336 ]\n",
      "  [0.5780347  0.16666667 0.         ... 0.         0.62992126 0.61153626]\n",
      "  [0.39306358 0.41666666 0.         ... 0.         0.6692913  0.5873016 ]\n",
      "  ...\n",
      "  [0.6069364  0.6666667  0.         ... 0.         0.52755904 0.52324265]\n",
      "  [0.2947977  0.8333333  0.         ... 0.         0.48818898 0.611678  ]\n",
      "  [0.54913294 0.5        0.         ... 0.         0.48031497 0.5460601 ]]]\n",
      "(180, 25)\n",
      "seq_array_test_k:  [[[0.25433525 0.33333334 0.         ... 0.         0.5590551  0.4350907 ]\n",
      "  [0.41040462 0.25       0.         ... 0.         0.7401575  0.5316043 ]\n",
      "  [0.5549133  0.6666667  0.         ... 0.         0.5748032  0.7994614 ]\n",
      "  ...\n",
      "  [0.5086705  0.9166667  0.         ... 0.         0.47244096 0.59438777]\n",
      "  [0.5317919  0.5        0.         ... 0.         0.44094488 0.66652495]\n",
      "  [0.4682081  0.9166667  0.         ... 0.         0.5905512  0.7037982 ]]]\n",
      "(190, 25)\n",
      "seq_array_test_k:  [[[0.5202312  0.9166667  0.         ... 0.         0.5984252  0.78316325]\n",
      "  [0.44508672 0.9166667  0.         ... 0.         0.70866144 0.59438777]\n",
      "  [0.41618496 0.16666667 0.         ... 0.         0.511811   0.6712018 ]\n",
      "  ...\n",
      "  [0.7803468  0.16666667 0.         ... 0.         0.5748032  0.56405896]\n",
      "  [0.6589595  0.6666667  0.         ... 0.         0.6062992  0.47378117]\n",
      "  [0.50289017 0.25       0.         ... 0.         0.63779527 0.627551  ]]]\n",
      "(200, 25)\n",
      "seq_array_test_k:  [[[0.5433526  0.8333333  0.         ... 0.         0.51968503 0.53245467]\n",
      "  [0.46242774 0.41666666 0.         ... 0.         0.6456693  0.53259635]\n",
      "  [0.5433526  0.6666667  0.         ... 0.         0.496063   0.7138606 ]\n",
      "  ...\n",
      "  [0.4682081  0.9166667  0.         ... 0.         0.6929134  0.60119045]\n",
      "  [0.24855492 0.6666667  0.         ... 0.         0.5905512  0.6894841 ]\n",
      "  [0.4913295  0.25       0.         ... 0.         0.496063   0.68480724]]]\n",
      "(210, 25)\n",
      "seq_array_test_k:  [[[0.6300578  0.5        0.         ... 0.         0.511811   0.78174603]\n",
      "  [0.47976878 0.33333334 0.         ... 0.         0.511811   0.59452945]\n",
      "  [0.47398844 0.6666667  0.         ... 0.         0.496063   0.64484125]\n",
      "  ...\n",
      "  [0.5953757  0.33333334 0.         ... 0.         0.6062992  0.46017572]\n",
      "  [0.46242774 0.5833333  0.         ... 0.         0.5984252  0.6108277 ]\n",
      "  [0.5086705  0.6666667  0.         ... 0.         0.48031497 0.5110544 ]]]\n",
      "(220, 25)\n",
      "seq_array_test_k:  [[[0.5606936  0.8333333  0.         ... 0.         0.6535433  0.63761336]\n",
      "  [0.5260116  0.16666667 0.         ... 0.         0.62204725 0.43905896]\n",
      "  [0.5433526  0.6666667  0.         ... 0.         0.5511811  0.49036282]\n",
      "  ...\n",
      "  [0.3815029  0.33333334 0.         ... 0.         0.56692916 0.4946145 ]\n",
      "  [0.54913294 0.41666666 0.         ... 0.         0.4488189  0.43253967]\n",
      "  [0.6473988  0.33333334 0.         ... 0.         0.54330707 0.56646824]]]\n",
      "(230, 25)\n",
      "seq_array_test_k:  [[[0.38728324 0.16666667 0.         ... 0.         0.5511811  0.51176304]\n",
      "  [0.61271673 0.8333333  0.         ... 0.         0.5511811  0.64512473]\n",
      "  [0.58381504 0.41666666 0.         ... 0.         0.511811   0.59963155]\n",
      "  ...\n",
      "  [0.56647396 0.5        0.         ... 0.         0.48818898 0.51714855]\n",
      "  [0.49710983 0.5        0.         ... 0.         0.54330707 0.5208333 ]\n",
      "  [0.5549133  0.6666667  0.         ... 0.         0.4488189  0.49957484]]]\n",
      "(240, 25)\n",
      "seq_array_test_k:  [[[0.5549133  0.5        0.         ... 0.         0.40944883 0.5935374 ]\n",
      "  [0.41040462 0.16666667 0.         ... 0.         0.5748032  0.66680837]\n",
      "  [0.49710983 0.75       0.         ... 0.         0.3464567  0.5969388 ]\n",
      "  ...\n",
      "  [0.39306358 0.5        0.         ... 0.         0.503937   0.47562358]\n",
      "  [0.73410404 0.6666667  0.         ... 0.         0.5748032  0.5582483 ]\n",
      "  [0.57225436 0.16666667 0.         ... 0.         0.48818898 0.4186508 ]]]\n",
      "(250, 25)\n",
      "seq_array_test_k:  [[[0.48554912 0.75       0.         ... 0.         0.4566929  0.5871599 ]\n",
      "  [0.56647396 0.41666666 0.         ... 0.         0.5905512  0.5977891 ]\n",
      "  [0.42774567 0.75       0.         ... 0.         0.511811   0.6778628 ]\n",
      "  ...\n",
      "  [0.41040462 0.41666666 0.         ... 0.         0.496063   0.6111111 ]\n",
      "  [0.30635837 0.16666667 0.         ... 0.         0.46456692 0.42743763]\n",
      "  [0.5317919  0.75       0.         ... 0.         0.51968503 0.4484127 ]]]\n",
      "(260, 25)\n",
      "seq_array_test_k:  [[[0.4682081  0.33333334 0.         ... 0.         0.5511811  0.5780896 ]\n",
      "  [0.5317919  0.5        0.         ... 0.         0.6614173  0.6340703 ]\n",
      "  [0.61271673 0.5        0.         ... 0.         0.54330707 0.5341553 ]\n",
      "  ...\n",
      "  [0.38728324 0.75       0.         ... 0.         0.51968503 0.51048756]\n",
      "  [0.85549134 0.5        0.         ... 0.         0.4015748  0.5255102 ]\n",
      "  [0.72254336 0.9166667  0.         ... 0.         0.39370078 0.45252267]]]\n",
      "(270, 25)\n",
      "seq_array_test_k:  [[[0.4566474  0.8333333  0.         ... 0.         0.6456693  0.7022392 ]\n",
      "  [0.4682081  0.6666667  0.         ... 0.         0.4566929  0.6789966 ]\n",
      "  [0.6647399  0.8333333  0.         ... 0.         0.41732284 0.70351475]\n",
      "  ...\n",
      "  [0.7109827  0.16666667 0.         ... 0.         0.37007874 0.4319728 ]\n",
      "  [0.6820809  0.16666667 0.         ... 0.         0.36220473 0.40320295]\n",
      "  [0.5317919  0.9166667  0.         ... 0.         0.42519686 0.28245464]]]\n",
      "(280, 25)\n",
      "seq_array_test_k:  [[[0.48554912 0.6666667  0.         ... 0.         0.48818898 0.35459185]\n",
      "  [0.38728324 0.8333333  0.         ... 0.         0.5590551  0.4865363 ]\n",
      "  [0.43930635 0.25       0.         ... 0.         0.511811   0.45620748]\n",
      "  ...\n",
      "  [0.5086705  0.33333334 0.         ... 0.         0.40944883 0.42091838]\n",
      "  [0.5202312  0.5833333  0.         ... 0.         0.37007874 0.41170636]\n",
      "  [0.1734104  0.8333333  0.         ... 0.         0.2992126  0.5486111 ]]]\n",
      "(290, 25)\n",
      "seq_array_test_k:  [[[0.6069364  0.5        0.         ... 0.         0.5511811  0.6189059 ]\n",
      "  [0.39306358 0.41666666 0.         ... 0.         0.43307087 0.40065193]\n",
      "  [0.7456647  0.5833333  0.         ... 0.         0.5984252  0.40575397]\n",
      "  ...\n",
      "  [0.3699422  0.16666667 0.         ... 0.         0.47244096 0.33645123]\n",
      "  [0.433526   0.25       0.         ... 0.         0.37007874 0.15561225]\n",
      "  [0.40462428 0.75       0.         ... 0.         0.2992126  0.30385488]]]\n",
      "(300, 25)\n",
      "seq_array_test_k:  [[[0.48554912 0.33333334 0.         ... 0.         0.35433072 0.5741213 ]\n",
      "  [0.6763006  0.16666667 0.         ... 0.         0.5748032  0.6269841 ]\n",
      "  [0.30635837 0.5        0.         ... 0.         0.48031497 0.6006236 ]\n",
      "  ...\n",
      "  [0.50289017 0.75       0.         ... 0.         0.27559054 0.28840703]\n",
      "  [0.31213874 0.16666667 0.         ... 0.         0.46456692 0.28231293]\n",
      "  [0.6820809  0.25       0.         ... 0.         0.5511811  0.29209185]]]\n",
      "(310, 25)\n",
      "seq_array_test_k:  [[[0.57225436 0.25       0.         ... 0.         0.52755904 0.4630102 ]\n",
      "  [0.57225436 0.5        0.         ... 0.         0.5826772  0.5711451 ]\n",
      "  [0.35260117 0.5        0.         ... 0.         0.48031497 0.37287414]\n",
      "  ...\n",
      "  [0.54913294 0.8333333  0.         ... 0.         0.33070865 0.3962585 ]\n",
      "  [0.32947975 0.8333333  0.         ... 0.         0.39370078 0.26955783]\n",
      "  [0.48554912 0.9166667  0.         ... 0.         0.39370078 0.32142857]]]\n",
      "(320, 25)\n",
      "seq_array_test_k:  [[[0.23121387 0.9166667  0.         ... 0.         0.4015748  0.32298753]\n",
      "  [0.39884394 0.9166667  0.         ... 0.         0.511811   0.51544785]\n",
      "  [0.5202312  0.9166667  0.         ... 0.         0.61417323 0.5283447 ]\n",
      "  ...\n",
      "  [0.5780347  0.33333334 0.         ... 0.         0.26771653 0.23497732]\n",
      "  [0.34104046 0.75       0.         ... 0.         0.27559054 0.4297052 ]\n",
      "  [0.58381504 0.6666667  0.         ... 0.         0.26771653 0.16723356]]]\n",
      "(330, 25)\n",
      "seq_array_test_k:  [[[0.27745664 0.75       0.         ... 0.         0.46456692 0.4885204 ]\n",
      "  [0.46242774 0.5833333  0.         ... 0.         0.52755904 0.5097789 ]\n",
      "  [0.39884394 0.8333333  0.         ... 0.         0.47244096 0.22845805]\n",
      "  ...\n",
      "  [0.39306358 0.6666667  0.         ... 0.         0.15748031 0.10119048]\n",
      "  [0.6300578  0.75       0.         ... 0.         0.36220473 0.20493197]\n",
      "  [0.6647399  0.8333333  0.         ... 0.         0.23622048 0.41978458]]]\n",
      "(340, 25)\n",
      "seq_array_test_k:  [[[0.7283237  0.9166667  0.         ... 0.         0.3464567  0.42205215]\n",
      "  [0.63583815 0.9166667  0.         ... 0.         0.4488189  0.40745464]\n",
      "  [0.2947977  0.16666667 0.         ... 0.         0.22047244 0.40986395]\n",
      "  ...\n",
      "  [0.3815029  0.8333333  0.         ... 0.         0.1496063  0.15731293]\n",
      "  [0.3468208  0.75       0.         ... 0.         0.18897638 0.13548753]\n",
      "  [0.5895954  0.9166667  0.         ... 0.         0.31496063 0.19146825]]]\n",
      "(50, 25)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq_array_test_k:  [[[0.31213874 0.41666666 0.         ... 0.         0.68503934 0.62783444]\n",
      "  [0.32947975 0.5833333  0.         ... 0.         0.6535433  0.698271  ]\n",
      "  [0.2947977  0.16666667 0.         ... 0.         0.61417323 0.671627  ]\n",
      "  ...\n",
      "  [0.65317917 0.5        0.         ... 0.         0.6535433  0.69146824]\n",
      "  [0.58381504 0.8333333  0.         ... 0.         0.511811   0.7124433 ]\n",
      "  [0.32947975 0.5833333  0.         ... 0.         0.52755904 0.70365644]]]\n",
      "(60, 25)\n",
      "seq_array_test_k:  [[[0.5895954  0.75       0.         ... 0.         0.63779527 0.545068  ]\n",
      "  [0.63583815 0.41666666 0.         ... 0.         0.62204725 0.727466  ]\n",
      "  [0.40462428 0.41666666 0.         ... 0.         0.7559055  0.6452664 ]\n",
      "  ...\n",
      "  [0.53757226 0.8333333  0.         ... 0.         0.7637795  0.670068  ]\n",
      "  [0.5549133  0.6666667  0.         ... 0.         0.6062992  0.6166383 ]\n",
      "  [0.40462428 0.9166667  0.         ... 0.         0.6456693  0.8900227 ]]]\n",
      "(70, 25)\n",
      "seq_array_test_k:  [[[0.6936416  0.33333334 0.         ... 0.         0.6771653  0.72293085]\n",
      "  [0.50289017 0.33333334 0.         ... 0.         0.62204725 0.5474773 ]\n",
      "  [0.5606936  0.6666667  0.         ... 0.         0.7007874  0.63321996]\n",
      "  ...\n",
      "  [0.3236994  0.6666667  0.         ... 0.         0.6062992  0.63265306]\n",
      "  [0.37572256 0.41666666 0.         ... 0.         0.62204725 0.56845236]\n",
      "  [0.3236994  0.5833333  0.         ... 0.         0.62204725 0.59325397]]]\n",
      "(80, 25)\n",
      "seq_array_test_k:  [[[0.3236994  0.75       0.         ... 0.         0.72440946 0.87712586]\n",
      "  [0.6300578  0.33333334 0.         ... 0.         0.7401575  0.56575966]\n",
      "  [0.5549133  0.33333334 0.         ... 0.         0.6535433  0.6626984 ]\n",
      "  ...\n",
      "  [0.40462428 0.75       0.         ... 0.         0.5905512  0.6377551 ]\n",
      "  [0.44508672 0.75       0.         ... 0.         0.54330707 0.5246599 ]\n",
      "  [0.45086706 0.9166667  0.         ... 0.         0.62992126 0.7475907 ]]]\n",
      "(90, 25)\n",
      "seq_array_test_k:  [[[0.5606936  0.5833333  0.         ... 0.         0.62204725 0.77593535]\n",
      "  [0.20809248 0.5        0.         ... 0.         0.63779527 0.7121599 ]\n",
      "  [0.46242774 0.25       0.         ... 0.         0.62204725 0.6736111 ]\n",
      "  ...\n",
      "  [0.33526012 0.16666667 0.         ... 0.         0.5748032  0.62911   ]\n",
      "  [0.53757226 0.41666666 0.         ... 0.         0.62992126 0.5340136 ]\n",
      "  [0.48554912 0.9166667  0.         ... 0.         0.6062992  0.6292517 ]]]\n",
      "(100, 25)\n",
      "seq_array_test_k:  [[[0.36416185 0.6666667  0.         ... 0.         0.5984252  0.5685941 ]\n",
      "  [0.57225436 0.75       0.         ... 0.         0.6929134  0.79818594]\n",
      "  [0.4566474  0.75       0.         ... 0.         0.63779527 0.54039115]\n",
      "  ...\n",
      "  [0.42196533 0.25       0.         ... 0.         0.56692916 0.56646824]\n",
      "  [0.5317919  0.9166667  0.         ... 0.         0.5984252  0.7549603 ]\n",
      "  [0.5953757  0.8333333  0.         ... 0.         0.48031497 0.5188492 ]]]\n",
      "(110, 25)\n",
      "seq_array_test_k:  [[[0.53757226 0.8333333  0.         ... 0.         0.42519686 0.5911281 ]\n",
      "  [0.28901735 0.25       0.         ... 0.         0.7322835  0.52621883]\n",
      "  [0.6416185  0.8333333  0.         ... 0.         0.70866144 0.6802721 ]\n",
      "  ...\n",
      "  [0.2947977  0.5        0.         ... 0.         0.511811   0.45408162]\n",
      "  [0.46242774 0.6666667  0.         ... 0.         0.48818898 0.48497733]\n",
      "  [0.6300578  0.5833333  0.         ... 0.         0.6062992  0.5       ]]]\n",
      "(120, 25)\n",
      "seq_array_test_k:  [[[0.4566474  0.6666667  0.         ... 0.         0.62992126 0.5334467 ]\n",
      "  [0.5433526  0.75       0.         ... 0.         0.61417323 0.59382087]\n",
      "  [0.19653179 0.16666667 0.         ... 0.         0.7559055  0.51785713]\n",
      "  ...\n",
      "  [0.5086705  0.5        0.         ... 0.         0.4566929  0.43310657]\n",
      "  [0.42196533 0.6666667  0.         ... 0.         0.52755904 0.29280046]\n",
      "  [0.43930635 0.5833333  0.         ... 0.         0.5511811  0.5114796 ]]]\n",
      "(130, 25)\n",
      "seq_array_test_k:  [[[0.58381504 0.8333333  0.         ... 0.         0.46456692 0.6135204 ]\n",
      "  [0.46242774 0.16666667 0.         ... 0.         0.5590551  0.68339   ]\n",
      "  [0.5202312  0.5833333  0.         ... 0.         0.5826772  0.6493764 ]\n",
      "  ...\n",
      "  [0.3583815  0.5        0.         ... 0.         0.46456692 0.5734127 ]\n",
      "  [0.5895954  0.33333334 0.         ... 0.         0.6062992  0.53713155]\n",
      "  [0.4566474  0.9166667  0.         ... 0.         0.28346458 0.5419501 ]]]\n",
      "(140, 25)\n",
      "seq_array_test_k:  [[[0.54913294 0.25       0.         ... 0.         0.68503934 0.579932  ]\n",
      "  [0.78612715 0.6666667  0.         ... 0.         0.5590551  0.79124147]\n",
      "  [0.3583815  0.6666667  0.         ... 0.         0.496063   0.6771542 ]\n",
      "  ...\n",
      "  [0.5260116  0.33333334 0.         ... 0.         0.2519685  0.37414965]\n",
      "  [0.5895954  0.8333333  0.         ... 0.         0.42519686 0.5130386 ]\n",
      "  [0.51445085 0.33333334 0.         ... 0.         0.33858266 0.21329366]]]\n",
      "(150, 25)\n",
      "seq_array_test_k:  [[[0.39306358 0.9166667  0.         ... 0.         0.51968503 0.5966553 ]\n",
      "  [0.40462428 0.6666667  0.         ... 0.         0.56692916 0.47845805]\n",
      "  [0.65317917 0.33333334 0.         ... 0.         0.5826772  0.5248016 ]\n",
      "  ...\n",
      "  [0.1618497  0.16666667 0.         ... 0.         0.33070865 0.30286282]\n",
      "  [0.60115606 0.5833333  0.         ... 0.         0.28346458 0.19997166]\n",
      "  [0.35260117 0.6666667  0.         ... 0.         0.2913386  0.22236395]]]\n",
      "(50, 25)\n",
      "seq_array_test_k:  [[[0.5780347  0.41666666 0.         ... 0.         0.51968503 0.67814624]\n",
      "  [0.36416185 0.5        0.         ... 0.         0.503937   0.6594388 ]\n",
      "  [0.5317919  0.08333334 0.         ... 0.         0.44094488 0.60345805]\n",
      "  ...\n",
      "  [0.4913295  0.16666667 0.         ... 0.         0.6771653  0.5630669 ]\n",
      "  [0.49710983 0.33333334 0.         ... 0.         0.46456692 0.6186224 ]\n",
      "  [0.48554912 0.25       0.         ... 0.         0.51968503 0.5202664 ]]]\n",
      "(60, 25)\n",
      "seq_array_test_k:  [[[0.45086706 0.5        0.         ... 0.         0.511811   0.47704083]\n",
      "  [0.31213874 0.08333334 0.         ... 0.         0.52755904 0.6585884 ]\n",
      "  [0.45086706 0.75       0.         ... 0.         0.511811   0.58985263]\n",
      "  ...\n",
      "  [0.50289017 0.08333334 0.         ... 0.         0.62204725 0.5002834 ]\n",
      "  [0.6069364  0.08333334 0.         ... 0.         0.42519686 0.49645692]\n",
      "  [0.6416185  0.5833333  0.         ... 0.         0.54330707 0.5841837 ]]]\n",
      "(70, 25)\n",
      "seq_array_test_k:  [[[0.53757226 0.5        0.         ... 0.         0.6771653  0.49617347]\n",
      "  [0.35260117 0.41666666 0.         ... 0.         0.54330707 0.5868764 ]\n",
      "  [0.54913294 0.5        0.         ... 0.         0.70866144 0.60289115]\n",
      "  ...\n",
      "  [0.60115606 0.6666667  0.         ... 0.         0.5984252  0.4387755 ]\n",
      "  [0.4566474  0.5        0.         ... 0.         0.5984252  0.56930274]\n",
      "  [0.49710983 0.25       0.         ... 0.         0.42519686 0.42219388]]]\n",
      "(80, 25)\n",
      "seq_array_test_k:  [[[0.76878613 0.41666666 0.         ... 0.         0.44094488 0.44373584]\n",
      "  [0.39306358 0.8333333  0.         ... 0.         0.51968503 0.61763036]\n",
      "  [0.28901735 0.33333334 0.         ... 0.         0.496063   0.4794501 ]\n",
      "  ...\n",
      "  [0.2947977  0.08333334 0.         ... 0.         0.503937   0.53245467]\n",
      "  [0.72254336 0.25       0.         ... 0.         0.4566929  0.5933957 ]\n",
      "  [0.42774567 0.33333334 0.         ... 0.         0.43307087 0.618339  ]]]\n",
      "(90, 25)\n",
      "seq_array_test_k:  [[[0.58381504 0.5        0.         ... 0.         0.44094488 0.50042516]\n",
      "  [0.5780347  0.75       0.         ... 0.         0.51968503 0.40575397]\n",
      "  [0.39306358 0.8333333  0.         ... 0.         0.48818898 0.5534297 ]\n",
      "  ...\n",
      "  [0.26589596 0.5833333  0.         ... 0.         0.48031497 0.6038832 ]\n",
      "  [0.4913295  0.08333334 0.         ... 0.         0.35433072 0.52763605]\n",
      "  [0.3699422  0.75       0.         ... 0.         0.48031497 0.63732994]]]\n",
      "(100, 25)\n",
      "seq_array_test_k:  [[[0.5260116  0.8333333  0.         ... 0.         0.5984252  0.5986394 ]\n",
      "  [0.31791908 0.75       0.         ... 0.         0.54330707 0.4988662 ]\n",
      "  [0.5549133  0.33333334 0.         ... 0.         0.5748032  0.37174037]\n",
      "  ...\n",
      "  [0.63583815 0.6666667  0.         ... 0.         0.40944883 0.5263606 ]\n",
      "  [0.51445085 0.5        0.         ... 0.         0.48031497 0.45124716]\n",
      "  [0.43930635 0.75       0.         ... 0.         0.5748032  0.46215987]]]\n",
      "(110, 25)\n",
      "seq_array_test_k:  [[[0.51445085 0.16666667 0.         ... 0.         0.7322835  0.44912133]\n",
      "  [0.6416185  0.16666667 0.         ... 0.         0.5590551  0.6055839 ]\n",
      "  [0.47976878 0.41666666 0.         ... 0.         0.47244096 0.48993763]\n",
      "  ...\n",
      "  [0.6242775  0.33333334 0.         ... 0.         0.48031497 0.50411   ]\n",
      "  [0.33526012 0.25       0.         ... 0.         0.48031497 0.41057256]\n",
      "  [0.57225436 0.8333333  0.         ... 0.         0.5590551  0.55257934]]]\n",
      "(120, 25)\n",
      "seq_array_test_k:  [[[0.69942194 0.5833333  0.         ... 0.         0.6929134  0.48171768]\n",
      "  [0.37572256 0.41666666 0.         ... 0.         0.4566929  0.44614512]\n",
      "  [0.72254336 0.75       0.         ... 0.         0.56692916 0.70209754]\n",
      "  ...\n",
      "  [0.41040462 0.25       0.         ... 0.         0.4566929  0.5334467 ]\n",
      "  [0.58381504 0.6666667  0.         ... 0.         0.6456693  0.5697279 ]\n",
      "  [0.39884394 0.5833333  0.         ... 0.         0.6535433  0.46513605]]]\n",
      "(130, 25)\n",
      "seq_array_test_k:  [[[0.31213874 0.75       0.         ... 0.         0.5511811  0.50821996]\n",
      "  [0.3583815  0.75       0.         ... 0.         0.56692916 0.55201244]\n",
      "  [0.38728324 0.8333333  0.         ... 0.         0.54330707 0.5168651 ]\n",
      "  ...\n",
      "  [0.56647396 0.16666667 0.         ... 0.         0.4566929  0.4501134 ]\n",
      "  [0.50289017 0.16666667 0.         ... 0.         0.496063   0.60402495]\n",
      "  [0.5549133  0.41666666 0.         ... 0.         0.5826772  0.6339286 ]]]\n",
      "(140, 25)\n",
      "seq_array_test_k:  [[[0.41618496 0.41666666 0.         ... 0.         0.30708662 0.44685373]\n",
      "  [0.5202312  0.5        0.         ... 0.         0.5748032  0.54237527]\n",
      "  [0.5780347  0.5833333  0.         ... 0.         0.4488189  0.36678004]\n",
      "  ...\n",
      "  [0.42774567 0.6666667  0.         ... 0.         0.511811   0.5       ]\n",
      "  [0.6763006  0.25       0.         ... 0.         0.61417323 0.59126985]\n",
      "  [0.5895954  0.25       0.         ... 0.         0.51968503 0.4713719 ]]]\n",
      "(150, 25)\n",
      "seq_array_test_k:  [[[0.53757226 0.33333334 0.         ... 0.         0.56692916 0.35274944]\n",
      "  [0.30635837 0.5        0.         ... 0.         0.42519686 0.4369331 ]\n",
      "  [0.42774567 0.33333334 0.         ... 0.         0.4488189  0.5915533 ]\n",
      "  ...\n",
      "  [0.6300578  0.41666666 0.         ... 0.         0.5905512  0.44132653]\n",
      "  [0.4682081  0.75       0.         ... 0.         0.51968503 0.43835035]\n",
      "  [0.51445085 0.5        0.         ... 0.         0.4566929  0.60175735]]]\n",
      "(160, 25)\n",
      "seq_array_test_k:  [[[0.6069364  0.25       0.         ... 0.         0.48818898 0.4084467 ]\n",
      "  [0.54913294 0.33333334 0.         ... 0.         0.4566929  0.579932  ]\n",
      "  [0.41040462 0.33333334 0.         ... 0.         0.56692916 0.43494898]\n",
      "  ...\n",
      "  [0.3815029  0.41666666 0.         ... 0.         0.5748032  0.4532313 ]\n",
      "  [0.2601156  0.8333333  0.         ... 0.         0.496063   0.52012473]\n",
      "  [0.37572256 0.25       0.         ... 0.         0.41732284 0.66822565]]]\n",
      "(170, 25)\n",
      "seq_array_test_k:  [[[0.57225436 0.08333334 0.         ... 0.         0.40944883 0.54294217]\n",
      "  [0.47976878 0.6666667  0.         ... 0.         0.6614173  0.6327948 ]\n",
      "  [0.47976878 0.41666666 0.         ... 0.         0.6062992  0.41539115]\n",
      "  ...\n",
      "  [0.4566474  0.75       0.         ... 0.         0.4488189  0.5121882 ]\n",
      "  [0.23121387 0.25       0.         ... 0.         0.54330707 0.4727891 ]\n",
      "  [0.72254336 0.41666666 0.         ... 0.         0.496063   0.5097789 ]]]\n",
      "(180, 25)\n",
      "seq_array_test_k:  [[[0.51445085 0.6666667  0.         ... 0.         0.39370078 0.60232425]\n",
      "  [0.44508672 0.16666667 0.         ... 0.         0.511811   0.5127551 ]\n",
      "  [0.46242774 0.8333333  0.         ... 0.         0.4488189  0.33545917]\n",
      "  ...\n",
      "  [0.47398844 0.75       0.         ... 0.         0.48031497 0.59382087]\n",
      "  [0.5606936  0.9166667  0.         ... 0.         0.40944883 0.4509637 ]\n",
      "  [0.42774567 0.6666667  0.         ... 0.         0.54330707 0.49787414]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(190, 25)\n",
      "seq_array_test_k:  [[[0.6473988  0.41666666 0.         ... 0.         0.35433072 0.551729  ]\n",
      "  [0.3583815  0.5        0.         ... 0.         0.511811   0.52324265]\n",
      "  [0.42196533 0.16666667 0.         ... 0.         0.7007874  0.58531743]\n",
      "  ...\n",
      "  [0.53757226 0.16666667 0.         ... 0.         0.52755904 0.430839  ]\n",
      "  [0.21387284 0.33333334 0.         ... 0.         0.44094488 0.33673468]\n",
      "  [0.6589595  0.5        0.         ... 0.         0.46456692 0.41326532]]]\n",
      "(200, 25)\n",
      "seq_array_test_k:  [[[0.47398844 0.5        0.         ... 0.         0.51968503 0.5283447 ]\n",
      "  [0.63583815 0.8333333  0.         ... 0.         0.41732284 0.46570295]\n",
      "  [0.37572256 0.16666667 0.         ... 0.         0.511811   0.55073696]\n",
      "  ...\n",
      "  [0.42774567 0.8333333  0.         ... 0.         0.39370078 0.5442177 ]\n",
      "  [0.58381504 0.16666667 0.         ... 0.         0.27559054 0.35473356]\n",
      "  [0.5433526  0.8333333  0.         ... 0.         0.47244096 0.4744898 ]]]\n",
      "(210, 25)\n",
      "seq_array_test_k:  [[[0.35260117 0.16666667 0.         ... 0.         0.52755904 0.40121883]\n",
      "  [0.3815029  0.5        0.         ... 0.         0.44094488 0.4204932 ]\n",
      "  [0.37572256 0.33333334 0.         ... 0.         0.46456692 0.5035431 ]\n",
      "  ...\n",
      "  [0.54913294 0.25       0.         ... 0.         0.27559054 0.2548186 ]\n",
      "  [0.27745664 0.5        0.         ... 0.         0.48818898 0.46683672]\n",
      "  [0.5433526  0.75       0.         ... 0.         0.4488189  0.36437073]]]\n",
      "(220, 25)\n",
      "seq_array_test_k:  [[[0.30635837 0.25       0.         ... 0.         0.19685039 0.41893423]\n",
      "  [0.6820809  0.6666667  0.         ... 0.         0.56692916 0.651644  ]\n",
      "  [0.57225436 0.6666667  0.         ... 0.         0.33858266 0.48710316]\n",
      "  ...\n",
      "  [0.51445085 0.8333333  0.         ... 0.         0.47244096 0.5002834 ]\n",
      "  [0.6763006  0.25       0.         ... 0.         0.30708662 0.29776078]\n",
      "  [0.56647396 0.8333333  0.         ... 0.         0.39370078 0.37046486]]]\n",
      "(230, 25)\n",
      "seq_array_test_k:  [[[0.42196533 0.6666667  0.         ... 0.         0.41732284 0.45252267]\n",
      "  [0.42196533 0.41666666 0.         ... 0.         0.38582677 0.59963155]\n",
      "  [0.46242774 0.33333334 0.         ... 0.         0.46456692 0.52650225]\n",
      "  ...\n",
      "  [0.41618496 0.5833333  0.         ... 0.         0.35433072 0.45677438]\n",
      "  [0.46242774 0.6666667  0.         ... 0.         0.23622048 0.37811792]\n",
      "  [0.61271673 0.25       0.         ... 0.         0.31496063 0.5069444 ]]]\n",
      "(240, 25)\n",
      "seq_array_test_k:  [[[0.5317919  0.16666667 0.         ... 0.         0.4566929  0.44274378]\n",
      "  [0.67052025 0.5833333  0.         ... 0.         0.48818898 0.506661  ]\n",
      "  [0.5895954  0.33333334 0.         ... 0.         0.47244096 0.53316325]\n",
      "  ...\n",
      "  [0.47398844 0.8333333  0.         ... 0.         0.47244096 0.3605442 ]\n",
      "  [0.2947977  0.6666667  0.         ... 0.         0.33858266 0.26658162]\n",
      "  [0.48554912 0.41666666 0.         ... 0.         0.22834645 0.39469954]]]\n",
      "(250, 25)\n",
      "seq_array_test_k:  [[[0.43930635 0.5833333  0.         ... 0.         0.511811   0.44940478]\n",
      "  [0.39884394 0.08333334 0.         ... 0.         0.41732284 0.5419501 ]\n",
      "  [0.50289017 0.5        0.         ... 0.         0.3464567  0.23200114]\n",
      "  ...\n",
      "  [0.34104046 0.33333334 0.         ... 0.         0.38582677 0.29634354]\n",
      "  [0.6300578  0.16666667 0.         ... 0.         0.25984251 0.2705499 ]\n",
      "  [0.54913294 0.5        0.         ... 0.         0.06299213 0.24248867]]]\n",
      "(50, 25)\n",
      "seq_array_test_k:  [[[0.53757226 0.25       0.         ... 0.         0.6456693  0.7670068 ]\n",
      "  [0.4566474  0.75       0.         ... 0.         0.5984252  0.6560374 ]\n",
      "  [0.42774567 0.33333334 0.         ... 0.         0.5826772  0.6989796 ]\n",
      "  ...\n",
      "  [0.5317919  0.6666667  0.         ... 0.         0.5590551  0.7497166 ]\n",
      "  [0.6589595  0.33333334 0.         ... 0.         0.54330707 0.5416667 ]\n",
      "  [0.5202312  0.08333334 0.         ... 0.         0.6535433  0.7080499 ]]]\n",
      "(60, 25)\n",
      "seq_array_test_k:  [[[0.2716763  0.8333333  0.         ... 0.         0.8110236  0.73511904]\n",
      "  [0.46242774 0.6666667  0.         ... 0.         0.43307087 0.703373  ]\n",
      "  [0.5317919  0.75       0.         ... 0.         0.7322835  0.7436224 ]\n",
      "  ...\n",
      "  [0.43930635 0.75       0.         ... 0.         0.6614173  0.8874717 ]\n",
      "  [0.6936416  0.5        0.         ... 0.         0.71653545 0.74489796]\n",
      "  [0.50289017 0.25       0.         ... 0.         0.77952754 0.7444728 ]]]\n",
      "(70, 25)\n",
      "seq_array_test_k:  [[[0.5202312  0.6666667  0.         ... 0.         0.70866144 0.80187076]\n",
      "  [0.78612715 0.41666666 0.         ... 0.         0.68503934 0.7630386 ]\n",
      "  [0.37572256 0.5833333  0.         ... 0.         0.62204725 0.66850907]\n",
      "  ...\n",
      "  [0.42196533 0.33333334 0.         ... 0.         0.71653545 0.8348923 ]\n",
      "  [0.6589595  0.41666666 0.         ... 0.         0.70866144 0.5668934 ]\n",
      "  [0.6242775  0.6666667  0.         ... 0.         0.6456693  0.6485261 ]]]\n",
      "(80, 25)\n",
      "seq_array_test_k:  [[[0.39306358 0.75       0.         ... 0.         0.6456693  0.6590136 ]\n",
      "  [0.2716763  0.5833333  0.         ... 0.         0.5905512  0.6794218 ]\n",
      "  [0.5895954  0.16666667 0.         ... 0.         0.7480315  0.76459754]\n",
      "  ...\n",
      "  [0.67052025 0.25       0.         ... 0.         0.8346457  0.7215136 ]\n",
      "  [0.63583815 0.5        0.         ... 0.         0.77952754 0.5939626 ]\n",
      "  [0.42196533 0.75       0.         ... 0.         0.6771653  0.7828798 ]]]\n",
      "(90, 25)\n",
      "seq_array_test_k:  [[[0.61271673 0.25       0.         ... 0.         0.68503934 0.63123584]\n",
      "  [0.40462428 0.41666666 0.         ... 0.         0.5748032  0.7348356 ]\n",
      "  [0.4566474  0.16666667 0.         ... 0.         0.62992126 0.8669218 ]\n",
      "  ...\n",
      "  [0.5260116  0.25       0.         ... 0.         0.62992126 0.6571712 ]\n",
      "  [0.6473988  0.41666666 0.         ... 0.         0.7007874  0.649093  ]\n",
      "  [0.51445085 0.8333333  0.         ... 0.         0.5984252  0.72845805]]]\n",
      "(100, 25)\n",
      "seq_array_test_k:  [[[0.6242775  0.16666667 0.         ... 0.         0.62204725 0.86734694]\n",
      "  [0.28901735 0.33333334 0.         ... 0.         0.70866144 0.75651926]\n",
      "  [0.7109827  0.25       0.         ... 0.         0.6535433  0.66298187]\n",
      "  ...\n",
      "  [0.42196533 0.9166667  0.         ... 0.         0.6929134  0.5752551 ]\n",
      "  [0.58381504 0.8333333  0.         ... 0.         0.6535433  0.8408447 ]\n",
      "  [0.5433526  0.5833333  0.         ... 0.         0.5984252  0.6072846 ]]]\n",
      "(110, 25)\n",
      "seq_array_test_k:  [[[0.3583815  0.25       0.         ... 0.         0.63779527 0.7104592 ]\n",
      "  [0.25433525 0.6666667  0.         ... 0.         0.56692916 0.52947843]\n",
      "  [0.34104046 0.33333334 0.         ... 0.         0.6771653  0.62840134]\n",
      "  ...\n",
      "  [0.5202312  0.9166667  0.         ... 0.         0.6929134  0.7708333 ]\n",
      "  [0.45086706 0.75       0.         ... 0.         0.72440946 0.7427721 ]\n",
      "  [0.57225436 0.16666667 0.         ... 0.         0.48818898 0.6255669 ]]]\n",
      "(120, 25)\n",
      "seq_array_test_k:  [[[0.3583815  0.5        0.         ... 0.         0.70866144 0.76729023]\n",
      "  [0.46242774 0.5833333  0.         ... 0.         0.7559055  0.69033444]\n",
      "  [0.5780347  0.6666667  0.         ... 0.         0.5984252  0.58290815]\n",
      "  ...\n",
      "  [0.57225436 0.08333334 0.         ... 0.         0.7401575  0.7202381 ]\n",
      "  [0.39884394 0.5        0.         ... 0.         0.5826772  0.6797052 ]\n",
      "  [0.3236994  0.33333334 0.         ... 0.         0.5984252  0.6811224 ]]]\n",
      "(130, 25)\n",
      "seq_array_test_k:  [[[0.39884394 0.6666667  0.         ... 0.         0.6771653  0.7063492 ]\n",
      "  [0.3583815  0.25       0.         ... 0.         0.6062992  0.7752268 ]\n",
      "  [0.47398844 0.8333333  0.         ... 0.         0.7322835  0.6327948 ]\n",
      "  ...\n",
      "  [0.56647396 0.5833333  0.         ... 0.         0.6771653  0.6614229 ]\n",
      "  [0.30635837 0.5833333  0.         ... 0.         0.6535433  0.53656465]\n",
      "  [0.6069364  0.6666667  0.         ... 0.         0.62204725 0.51062924]]]\n",
      "(140, 25)\n",
      "seq_array_test_k:  [[[0.41040462 0.75       0.         ... 0.         0.6535433  0.57738096]\n",
      "  [0.23699422 0.5833333  0.         ... 0.         0.56692916 0.56094104]\n",
      "  [0.5433526  0.75       0.         ... 0.         0.72440946 0.7439059 ]\n",
      "  ...\n",
      "  [0.7630058  0.8333333  0.         ... 0.         0.62204725 0.65178573]\n",
      "  [0.433526   0.25       0.         ... 0.         0.47244096 0.79790246]\n",
      "  [0.36416185 0.9166667  0.         ... 0.         0.5905512  0.7222222 ]]]\n",
      "(150, 25)\n",
      "seq_array_test_k:  [[[0.2716763  0.5        0.         ... 0.         0.56692916 0.7796202 ]\n",
      "  [0.5780347  0.08333334 0.         ... 0.         0.6771653  0.67020977]\n",
      "  [0.42196533 0.33333334 0.         ... 0.         0.6692913  0.74461454]\n",
      "  ...\n",
      "  [0.6242775  0.5        0.         ... 0.         0.7401575  0.5763889 ]\n",
      "  [0.3583815  0.25       0.         ... 0.         0.61417323 0.6472506 ]\n",
      "  [0.5260116  0.33333334 0.         ... 0.         0.7637795  0.801729  ]]]\n",
      "(160, 25)\n",
      "seq_array_test_k:  [[[0.6589595  0.5        0.         ... 0.         0.70866144 0.60459185]\n",
      "  [0.4566474  0.5833333  0.         ... 0.         0.5511811  0.78798187]\n",
      "  [0.44508672 0.5833333  0.         ... 0.         0.6062992  0.7022392 ]\n",
      "  ...\n",
      "  [0.6416185  0.75       0.         ... 0.         0.56692916 0.83290815]\n",
      "  [0.7514451  0.75       0.         ... 0.         0.511811   0.7171202 ]\n",
      "  [0.45086706 0.5        0.         ... 0.         0.5984252  0.6897676 ]]]\n",
      "(170, 25)\n",
      "seq_array_test_k:  [[[0.39884394 0.33333334 0.         ... 0.         0.6692913  0.58460885]\n",
      "  [0.8265896  0.08333334 0.         ... 0.         0.6692913  0.6427154 ]\n",
      "  [0.4913295  0.5833333  0.         ... 0.         0.61417323 0.6047336 ]\n",
      "  ...\n",
      "  [0.54913294 0.16666667 0.         ... 0.         0.5826772  0.5471939 ]\n",
      "  [0.49710983 0.08333334 0.         ... 0.         0.6535433  0.49744898]\n",
      "  [0.5895954  0.25       0.         ... 0.         0.5826772  0.63010204]]]\n",
      "(180, 25)\n",
      "seq_array_test_k:  [[[0.28901735 0.16666667 0.         ... 0.         0.5826772  0.6955782 ]\n",
      "  [0.58381504 0.6666667  0.         ... 0.         0.5905512  0.65873015]\n",
      "  [0.5202312  0.41666666 0.         ... 0.         0.7401575  0.6164966 ]\n",
      "  ...\n",
      "  [0.6763006  0.41666666 0.         ... 0.         0.5905512  0.6958617 ]\n",
      "  [0.6763006  0.6666667  0.         ... 0.         0.51968503 0.6588719 ]\n",
      "  [0.4566474  0.5        0.         ... 0.         0.53543305 0.55017006]]]\n",
      "(190, 25)\n",
      "seq_array_test_k:  [[[0.37572256 0.9166667  0.         ... 0.         0.77952754 0.59311223]\n",
      "  [0.433526   0.25       0.         ... 0.         0.62992126 0.711593  ]\n",
      "  [0.5780347  0.6666667  0.         ... 0.         0.62204725 0.6924603 ]\n",
      "  ...\n",
      "  [0.33526012 0.6666667  0.         ... 0.         0.62992126 0.5804989 ]\n",
      "  [0.67052025 0.6666667  0.         ... 0.         0.496063   0.57865644]\n",
      "  [0.5433526  0.33333334 0.         ... 0.         0.6614173  0.4944728 ]]]\n",
      "(200, 25)\n",
      "seq_array_test_k:  [[[0.56647396 0.6666667  0.         ... 0.         0.6614173  0.51927435]\n",
      "  [0.5549133  0.33333334 0.         ... 0.         0.6062992  0.79350907]\n",
      "  [0.17919075 0.25       0.         ... 0.         0.6614173  0.7277494 ]\n",
      "  ...\n",
      "  [0.57225436 0.41666666 0.         ... 0.         0.52755904 0.64597505]\n",
      "  [0.53757226 0.25       0.         ... 0.         0.4566929  0.58630955]\n",
      "  [0.50289017 0.8333333  0.         ... 0.         0.51968503 0.47420636]]]\n",
      "(210, 25)\n",
      "seq_array_test_k:  [[[0.41040462 0.8333333  0.         ... 0.         0.61417323 0.4356576 ]\n",
      "  [0.41618496 0.5        0.         ... 0.         0.7007874  0.5746882 ]\n",
      "  [0.38728324 0.75       0.         ... 0.         0.6614173  0.52508503]\n",
      "  ...\n",
      "  [0.6416185  0.75       0.         ... 0.         0.511811   0.4934807 ]\n",
      "  [0.5317919  0.6666667  0.         ... 0.         0.54330707 0.70464855]\n",
      "  [0.39884394 0.5        0.         ... 0.         0.40944883 0.56590134]]]\n",
      "(220, 25)\n",
      "seq_array_test_k:  [[[0.5202312  0.41666666 0.         ... 0.         0.7007874  0.72208047]\n",
      "  [0.65317917 0.8333333  0.         ... 0.         0.5905512  0.694161  ]\n",
      "  [0.25433525 0.5833333  0.         ... 0.         0.5826772  0.7560941 ]\n",
      "  ...\n",
      "  [0.2601156  0.25       0.         ... 0.         0.39370078 0.59793085]\n",
      "  [0.25433525 0.8333333  0.         ... 0.         0.5590551  0.55711454]\n",
      "  [0.49710983 0.8333333  0.         ... 0.         0.5511811  0.3955499 ]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(230, 25)\n",
      "seq_array_test_k:  [[[0.72254336 0.41666666 0.         ... 0.         0.46456692 0.5922619 ]\n",
      "  [0.6936416  0.25       0.         ... 0.         0.61417323 0.55598074]\n",
      "  [0.53757226 0.8333333  0.         ... 0.         0.62992126 0.68905896]\n",
      "  ...\n",
      "  [0.43930635 0.5833333  0.         ... 0.         0.36220473 0.45223922]\n",
      "  [0.56647396 0.75       0.         ... 0.         0.48031497 0.54322565]\n",
      "  [0.40462428 0.75       0.         ... 0.         0.48031497 0.3761338 ]]]\n",
      "(240, 25)\n",
      "seq_array_test_k:  [[[0.5549133  0.41666666 0.         ... 0.         0.6535433  0.6353458 ]\n",
      "  [0.2601156  0.6666667  0.         ... 0.         0.6062992  0.64342403]\n",
      "  [0.44508672 0.75       0.         ... 0.         0.42519686 0.80300456]\n",
      "  ...\n",
      "  [0.30635837 0.9166667  0.         ... 0.         0.3464567  0.5647676 ]\n",
      "  [0.30635837 0.5        0.         ... 0.         0.5826772  0.35870183]\n",
      "  [0.5260116  0.75       0.         ... 0.         0.35433072 0.54294217]]]\n",
      "(250, 25)\n",
      "seq_array_test_k:  [[[0.61271673 0.08333334 0.         ... 0.         0.6062992  0.56519276]\n",
      "  [0.38728324 0.75       0.         ... 0.         0.5511811  0.43480727]\n",
      "  [0.35260117 0.5833333  0.         ... 0.         0.5511811  0.6231576 ]\n",
      "  ...\n",
      "  [0.28901735 0.5        0.         ... 0.         0.43307087 0.44331065]\n",
      "  [0.3815029  0.25       0.         ... 0.         0.53543305 0.3289399 ]\n",
      "  [0.21387284 0.25       0.         ... 0.         0.36220473 0.48752835]]]\n",
      "(260, 25)\n",
      "seq_array_test_k:  [[[0.5433526  0.33333334 0.         ... 0.         0.5984252  0.5442177 ]\n",
      "  [0.58381504 0.25       0.         ... 0.         0.4566929  0.3197279 ]\n",
      "  [0.58381504 0.9166667  0.         ... 0.         0.44094488 0.46159297]\n",
      "  ...\n",
      "  [0.58381504 0.9166667  0.         ... 0.         0.4015748  0.3538832 ]\n",
      "  [0.4913295  0.9166667  0.         ... 0.         0.2992126  0.47675738]\n",
      "  [0.5202312  0.5        0.         ... 0.         0.23622048 0.47463152]]]\n",
      "(270, 25)\n",
      "seq_array_test_k:  [[[0.6242775  0.5        0.         ... 0.         0.40944883 0.6464002 ]\n",
      "  [0.33526012 0.75       0.         ... 0.         0.42519686 0.5214002 ]\n",
      "  [0.73410404 0.75       0.         ... 0.         0.47244096 0.49787414]\n",
      "  ...\n",
      "  [0.61849713 0.25       0.         ... 0.         0.33858266 0.36082765]\n",
      "  [0.2947977  0.8333333  0.         ... 0.         0.32283464 0.3106576 ]\n",
      "  [0.38728324 0.5833333  0.         ... 0.         0.28346458 0.4576247 ]]]\n",
      "(280, 25)\n",
      "seq_array_test_k:  [[[0.60115606 0.41666666 0.         ... 0.         0.39370078 0.41128117]\n",
      "  [0.49710983 0.33333334 0.         ... 0.         0.38582677 0.50042516]\n",
      "  [0.5260116  0.16666667 0.         ... 0.         0.43307087 0.5527211 ]\n",
      "  ...\n",
      "  [0.3699422  0.16666667 0.         ... 0.         0.16535433 0.23270975]\n",
      "  [0.45086706 0.5        0.         ... 0.         0.23622048 0.37641722]\n",
      "  [0.433526   0.16666667 0.         ... 0.         0.22047244 0.29563493]]]\n",
      "(50, 25)\n",
      "seq_array_test_k:  [[[0.41618496 0.16666667 0.         ... 0.         0.51968503 0.72378117]\n",
      "  [0.5202312  0.33333334 0.         ... 0.         0.6692913  0.6397392 ]\n",
      "  [0.46242774 0.75       0.         ... 0.         0.5905512  0.60515875]\n",
      "  ...\n",
      "  [0.3583815  0.75       0.         ... 0.         0.62992126 0.49631518]\n",
      "  [0.47398844 0.75       0.         ... 0.         0.6929134  0.8707483 ]\n",
      "  [0.433526   0.08333334 0.         ... 0.         0.53543305 0.60119045]]]\n",
      "(60, 25)\n",
      "seq_array_test_k:  [[[0.4682081  0.41666666 0.         ... 0.         0.5984252  0.69954646]\n",
      "  [0.716763   0.5        0.         ... 0.         0.62204725 0.72675735]\n",
      "  [0.41040462 0.41666666 0.         ... 0.         0.6062992  0.5497449 ]\n",
      "  ...\n",
      "  [0.6069364  0.16666667 0.         ... 0.         0.68503934 0.5462018 ]\n",
      "  [0.42774567 0.9166667  0.         ... 0.         0.6062992  0.6539116 ]\n",
      "  [0.44508672 0.5        0.         ... 0.         0.6535433  0.7536848 ]]]\n",
      "(70, 25)\n",
      "seq_array_test_k:  [[[0.28323698 0.9166667  0.         ... 0.         0.62992126 0.65688777]\n",
      "  [0.3699422  0.6666667  0.         ... 0.         0.48031497 0.57128686]\n",
      "  [0.5086705  0.5        0.         ... 0.         0.5511811  0.752551  ]\n",
      "  ...\n",
      "  [0.5317919  0.5833333  0.         ... 0.         0.70866144 0.65617913]\n",
      "  [0.6069364  0.6666667  0.         ... 0.         0.68503934 0.70705783]\n",
      "  [0.30635837 0.08333334 0.         ... 0.         0.71653545 0.5588152 ]]]\n",
      "(80, 25)\n",
      "seq_array_test_k:  [[[0.5202312  0.9166667  0.         ... 0.         0.6062992  0.8106576 ]\n",
      "  [0.23699422 0.16666667 0.         ... 0.         0.63779527 0.6267007 ]\n",
      "  [0.6069364  0.5        0.         ... 0.         0.6614173  0.64880955]\n",
      "  ...\n",
      "  [0.5317919  0.16666667 0.         ... 0.         0.51968503 0.65150225]\n",
      "  [0.4566474  0.25       0.         ... 0.         0.6929134  0.5297619 ]\n",
      "  [0.61849713 0.8333333  0.         ... 0.         0.5984252  0.5102041 ]]]\n",
      "(90, 25)\n",
      "seq_array_test_k:  [[[0.44508672 0.08333334 0.         ... 0.         0.5984252  0.836593  ]\n",
      "  [0.44508672 0.16666667 0.         ... 0.         0.5905512  0.69869614]\n",
      "  [0.63583815 0.9166667  0.         ... 0.         0.503937   0.53599775]\n",
      "  ...\n",
      "  [0.3815029  0.25       0.         ... 0.         0.7480315  0.6432823 ]\n",
      "  [0.47398844 0.8333333  0.         ... 0.         0.5748032  0.7718254 ]\n",
      "  [0.56647396 0.25       0.         ... 0.         0.6456693  0.5022676 ]]]\n",
      "(100, 25)\n",
      "seq_array_test_k:  [[[0.48554912 0.5833333  0.         ... 0.         0.79527557 0.60515875]\n",
      "  [0.41618496 0.75       0.         ... 0.         0.7401575  0.70620745]\n",
      "  [0.53757226 0.6666667  0.         ... 0.         0.6062992  0.71938777]\n",
      "  ...\n",
      "  [0.49710983 0.33333334 0.         ... 0.         0.6771653  0.59070295]\n",
      "  [0.56647396 0.16666667 0.         ... 0.         0.7559055  0.49914965]\n",
      "  [0.47398844 0.5833333  0.         ... 0.         0.70866144 0.61451244]]]\n",
      "(110, 25)\n",
      "seq_array_test_k:  [[[0.5895954  0.41666666 0.         ... 0.         0.5590551  0.6758787 ]\n",
      "  [0.43930635 0.41666666 0.         ... 0.         0.68503934 0.6499433 ]\n",
      "  [0.5895954  0.41666666 0.         ... 0.         0.52755904 0.64115644]\n",
      "  ...\n",
      "  [0.50289017 0.75       0.         ... 0.         0.48818898 0.6750283 ]\n",
      "  [0.42774567 0.5833333  0.         ... 0.         0.54330707 0.62769276]\n",
      "  [0.69942194 0.5833333  0.         ... 0.         0.6692913  0.54634356]]]\n",
      "(120, 25)\n",
      "seq_array_test_k:  [[[0.50289017 0.41666666 0.         ... 0.         0.5748032  0.6789966 ]\n",
      "  [0.46242774 0.41666666 0.         ... 0.         0.5511811  0.67077667]\n",
      "  [0.4682081  0.8333333  0.         ... 0.         0.62992126 0.7548186 ]\n",
      "  ...\n",
      "  [0.65317917 0.5        0.         ... 0.         0.62992126 0.6133787 ]\n",
      "  [0.5086705  0.41666666 0.         ... 0.         0.5748032  0.61989796]\n",
      "  [0.3468208  0.75       0.         ... 0.         0.72440946 0.60374147]]]\n",
      "(130, 25)\n",
      "seq_array_test_k:  [[[0.31791908 0.25       0.         ... 0.         0.5984252  0.43650794]\n",
      "  [0.44508672 0.25       0.         ... 0.         0.7322835  0.6573129 ]\n",
      "  [0.3815029  0.41666666 0.         ... 0.         0.6929134  0.7283163 ]\n",
      "  ...\n",
      "  [0.31791908 0.33333334 0.         ... 0.         0.5984252  0.5103458 ]\n",
      "  [0.5317919  0.5833333  0.         ... 0.         0.8031496  0.5952381 ]\n",
      "  [0.54913294 0.41666666 0.         ... 0.         0.63779527 0.7196712 ]]]\n",
      "(140, 25)\n",
      "seq_array_test_k:  [[[0.39306358 0.5833333  0.         ... 0.         0.62204725 0.72321427]\n",
      "  [0.7398844  0.5833333  0.         ... 0.         0.6456693  0.75992066]\n",
      "  [0.24277456 0.33333334 0.         ... 0.         0.5748032  0.65632087]\n",
      "  ...\n",
      "  [0.4913295  0.5833333  0.         ... 0.         0.6614173  0.68820864]\n",
      "  [0.67052025 0.25       0.         ... 0.         0.68503934 0.6643991 ]\n",
      "  [0.4913295  0.75       0.         ... 0.         0.4566929  0.7077664 ]]]\n",
      "(150, 25)\n",
      "seq_array_test_k:  [[[0.56647396 0.75       0.         ... 0.         0.6062992  0.72236395]\n",
      "  [0.61849713 0.75       0.         ... 0.         0.5590551  0.6617063 ]\n",
      "  [0.5317919  0.5        0.         ... 0.         0.5905512  0.7755102 ]\n",
      "  ...\n",
      "  [0.3236994  0.33333334 0.         ... 0.         0.48818898 0.5677438 ]\n",
      "  [0.67052025 0.5        0.         ... 0.         0.6692913  0.45308957]\n",
      "  [0.34104046 0.5833333  0.         ... 0.         0.52755904 0.48639455]]]\n",
      "(160, 25)\n",
      "seq_array_test_k:  [[[0.47398844 0.75       0.         ... 0.         0.47244096 0.61210316]\n",
      "  [0.56647396 0.16666667 0.         ... 0.         0.6535433  0.671627  ]\n",
      "  [0.58381504 0.16666667 0.         ... 0.         0.52755904 0.6893424 ]\n",
      "  ...\n",
      "  [0.47398844 0.5833333  0.         ... 0.         0.53543305 0.59041953]\n",
      "  [0.38728324 0.9166667  0.         ... 0.         0.37007874 0.5286281 ]\n",
      "  [0.433526   0.08333334 0.         ... 0.         0.6062992  0.59325397]]]\n",
      "(170, 25)\n",
      "seq_array_test_k:  [[[0.63583815 0.41666666 0.         ... 0.         0.7401575  0.65632087]\n",
      "  [0.35260117 0.5833333  0.         ... 0.         0.61417323 0.68962586]\n",
      "  [0.57225436 0.16666667 0.         ... 0.         0.48818898 0.77933675]\n",
      "  ...\n",
      "  [0.53757226 0.75       0.         ... 0.         0.7322835  0.54846936]\n",
      "  [0.5780347  0.75       0.         ... 0.         0.53543305 0.58347505]\n",
      "  [0.46242774 0.6666667  0.         ... 0.         0.6929134  0.60544217]]]\n",
      "(180, 25)\n",
      "seq_array_test_k:  [[[0.49710983 0.5833333  0.         ... 0.         0.56692916 0.73681974]\n",
      "  [0.3468208  0.8333333  0.         ... 0.         0.5748032  0.7110261 ]\n",
      "  [0.5953757  0.16666667 0.         ... 0.         0.47244096 0.5705782 ]\n",
      "  ...\n",
      "  [0.47398844 0.16666667 0.         ... 0.         0.511811   0.45351472]\n",
      "  [0.716763   0.08333334 0.         ... 0.         0.5905512  0.7026644 ]\n",
      "  [0.3236994  0.5        0.         ... 0.         0.68503934 0.5688776 ]]]\n",
      "(190, 25)\n",
      "seq_array_test_k:  [[[0.42196533 0.9166667  0.         ... 0.         0.54330707 0.6136621 ]\n",
      "  [0.22543353 0.6666667  0.         ... 0.         0.56692916 0.74376416]\n",
      "  [0.49710983 0.8333333  0.         ... 0.         0.5826772  0.69685376]\n",
      "  ...\n",
      "  [0.60115606 0.9166667  0.         ... 0.         0.62204725 0.635771  ]\n",
      "  [0.67052025 0.9166667  0.         ... 0.         0.53543305 0.600907  ]\n",
      "  [0.39884394 0.41666666 0.         ... 0.         0.48031497 0.48214287]]]\n",
      "(200, 25)\n",
      "seq_array_test_k:  [[[0.42196533 0.41666666 0.         ... 0.         0.52755904 0.6203231 ]\n",
      "  [0.35260117 0.5        0.         ... 0.         0.6456693  0.52593535]\n",
      "  [0.48554912 0.33333334 0.         ... 0.         0.6062992  0.7203798 ]\n",
      "  ...\n",
      "  [0.48554912 0.75       0.         ... 0.         0.46456692 0.63704646]\n",
      "  [0.60115606 0.8333333  0.         ... 0.         0.503937   0.5069444 ]\n",
      "  [0.50289017 0.5        0.         ... 0.         0.5984252  0.52536845]]]\n",
      "(210, 25)\n",
      "seq_array_test_k:  [[[0.433526   0.6666667  0.         ... 0.         0.6456693  0.6299603 ]\n",
      "  [0.5317919  0.41666666 0.         ... 0.         0.62992126 0.7644558 ]\n",
      "  [0.42196533 0.75       0.         ... 0.         0.5826772  0.50992066]\n",
      "  ...\n",
      "  [0.5606936  0.33333334 0.         ... 0.         0.6535433  0.66879255]\n",
      "  [0.75722545 0.25       0.         ... 0.         0.56692916 0.6072846 ]\n",
      "  [0.25433525 0.25       0.         ... 0.         0.511811   0.4326814 ]]]\n",
      "(220, 25)\n",
      "seq_array_test_k:  [[[0.50289017 0.5833333  0.         ... 0.         0.54330707 0.3951247 ]\n",
      "  [0.30057803 0.5833333  0.         ... 0.         0.5984252  0.578373  ]\n",
      "  [0.57225436 0.5        0.         ... 0.         0.63779527 0.72264737]\n",
      "  ...\n",
      "  [0.3468208  0.5        0.         ... 0.         0.4015748  0.45436507]\n",
      "  [0.37572256 0.6666667  0.         ... 0.         0.496063   0.4642857 ]\n",
      "  [0.4682081  0.5        0.         ... 0.         0.4566929  0.43650794]]]\n",
      "(230, 25)\n",
      "seq_array_test_k:  [[[0.49710983 0.33333334 0.         ... 0.         0.6062992  0.551729  ]\n",
      "  [0.57225436 0.9166667  0.         ... 0.         0.51968503 0.5521542 ]\n",
      "  [0.433526   0.75       0.         ... 0.         0.5905512  0.600907  ]\n",
      "  ...\n",
      "  [0.3468208  0.5        0.         ... 0.         0.40944883 0.45606577]\n",
      "  [0.7803468  0.16666667 0.         ... 0.         0.24409449 0.539966  ]\n",
      "  [0.5202312  0.41666666 0.         ... 0.         0.511811   0.55739796]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 25)\n",
      "seq_array_test_k:  [[[0.7745665  0.75       0.         ... 0.         0.5826772  0.47491497]\n",
      "  [0.39884394 0.75       0.         ... 0.         0.6062992  0.49645692]\n",
      "  [0.61271673 0.75       0.         ... 0.         0.56692916 0.6578798 ]\n",
      "  ...\n",
      "  [0.27745664 0.8333333  0.         ... 0.         0.52755904 0.7230726 ]\n",
      "  [0.4913295  0.8333333  0.         ... 0.         0.53543305 0.45649093]\n",
      "  [0.49710983 0.9166667  0.         ... 0.         0.39370078 0.53117913]]]\n",
      "(250, 25)\n",
      "seq_array_test_k:  [[[0.19075145 0.6666667  0.         ... 0.         0.54330707 0.6197562 ]\n",
      "  [0.3815029  0.75       0.         ... 0.         0.54330707 0.7386621 ]\n",
      "  [0.57225436 0.25       0.         ... 0.         0.4488189  0.609127  ]\n",
      "  ...\n",
      "  [0.61271673 0.33333334 0.         ... 0.         0.503937   0.5915533 ]\n",
      "  [0.4682081  0.25       0.         ... 0.         0.61417323 0.38732994]\n",
      "  [0.716763   0.6666667  0.         ... 0.         0.38582677 0.3890306 ]]]\n",
      "(260, 25)\n",
      "seq_array_test_k:  [[[0.49710983 0.5        0.         ... 0.         0.37795275 0.57426304]\n",
      "  [0.54913294 0.6666667  0.         ... 0.         0.496063   0.48086736]\n",
      "  [0.39884394 0.33333334 0.         ... 0.         0.68503934 0.49659863]\n",
      "  ...\n",
      "  [0.67052025 0.41666666 0.         ... 0.         0.44094488 0.53245467]\n",
      "  [0.41618496 0.5833333  0.         ... 0.         0.4566929  0.43225622]\n",
      "  [0.6069364  0.25       0.         ... 0.         0.36220473 0.33418366]]]\n",
      "(270, 25)\n",
      "seq_array_test_k:  [[[0.5433526  0.41666666 0.         ... 0.         0.52755904 0.54846936]\n",
      "  [0.24277456 0.25       0.         ... 0.         0.511811   0.48625284]\n",
      "  [0.76878613 0.08333334 0.         ... 0.         0.5590551  0.5997732 ]\n",
      "  ...\n",
      "  [0.47398844 0.08333334 0.         ... 0.         0.48818898 0.4260204 ]\n",
      "  [0.4913295  0.6666667  0.         ... 0.         0.43307087 0.28373015]\n",
      "  [0.4566474  0.75       0.         ... 0.         0.3464567  0.49050453]]]\n",
      "(280, 25)\n",
      "seq_array_test_k:  [[[0.5780347  0.9166667  0.         ... 0.         0.5905512  0.5654762 ]\n",
      "  [0.48554912 0.75       0.         ... 0.         0.53543305 0.5671769 ]\n",
      "  [0.56647396 0.5        0.         ... 0.         0.38582677 0.47179705]\n",
      "  ...\n",
      "  [0.41040462 0.33333334 0.         ... 0.         0.35433072 0.5181406 ]\n",
      "  [0.41618496 0.6666667  0.         ... 0.         0.4566929  0.4029195 ]\n",
      "  [0.5260116  0.9166667  0.         ... 0.         0.46456692 0.56122446]]]\n",
      "(290, 25)\n",
      "seq_array_test_k:  [[[0.42774567 0.8333333  0.         ... 0.         0.52755904 0.6235828 ]\n",
      "  [0.6647399  0.5        0.         ... 0.         0.37007874 0.5350057 ]\n",
      "  [0.54913294 0.41666666 0.         ... 0.         0.4488189  0.5372732 ]\n",
      "  ...\n",
      "  [0.716763   0.41666666 0.         ... 0.         0.54330707 0.4332483 ]\n",
      "  [0.63583815 0.16666667 0.         ... 0.         0.47244096 0.14186507]\n",
      "  [0.47976878 0.41666666 0.         ... 0.         0.3464567  0.5185658 ]]]\n",
      "(300, 25)\n",
      "seq_array_test_k:  [[[0.56647396 0.16666667 0.         ... 0.         0.38582677 0.49192178]\n",
      "  [0.54913294 0.5833333  0.         ... 0.         0.38582677 0.5673186 ]\n",
      "  [0.5780347  0.16666667 0.         ... 0.         0.511811   0.46215987]\n",
      "  ...\n",
      "  [0.50289017 0.5        0.         ... 0.         0.32283464 0.35941043]\n",
      "  [0.47398844 0.41666666 0.         ... 0.         0.37795275 0.48270977]\n",
      "  [0.44508672 0.41666666 0.         ... 0.         0.42519686 0.29719388]]]\n",
      "(310, 25)\n",
      "seq_array_test_k:  [[[0.6589595  0.6666667  0.         ... 0.         0.48818898 0.5005669 ]\n",
      "  [0.53757226 0.6666667  0.         ... 0.         0.4015748  0.4720805 ]\n",
      "  [0.2947977  0.8333333  0.         ... 0.         0.503937   0.4998583 ]\n",
      "  ...\n",
      "  [0.49710983 0.6666667  0.         ... 0.         0.26771653 0.325822  ]\n",
      "  [0.42774567 0.75       0.         ... 0.         0.2519685  0.30385488]\n",
      "  [0.39306358 0.8333333  0.         ... 0.         0.3464567  0.28911564]]]\n",
      "(320, 25)\n",
      "seq_array_test_k:  [[[0.54913294 0.9166667  0.         ... 0.         0.48031497 0.29747733]\n",
      "  [0.47398844 0.16666667 0.         ... 0.         0.47244096 0.46697846]\n",
      "  [0.47398844 0.6666667  0.         ... 0.         0.5511811  0.26133788]\n",
      "  ...\n",
      "  [0.5317919  0.75       0.         ... 0.         0.32283464 0.30201247]\n",
      "  [0.50289017 0.33333334 0.         ... 0.         0.22834645 0.2439059 ]\n",
      "  [0.5433526  0.25       0.         ... 0.         0.30708662 0.22123016]]]\n",
      "(330, 25)\n",
      "seq_array_test_k:  [[[0.6242775  0.41666666 0.         ... 0.         0.47244096 0.4859694 ]\n",
      "  [0.6936416  0.75       0.         ... 0.         0.42519686 0.40518707]\n",
      "  [0.44508672 0.5        0.         ... 0.         0.5590551  0.39980158]\n",
      "  ...\n",
      "  [0.4913295  0.9166667  0.         ... 0.         0.17322835 0.34197846]\n",
      "  [0.6416185  0.6666667  0.         ... 0.         0.20472442 0.23370181]\n",
      "  [0.6589595  0.33333334 0.         ... 0.         0.26771653 0.16227324]]]\n",
      "(50, 25)\n",
      "seq_array_test_k:  [[[0.27745664 0.75       0.         ... 0.         0.61417323 0.6605726 ]\n",
      "  [0.39306358 0.41666666 0.         ... 0.         0.77165353 0.69628686]\n",
      "  [0.23699422 0.33333334 0.         ... 0.         0.63779527 0.7039399 ]\n",
      "  ...\n",
      "  [0.4682081  0.8333333  0.         ... 0.         0.72440946 0.73072565]\n",
      "  [0.53757226 0.41666666 0.         ... 0.         0.5984252  0.82043654]\n",
      "  [0.54913294 0.25       0.         ... 0.         0.68503934 0.6244331 ]]]\n",
      "(60, 25)\n",
      "seq_array_test_k:  [[[0.5260116  0.9166667  0.         ... 0.         0.6535433  0.75155896]\n",
      "  [0.433526   0.9166667  0.         ... 0.         0.5748032  0.74433106]\n",
      "  [0.54913294 0.6666667  0.         ... 0.         0.6929134  0.6904762 ]\n",
      "  ...\n",
      "  [0.4682081  0.8333333  0.         ... 0.         0.63779527 0.714144  ]\n",
      "  [0.33526012 0.8333333  0.         ... 0.         0.5905512  0.64512473]\n",
      "  [0.67052025 0.9166667  0.         ... 0.         0.6614173  0.63789684]]]\n",
      "(70, 25)\n",
      "seq_array_test_k:  [[[0.6242775  0.16666667 0.         ... 0.         0.6062992  0.73015875]\n",
      "  [0.37572256 0.6666667  0.         ... 0.         0.54330707 0.6985544 ]\n",
      "  [0.5260116  0.16666667 0.         ... 0.         0.7559055  0.6513606 ]\n",
      "  ...\n",
      "  [0.4913295  0.25       0.         ... 0.         0.56692916 0.5880102 ]\n",
      "  [0.50289017 0.41666666 0.         ... 0.         0.5984252  0.71570295]\n",
      "  [0.7456647  0.8333333  0.         ... 0.         0.38582677 0.58645123]]]\n",
      "(80, 25)\n",
      "seq_array_test_k:  [[[0.2947977  0.41666666 0.         ... 0.         0.48031497 0.5780896 ]\n",
      "  [0.58381504 0.9166667  0.         ... 0.         0.61417323 0.72959185]\n",
      "  [0.4682081  0.9166667  0.         ... 0.         0.56692916 0.55867344]\n",
      "  ...\n",
      "  [0.61271673 0.6666667  0.         ... 0.         0.6535433  0.6031746 ]\n",
      "  [0.46242774 0.8333333  0.         ... 0.         0.6062992  0.6330782 ]\n",
      "  [0.57225436 0.9166667  0.         ... 0.         0.6614173  0.73129255]]]\n",
      "(90, 25)\n",
      "seq_array_test_k:  [[[0.33526012 0.33333334 0.         ... 0.         0.6614173  0.70068026]\n",
      "  [0.5953757  0.33333334 0.         ... 0.         0.7007874  0.46768707]\n",
      "  [0.43930635 0.5        0.         ... 0.         0.7401575  0.67517006]\n",
      "  ...\n",
      "  [0.5317919  0.16666667 0.         ... 0.         0.62204725 0.5856009 ]\n",
      "  [0.6936416  0.41666666 0.         ... 0.         0.6535433  0.7760771 ]\n",
      "  [0.38728324 0.5        0.         ... 0.         0.53543305 0.60515875]]]\n",
      "(100, 25)\n",
      "seq_array_test_k:  [[[0.30635837 0.5833333  0.         ... 0.         0.7007874  0.6706349 ]\n",
      "  [0.4913295  0.6666667  0.         ... 0.         0.70866144 0.6571712 ]\n",
      "  [0.5433526  0.33333334 0.         ... 0.         0.511811   0.6505102 ]\n",
      "  ...\n",
      "  [0.61849713 0.25       0.         ... 0.         0.511811   0.5802154 ]\n",
      "  [0.42196533 0.8333333  0.         ... 0.         0.7559055  0.78514737]\n",
      "  [0.5606936  0.75       0.         ... 0.         0.63779527 0.57851475]]]\n",
      "(110, 25)\n",
      "seq_array_test_k:  [[[0.5549133  0.75       0.         ... 0.         0.6929134  0.6632653 ]\n",
      "  [0.47976878 0.5        0.         ... 0.         0.5905512  0.68296486]\n",
      "  [0.6242775  0.33333334 0.         ... 0.         0.56692916 0.71952945]\n",
      "  ...\n",
      "  [0.46242774 0.33333334 0.         ... 0.         0.47244096 0.529195  ]\n",
      "  [0.56647396 0.25       0.         ... 0.         0.6771653  0.5908447 ]\n",
      "  [0.4913295  0.5833333  0.         ... 0.         0.63779527 0.63321996]]]\n",
      "(120, 25)\n",
      "seq_array_test_k:  [[[0.53757226 0.6666667  0.         ... 0.         0.7637795  0.57865644]\n",
      "  [0.2601156  0.75       0.         ... 0.         0.5984252  0.6425737 ]\n",
      "  [0.5606936  0.41666666 0.         ... 0.         0.6692913  0.54761904]\n",
      "  ...\n",
      "  [0.60115606 0.41666666 0.         ... 0.         0.37007874 0.660856  ]\n",
      "  [0.5549133  0.5833333  0.         ... 0.         0.62204725 0.6892007 ]\n",
      "  [0.5606936  0.25       0.         ... 0.         0.6692913  0.6169218 ]]]\n",
      "(130, 25)\n",
      "seq_array_test_k:  [[[0.3699422  0.5833333  0.         ... 0.         0.6614173  0.63903064]\n",
      "  [0.49710983 0.25       0.         ... 0.         0.5511811  0.5844671 ]\n",
      "  [0.5202312  0.9166667  0.         ... 0.         0.56692916 0.7060658 ]\n",
      "  ...\n",
      "  [0.45086706 0.33333334 0.         ... 0.         0.7401575  0.60841835]\n",
      "  [0.38728324 0.75       0.         ... 0.         0.7401575  0.55711454]\n",
      "  [0.2601156  0.33333334 0.         ... 0.         0.52755904 0.6889172 ]]]\n",
      "(140, 25)\n",
      "seq_array_test_k:  [[[0.5606936  0.9166667  0.         ... 0.         0.54330707 0.56901926]\n",
      "  [0.61271673 0.41666666 0.         ... 0.         0.5905512  0.5382653 ]\n",
      "  [0.5317919  0.16666667 0.         ... 0.         0.6692913  0.7346939 ]\n",
      "  ...\n",
      "  [0.5433526  0.25       0.         ... 0.         0.7007874  0.6438492 ]\n",
      "  [0.65317917 0.9166667  0.         ... 0.         0.5748032  0.6551871 ]\n",
      "  [0.22543353 0.5833333  0.         ... 0.         0.63779527 0.60955215]]]\n",
      "(150, 25)\n",
      "seq_array_test_k:  [[[0.47398844 0.6666667  0.         ... 0.         0.62992126 0.6335034 ]\n",
      "  [0.6589595  0.75       0.         ... 0.         0.47244096 0.6070011 ]\n",
      "  [0.53757226 0.33333334 0.         ... 0.         0.54330707 0.64569163]\n",
      "  ...\n",
      "  [0.50289017 0.33333334 0.         ... 0.         0.51968503 0.5677438 ]\n",
      "  [0.39884394 0.75       0.         ... 0.         0.5984252  0.67814624]\n",
      "  [0.5433526  0.25       0.         ... 0.         0.4488189  0.5763889 ]]]\n",
      "(160, 25)\n",
      "seq_array_test_k:  [[[0.49710983 0.6666667  0.         ... 0.         0.62992126 0.6119614 ]\n",
      "  [0.5549133  0.16666667 0.         ... 0.         0.5984252  0.57298756]\n",
      "  [0.46242774 0.8333333  0.         ... 0.         0.5826772  0.7091837 ]\n",
      "  ...\n",
      "  [0.5086705  0.5833333  0.         ... 0.         0.62204725 0.39526644]\n",
      "  [0.40462428 0.5        0.         ... 0.         0.42519686 0.6281179 ]\n",
      "  [0.40462428 0.75       0.         ... 0.         0.47244096 0.4248866 ]]]\n",
      "(170, 25)\n",
      "seq_array_test_k:  [[[0.72254336 0.33333334 0.         ... 0.         0.62992126 0.57851475]\n",
      "  [0.5549133  0.5833333  0.         ... 0.         0.511811   0.57681406]\n",
      "  [0.39306358 0.33333334 0.         ... 0.         0.5748032  0.6750283 ]\n",
      "  ...\n",
      "  [0.5260116  0.33333334 0.         ... 0.         0.39370078 0.56320864]\n",
      "  [0.433526   0.9166667  0.         ... 0.         0.61417323 0.48015872]\n",
      "  [0.30057803 0.5833333  0.         ... 0.         0.4015748  0.4005102 ]]]\n",
      "(180, 25)\n",
      "seq_array_test_k:  [[[0.48554912 0.41666666 0.         ... 0.         0.52755904 0.68650794]\n",
      "  [0.4913295  0.9166667  0.         ... 0.         0.62992126 0.55243766]\n",
      "  [0.19075145 0.5        0.         ... 0.         0.62992126 0.69742066]\n",
      "  ...\n",
      "  [0.47398844 0.5        0.         ... 0.         0.42519686 0.3538832 ]\n",
      "  [0.44508672 0.75       0.         ... 0.         0.4488189  0.5236678 ]\n",
      "  [0.39884394 0.5        0.         ... 0.         0.48818898 0.26729023]]]\n",
      "(190, 25)\n",
      "seq_array_test_k:  [[[0.50289017 0.75       0.         ... 0.         0.8267717  0.65121883]\n",
      "  [0.42774567 0.41666666 0.         ... 0.         0.77952754 0.4951814 ]\n",
      "  [0.48554912 0.16666667 0.         ... 0.         0.6614173  0.486678  ]\n",
      "  ...\n",
      "  [0.46242774 0.8333333  0.         ... 0.         0.24409449 0.44387755]\n",
      "  [0.433526   0.5        0.         ... 0.         0.4488189  0.33333334]\n",
      "  [0.48554912 0.6666667  0.         ... 0.         0.2992126  0.408305  ]]]\n",
      "(200, 25)\n",
      "seq_array_test_k:  [[[0.5317919  0.16666667 0.         ... 0.         0.48818898 0.61734694]\n",
      "  [0.6069364  0.41666666 0.         ... 0.         0.41732284 0.571712  ]\n",
      "  [0.61271673 0.75       0.         ... 0.         0.41732284 0.6014739 ]\n",
      "  ...\n",
      "  [0.45086706 0.33333334 0.         ... 0.         0.17322835 0.06760204]\n",
      "  [0.6069364  0.33333334 0.         ... 0.         0.33858266 0.22477324]\n",
      "  [0.2947977  0.9166667  0.         ... 0.         0.18110237 0.2026644 ]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 25)\n",
      "seq_array_test_k:  [[[0.6069364  0.33333334 0.         ... 0.         0.6692913  0.7760771 ]\n",
      "  [0.6416185  0.5        0.         ... 0.         0.5905512  0.56462586]\n",
      "  [0.433526   0.08333334 0.         ... 0.         0.78740156 0.6527778 ]\n",
      "  ...\n",
      "  [0.30635837 0.16666667 0.         ... 0.         0.63779527 0.6655329 ]\n",
      "  [0.5317919  0.41666666 0.         ... 0.         0.52755904 0.785856  ]\n",
      "  [0.5433526  0.33333334 0.         ... 0.         0.5826772  0.660856  ]]]\n",
      "(60, 25)\n",
      "seq_array_test_k:  [[[0.56647396 0.41666666 0.         ... 0.         0.6692913  0.6744614 ]\n",
      "  [0.31791908 0.08333334 0.         ... 0.         0.61417323 0.6917517 ]\n",
      "  [0.42774567 0.25       0.         ... 0.         0.6771653  0.81320864]\n",
      "  ...\n",
      "  [0.47976878 0.41666666 0.         ... 0.         0.53543305 0.664966  ]\n",
      "  [0.65317917 0.75       0.         ... 0.         0.63779527 0.8239796 ]\n",
      "  [0.57225436 0.75       0.         ... 0.         0.6614173  0.73795354]]]\n",
      "(70, 25)\n",
      "seq_array_test_k:  [[[0.3583815  0.5833333  0.         ... 0.         0.6929134  0.7675737 ]\n",
      "  [0.7109827  0.5833333  0.         ... 0.         0.6535433  0.6897676 ]\n",
      "  [0.31213874 0.16666667 0.         ... 0.         0.5748032  0.69033444]\n",
      "  ...\n",
      "  [0.37572256 0.16666667 0.         ... 0.         0.7559055  0.74730724]\n",
      "  [0.47976878 0.41666666 0.         ... 0.         0.5511811  0.81292516]\n",
      "  [0.39884394 0.6666667  0.         ... 0.         0.6456693  0.7679989 ]]]\n",
      "(80, 25)\n",
      "seq_array_test_k:  [[[0.51445085 0.33333334 0.         ... 0.         0.6692913  0.6628401 ]\n",
      "  [0.4682081  0.         0.         ... 0.         0.496063   0.84495467]\n",
      "  [0.5260116  0.33333334 0.         ... 0.         0.6771653  0.7535431 ]\n",
      "  ...\n",
      "  [0.5317919  0.75       0.         ... 0.         0.5511811  0.642432  ]\n",
      "  [0.41618496 0.75       0.         ... 0.         0.39370078 0.39299887]\n",
      "  [0.54913294 0.5833333  0.         ... 0.         0.5511811  0.6081349 ]]]\n",
      "(90, 25)\n",
      "seq_array_test_k:  [[[0.3583815  0.16666667 0.         ... 0.         0.6456693  0.62953514]\n",
      "  [0.47398844 0.8333333  0.         ... 0.         0.6535433  0.7230726 ]\n",
      "  [0.42196533 0.41666666 0.         ... 0.         0.54330707 0.59183675]\n",
      "  ...\n",
      "  [0.48554912 0.5833333  0.         ... 0.         0.511811   0.5296202 ]\n",
      "  [0.5780347  0.16666667 0.         ... 0.         0.6535433  0.6486678 ]\n",
      "  [0.46242774 0.5        0.         ... 0.         0.5984252  0.703373  ]]]\n",
      "(100, 25)\n",
      "seq_array_test_k:  [[[0.6763006  0.6666667  0.         ... 0.         0.70866144 0.42885488]\n",
      "  [0.20809248 0.33333334 0.         ... 0.         0.77165353 0.5636338 ]\n",
      "  [0.51445085 0.5        0.         ... 0.         0.5905512  0.73100907]\n",
      "  ...\n",
      "  [0.7630058  0.6666667  0.         ... 0.         0.44094488 0.48880386]\n",
      "  [0.49710983 0.5833333  0.         ... 0.         0.47244096 0.614229  ]\n",
      "  [0.32947975 0.75       0.         ... 0.         0.48818898 0.7827381 ]]]\n",
      "(110, 25)\n",
      "seq_array_test_k:  [[[0.5260116  0.5        0.         ... 0.         0.7480315  0.71626985]\n",
      "  [0.4566474  0.5        0.         ... 0.         0.53543305 0.43905896]\n",
      "  [0.6242775  0.25       0.         ... 0.         0.511811   0.6388889 ]\n",
      "  ...\n",
      "  [0.49710983 0.08333334 0.         ... 0.         0.51968503 0.5989229 ]\n",
      "  [0.5895954  0.5833333  0.         ... 0.         0.61417323 0.55243766]\n",
      "  [0.51445085 0.25       0.         ... 0.         0.496063   0.6611394 ]]]\n",
      "(120, 25)\n",
      "seq_array_test_k:  [[[0.3583815  0.41666666 0.         ... 0.         0.5590551  0.66043085]\n",
      "  [0.70520234 0.75       0.         ... 0.         0.5826772  0.70181406]\n",
      "  [0.49710983 0.75       0.         ... 0.         0.6771653  0.56179136]\n",
      "  ...\n",
      "  [0.49710983 0.5833333  0.         ... 0.         0.30708662 0.486678  ]\n",
      "  [0.5202312  0.8333333  0.         ... 0.         0.40944883 0.5564059 ]\n",
      "  [0.39884394 0.5833333  0.         ... 0.         0.6771653  0.4672619 ]]]\n",
      "(130, 25)\n",
      "seq_array_test_k:  [[[0.6242775  0.25       0.         ... 0.         0.5511811  0.5205499 ]\n",
      "  [0.42774567 0.41666666 0.         ... 0.         0.6692913  0.65575397]\n",
      "  [0.6242775  0.25       0.         ... 0.         0.51968503 0.6020408 ]\n",
      "  ...\n",
      "  [0.68786126 0.75       0.         ... 0.         0.4015748  0.6335034 ]\n",
      "  [0.4913295  0.33333334 0.         ... 0.         0.48818898 0.45053855]\n",
      "  [0.6300578  0.25       0.         ... 0.         0.4488189  0.33007368]]]\n",
      "(140, 25)\n",
      "seq_array_test_k:  [[[0.47398844 0.25       0.         ... 0.         0.7007874  0.6753118 ]\n",
      "  [0.6242775  0.08333334 0.         ... 0.         0.48818898 0.5986394 ]\n",
      "  [0.46242774 0.5833333  0.         ... 0.         0.61417323 0.61763036]\n",
      "  ...\n",
      "  [0.50289017 0.41666666 0.         ... 0.         0.35433072 0.38251135]\n",
      "  [0.5086705  0.5833333  0.         ... 0.         0.27559054 0.30385488]\n",
      "  [0.48554912 0.75       0.         ... 0.         0.33070865 0.5766723 ]]]\n",
      "(150, 25)\n",
      "seq_array_test_k:  [[[0.61271673 0.5833333  0.         ... 0.         0.496063   0.58645123]\n",
      "  [0.4913295  0.41666666 0.         ... 0.         0.6456693  0.4981576 ]\n",
      "  [0.61849713 0.25       0.         ... 0.         0.5984252  0.5902778 ]\n",
      "  ...\n",
      "  [0.5086705  0.08333334 0.         ... 0.         0.30708662 0.28160432]\n",
      "  [0.36416185 0.16666667 0.         ... 0.         0.37007874 0.49546486]\n",
      "  [0.65317917 0.5833333  0.         ... 0.         0.4015748  0.36635488]]]\n",
      "(50, 25)\n",
      "seq_array_test_k:  [[[0.5606936  0.9166667  0.         ... 0.         0.6692913  0.69954646]\n",
      "  [0.5202312  0.5833333  0.         ... 0.         0.7007874  0.7297336 ]\n",
      "  [0.5260116  0.6666667  0.         ... 0.         0.6614173  0.7069161 ]\n",
      "  ...\n",
      "  [0.6069364  0.75       0.         ... 0.         0.6062992  0.5700113 ]\n",
      "  [0.51445085 0.16666667 0.         ... 0.         0.6929134  0.70620745]\n",
      "  [0.36416185 0.16666667 0.         ... 0.         0.56692916 0.63038546]]]\n",
      "(60, 25)\n",
      "seq_array_test_k:  [[[0.6473988  0.25       0.         ... 0.         0.54330707 0.69090134]\n",
      "  [0.5202312  0.75       0.         ... 0.         0.62204725 0.62485826]\n",
      "  [0.63583815 0.25       0.         ... 0.         0.6929134  0.69571996]\n",
      "  ...\n",
      "  [0.56647396 0.75       0.         ... 0.         0.5826772  0.7847222 ]\n",
      "  [0.41618496 0.5        0.         ... 0.         0.44094488 0.69430274]\n",
      "  [0.33526012 0.8333333  0.         ... 0.         0.6929134  0.63010204]]]\n",
      "(70, 25)\n",
      "seq_array_test_k:  [[[0.36416185 0.08333334 0.         ... 0.         0.7637795  0.6247166 ]\n",
      "  [0.4682081  0.8333333  0.         ... 0.         0.6929134  0.67871314]\n",
      "  [0.5202312  0.16666667 0.         ... 0.         0.71653545 0.6863662 ]\n",
      "  ...\n",
      "  [0.39306358 0.75       0.         ... 0.         0.6456693  0.7502834 ]\n",
      "  [0.54913294 0.5833333  0.         ... 0.         0.5511811  0.6461168 ]\n",
      "  [0.63583815 0.75       0.         ... 0.         0.5590551  0.6079932 ]]]\n",
      "(80, 25)\n",
      "seq_array_test_k:  [[[0.5202312  0.75       0.         ... 0.         0.496063   0.5622166 ]\n",
      "  [0.41040462 0.6666667  0.         ... 0.         0.6614173  0.6828231 ]\n",
      "  [0.3236994  0.8333333  0.         ... 0.         0.63779527 0.7722506 ]\n",
      "  ...\n",
      "  [0.35260117 0.41666666 0.         ... 0.         0.6535433  0.67800456]\n",
      "  [0.35260117 0.75       0.         ... 0.         0.51968503 0.68537414]\n",
      "  [0.30057803 0.25       0.         ... 0.         0.511811   0.53302157]]]\n",
      "(90, 25)\n",
      "seq_array_test_k:  [[[0.70520234 0.33333334 0.         ... 0.         0.48818898 0.77267575]\n",
      "  [0.7109827  0.41666666 0.         ... 0.         0.5984252  0.68622446]\n",
      "  [0.4913295  0.25       0.         ... 0.         0.6692913  0.6845238 ]\n",
      "  ...\n",
      "  [0.50289017 0.25       0.         ... 0.         0.81889766 0.48625284]\n",
      "  [0.5202312  0.6666667  0.         ... 0.         0.5590551  0.8028628 ]\n",
      "  [0.27745664 0.6666667  0.         ... 0.         0.78740156 0.79322565]]]\n",
      "(100, 25)\n",
      "seq_array_test_k:  [[[0.43930635 0.75       0.         ... 0.         0.496063   0.69288546]\n",
      "  [0.6242775  0.75       0.         ... 0.         0.63779527 0.48455215]\n",
      "  [0.3815029  0.41666666 0.         ... 0.         0.56692916 0.5155896 ]\n",
      "  ...\n",
      "  [0.6242775  0.41666666 0.         ... 0.         0.5590551  0.47902495]\n",
      "  [0.56647396 0.41666666 0.         ... 0.         0.6929134  0.60430837]\n",
      "  [0.3815029  0.33333334 0.         ... 0.         0.5905512  0.50382656]]]\n",
      "(110, 25)\n",
      "seq_array_test_k:  [[[0.57225436 0.41666666 0.         ... 0.         0.52755904 0.69146824]\n",
      "  [0.51445085 0.33333334 0.         ... 0.         0.5905512  0.6425737 ]\n",
      "  [0.5433526  0.75       0.         ... 0.         0.63779527 0.66213155]\n",
      "  ...\n",
      "  [0.48554912 0.6666667  0.         ... 0.         0.5984252  0.70153064]\n",
      "  [0.63583815 0.6666667  0.         ... 0.         0.48818898 0.5222506 ]\n",
      "  [0.37572256 0.6666667  0.         ... 0.         0.54330707 0.65150225]]]\n",
      "(120, 25)\n",
      "seq_array_test_k:  [[[0.4913295  0.5833333  0.         ... 0.         0.7480315  0.7276077 ]\n",
      "  [0.5895954  0.5        0.         ... 0.         0.6062992  0.704932  ]\n",
      "  [0.5433526  0.75       0.         ... 0.         0.6614173  0.51927435]\n",
      "  ...\n",
      "  [0.54913294 0.5        0.         ... 0.         0.511811   0.6906179 ]\n",
      "  [0.5086705  0.33333334 0.         ... 0.         0.39370078 0.48256803]\n",
      "  [0.3583815  0.33333334 0.         ... 0.         0.5511811  0.6235828 ]]]\n",
      "(130, 25)\n",
      "seq_array_test_k:  [[[0.6763006  0.6666667  0.         ... 0.         0.56692916 0.55513036]\n",
      "  [0.7283237  0.5        0.         ... 0.         0.63779527 0.589144  ]\n",
      "  [0.5433526  0.5833333  0.         ... 0.         0.71653545 0.6669501 ]\n",
      "  ...\n",
      "  [0.5317919  0.6666667  0.         ... 0.         0.61417323 0.46683672]\n",
      "  [0.39884394 0.33333334 0.         ... 0.         0.4566929  0.56575966]\n",
      "  [0.5606936  0.5        0.         ... 0.         0.6062992  0.5819161 ]]]\n",
      "(140, 25)\n",
      "seq_array_test_k:  [[[0.61849713 0.25       0.         ... 0.         0.6929134  0.5986394 ]\n",
      "  [0.5549133  0.25       0.         ... 0.         0.5590551  0.5975057 ]\n",
      "  [0.6416185  0.6666667  0.         ... 0.         0.63779527 0.54039115]\n",
      "  ...\n",
      "  [0.67052025 0.6666667  0.         ... 0.         0.5511811  0.6446996 ]\n",
      "  [0.48554912 0.8333333  0.         ... 0.         0.496063   0.41170636]\n",
      "  [0.35260117 0.41666666 0.         ... 0.         0.47244096 0.43367347]]]\n",
      "(150, 25)\n",
      "seq_array_test_k:  [[[0.42196533 0.5        0.         ... 0.         0.5748032  0.49829933]\n",
      "  [0.6473988  0.6666667  0.         ... 0.         0.62992126 0.73653626]\n",
      "  [0.53757226 0.5833333  0.         ... 0.         0.53543305 0.51062924]\n",
      "  ...\n",
      "  [0.32947975 0.6666667  0.         ... 0.         0.52755904 0.29350907]\n",
      "  [0.4682081  0.9166667  0.         ... 0.         0.5748032  0.45592403]\n",
      "  [0.5317919  0.41666666 0.         ... 0.         0.46456692 0.40632087]]]\n",
      "(160, 25)\n",
      "seq_array_test_k:  [[[0.23121387 0.6666667  0.         ... 0.         0.6692913  0.6347789 ]\n",
      "  [0.6763006  0.33333334 0.         ... 0.         0.52755904 0.54988664]\n",
      "  [0.49710983 0.25       0.         ... 0.         0.7401575  0.6014739 ]\n",
      "  ...\n",
      "  [0.45086706 0.5        0.         ... 0.         0.2519685  0.33673468]\n",
      "  [0.5549133  0.9166667  0.         ... 0.         0.48818898 0.3823696 ]\n",
      "  [0.6763006  0.41666666 0.         ... 0.         0.38582677 0.4010771 ]]]\n",
      "(170, 25)\n",
      "seq_array_test_k:  [[[0.46242774 0.5        0.         ... 0.         0.5984252  0.58290815]\n",
      "  [0.5433526  0.75       0.         ... 0.         0.51968503 0.46697846]\n",
      "  [0.28323698 0.41666666 0.         ... 0.         0.5905512  0.43920067]\n",
      "  ...\n",
      "  [0.58381504 0.9166667  0.         ... 0.         0.2992126  0.16737528]\n",
      "  [0.6589595  0.25       0.         ... 0.         0.37795275 0.41213152]\n",
      "  [0.5606936  0.6666667  0.         ... 0.         0.4015748  0.47534013]]]\n",
      "(180, 25)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq_array_test_k:  [[[0.31791908 0.33333334 0.         ... 0.         0.503937   0.5419501 ]\n",
      "  [0.716763   0.6666667  0.         ... 0.         0.48031497 0.4934807 ]\n",
      "  [0.83815026 0.5        0.         ... 0.         0.5511811  0.5406746 ]\n",
      "  ...\n",
      "  [0.41618496 0.5        0.         ... 0.         0.31496063 0.21513605]\n",
      "  [0.54913294 0.6666667  0.         ... 0.         0.22834645 0.33078232]\n",
      "  [0.54913294 0.41666666 0.         ... 0.         0.25984251 0.04606009]]]\n",
      "(50, 25)\n",
      "seq_array_test_k:  [[[0.30635837 0.75       0.         ... 0.         0.44094488 0.68424034]\n",
      "  [0.5549133  0.16666667 0.         ... 0.         0.8031496  0.48030046]\n",
      "  [0.63583815 0.16666667 0.         ... 0.         0.62204725 0.41992632]\n",
      "  ...\n",
      "  [0.45086706 0.75       0.         ... 0.         0.5826772  0.50014174]\n",
      "  [0.60115606 0.5833333  0.         ... 0.         0.56692916 0.7056406 ]\n",
      "  [0.5260116  0.8333333  0.         ... 0.         0.56692916 0.63562924]]]\n",
      "(60, 25)\n",
      "seq_array_test_k:  [[[0.433526   0.08333334 0.         ... 0.         0.6929134  0.7256236 ]\n",
      "  [0.31213874 0.8333333  0.         ... 0.         0.48818898 0.6296769 ]\n",
      "  [0.5202312  0.08333334 0.         ... 0.         0.6771653  0.64838433]\n",
      "  ...\n",
      "  [0.5317919  0.08333334 0.         ... 0.         0.6535433  0.48228458]\n",
      "  [0.53757226 0.41666666 0.         ... 0.         0.503937   0.6522109 ]\n",
      "  [0.30635837 0.8333333  0.         ... 0.         0.5748032  0.52097505]]]\n",
      "(70, 25)\n",
      "seq_array_test_k:  [[[0.49710983 0.08333334 0.         ... 0.         0.511811   0.71924603]\n",
      "  [0.38728324 0.5        0.         ... 0.         0.6771653  0.60515875]\n",
      "  [0.48554912 0.5833333  0.         ... 0.         0.503937   0.61904764]\n",
      "  ...\n",
      "  [0.41040462 0.8333333  0.         ... 0.         0.62992126 0.4302721 ]\n",
      "  [0.42196533 0.08333334 0.         ... 0.         0.4566929  0.6999717 ]\n",
      "  [0.58381504 0.16666667 0.         ... 0.         0.54330707 0.56901926]]]\n",
      "(80, 25)\n",
      "seq_array_test_k:  [[[0.48554912 0.25       0.         ... 0.         0.5826772  0.77125853]\n",
      "  [0.5780347  0.75       0.         ... 0.         0.53543305 0.6719104 ]\n",
      "  [0.32947975 0.75       0.         ... 0.         0.52755904 0.60487527]\n",
      "  ...\n",
      "  [0.50289017 0.75       0.         ... 0.         0.61417323 0.52012473]\n",
      "  [0.44508672 0.25       0.         ... 0.         0.4566929  0.67757934]\n",
      "  [0.6300578  0.25       0.         ... 0.         0.6456693  0.37003967]]]\n",
      "(90, 25)\n",
      "seq_array_test_k:  [[[0.5549133  0.5833333  0.         ... 0.         0.7322835  0.7158447 ]\n",
      "  [0.39306358 0.08333334 0.         ... 0.         0.7401575  0.62514174]\n",
      "  [0.20231214 0.08333334 0.         ... 0.         0.496063   0.6087018 ]\n",
      "  ...\n",
      "  [0.37572256 0.33333334 0.         ... 0.         0.52755904 0.408305  ]\n",
      "  [0.3699422  0.08333334 0.         ... 0.         0.62992126 0.6464002 ]\n",
      "  [0.6242775  0.08333334 0.         ... 0.         0.7401575  0.66071427]]]\n",
      "(100, 25)\n",
      "seq_array_test_k:  [[[0.5202312  0.5833333  0.         ... 0.         0.6614173  0.5555556 ]\n",
      "  [0.6416185  0.16666667 0.         ... 0.         0.5748032  0.66156465]\n",
      "  [0.716763   0.8333333  0.         ... 0.         0.5748032  0.52125853]\n",
      "  ...\n",
      "  [0.3583815  0.75       0.         ... 0.         0.52755904 0.48469388]\n",
      "  [0.47398844 0.5        0.         ... 0.         0.5905512  0.6513606 ]\n",
      "  [0.42196533 0.33333334 0.         ... 0.         0.47244096 0.5433673 ]]]\n",
      "(110, 25)\n",
      "seq_array_test_k:  [[[0.5260116  0.08333334 0.         ... 0.         0.5511811  0.4034864 ]\n",
      "  [0.3583815  0.41666666 0.         ... 0.         0.5826772  0.553288  ]\n",
      "  [0.2947977  0.5        0.         ... 0.         0.61417323 0.50099206]\n",
      "  ...\n",
      "  [0.21387284 0.33333334 0.         ... 0.         0.4488189  0.72845805]\n",
      "  [0.6647399  0.5833333  0.         ... 0.         0.6062992  0.6765873 ]\n",
      "  [0.5317919  0.16666667 0.         ... 0.         0.28346458 0.5445011 ]]]\n",
      "(120, 25)\n",
      "seq_array_test_k:  [[[0.41618496 0.25       0.         ... 0.         0.6456693  0.56207484]\n",
      "  [0.58381504 0.16666667 0.         ... 0.         0.51968503 0.58531743]\n",
      "  [0.50289017 0.6666667  0.         ... 0.         0.6456693  0.46017572]\n",
      "  ...\n",
      "  [0.60115606 0.33333334 0.         ... 0.         0.511811   0.4835601 ]\n",
      "  [0.61271673 0.25       0.         ... 0.         0.48031497 0.47704083]\n",
      "  [0.5202312  0.75       0.         ... 0.         0.48818898 0.6166383 ]]]\n",
      "(130, 25)\n",
      "seq_array_test_k:  [[[0.5606936  0.6666667  0.         ... 0.         0.68503934 0.62911   ]\n",
      "  [0.75722545 0.6666667  0.         ... 0.         0.2913386  0.50411   ]\n",
      "  [0.73410404 0.5833333  0.         ... 0.         0.40944883 0.61437076]\n",
      "  ...\n",
      "  [0.37572256 0.5        0.         ... 0.         0.5826772  0.4994331 ]\n",
      "  [0.7398844  0.08333334 0.         ... 0.         0.48031497 0.6108277 ]\n",
      "  [0.3699422  0.5833333  0.         ... 0.         0.4488189  0.52324265]]]\n",
      "(140, 25)\n",
      "seq_array_test_k:  [[[0.41040462 0.8333333  0.         ... 0.         0.5984252  0.5816327 ]\n",
      "  [0.5433526  0.5833333  0.         ... 0.         0.6535433  0.6108277 ]\n",
      "  [0.24855492 0.5833333  0.         ... 0.         0.503937   0.589144  ]\n",
      "  ...\n",
      "  [0.3815029  0.08333334 0.         ... 0.         0.496063   0.4798753 ]\n",
      "  [0.39884394 0.6666667  0.         ... 0.         0.54330707 0.55853176]\n",
      "  [0.6300578  0.25       0.         ... 0.         0.4566929  0.4920635 ]]]\n",
      "(150, 25)\n",
      "seq_array_test_k:  [[[0.3236994  0.16666667 0.         ... 0.         0.52755904 0.5914116 ]\n",
      "  [0.6589595  0.16666667 0.         ... 0.         0.6456693  0.39214852]\n",
      "  [0.41618496 0.5833333  0.         ... 0.         0.4015748  0.3677721 ]\n",
      "  ...\n",
      "  [0.5953757  0.75       0.         ... 0.         0.53543305 0.6169218 ]\n",
      "  [0.6589595  0.41666666 0.         ... 0.         0.27559054 0.44940478]\n",
      "  [0.4913295  0.25       0.         ... 0.         0.36220473 0.41822562]]]\n",
      "(160, 25)\n",
      "seq_array_test_k:  [[[0.38728324 0.08333334 0.         ... 0.         0.48818898 0.5894274 ]\n",
      "  [0.32947975 0.75       0.         ... 0.         0.56692916 0.51870745]\n",
      "  [0.51445085 0.33333334 0.         ... 0.         0.36220473 0.48880386]\n",
      "  ...\n",
      "  [0.5780347  0.33333334 0.         ... 0.         0.511811   0.3822279 ]\n",
      "  [0.433526   0.6666667  0.         ... 0.         0.33858266 0.58319163]\n",
      "  [0.5549133  0.5833333  0.         ... 0.         0.36220473 0.28684807]]]\n",
      "(170, 25)\n",
      "seq_array_test_k:  [[[0.50289017 0.25       0.         ... 0.         0.503937   0.47066328]\n",
      "  [0.47976878 0.5        0.         ... 0.         0.61417323 0.5510204 ]\n",
      "  [0.42774567 0.08333334 0.         ... 0.         0.511811   0.5761054 ]\n",
      "  ...\n",
      "  [0.34104046 0.33333334 0.         ... 0.         0.35433072 0.5036848 ]\n",
      "  [0.38728324 0.25       0.         ... 0.         0.43307087 0.43792516]\n",
      "  [0.30057803 0.75       0.         ... 0.         0.37007874 0.3531746 ]]]\n",
      "(180, 25)\n",
      "seq_array_test_k:  [[[0.61271673 0.8333333  0.         ... 0.         0.503937   0.55300456]\n",
      "  [0.37572256 0.25       0.         ... 0.         0.51968503 0.60600907]\n",
      "  [0.5086705  0.41666666 0.         ... 0.         0.5826772  0.4107143 ]\n",
      "  ...\n",
      "  [0.5260116  0.25       0.         ... 0.         0.30708662 0.450822  ]\n",
      "  [0.61271673 0.8333333  0.         ... 0.         0.36220473 0.37046486]\n",
      "  [0.43930635 0.5833333  0.         ... 0.         0.2992126  0.46400228]]]\n",
      "(190, 25)\n",
      "seq_array_test_k:  [[[0.48554912 0.33333334 0.         ... 0.         0.46456692 0.52650225]\n",
      "  [0.44508672 0.25       0.         ... 0.         0.33070865 0.61706346]\n",
      "  [0.31791908 0.25       0.         ... 0.         0.28346458 0.39328232]\n",
      "  ...\n",
      "  [0.45086706 0.33333334 0.         ... 0.         0.15748031 0.20989229]\n",
      "  [0.58381504 0.5833333  0.         ... 0.         0.38582677 0.2154195 ]\n",
      "  [0.4913295  0.6666667  0.         ... 0.         0.20472442 0.21712019]]]\n",
      "(200, 25)\n",
      "seq_array_test_k:  [[[0.75722545 0.75       0.         ... 0.         0.46456692 0.43480727]\n",
      "  [0.43930635 0.33333334 0.         ... 0.         0.51968503 0.5510204 ]\n",
      "  [0.43930635 0.25       0.         ... 0.         0.48031497 0.30753967]\n",
      "  ...\n",
      "  [0.5202312  0.5        0.         ... 0.         0.22047244 0.03713152]\n",
      "  [0.433526   0.75       0.         ... 0.         0.10236221 0.22236395]\n",
      "  [0.31213874 0.08333334 0.         ... 0.         0.16535433 0.20564058]]]\n"
     ]
    }
   ],
   "source": [
    "def calculate_probabilities(estimator, pdm_df, scaler, params, cols_normalize_train, sequence_cols):\n",
    "    \n",
    "    for id in pdm_df['id'].unique():\n",
    "        # Loop through each decision point\n",
    "        for cycle in range(pdm_df[pdm_df['id']==id].shape[0]-params+1):\n",
    "            if cycle in array_decisions:\n",
    "                # Prepare data                           \n",
    "                norm_pdm_df = pd.DataFrame(scaler.transform(pdm_df[pdm_df['id']==id][cols_normalize_train][:params+cycle]),\n",
    "                 columns=cols_normalize_train,\n",
    "                 index=pdm_df[pdm_df['id']==id][:params+cycle].index)\n",
    "                print(norm_pdm_df.shape)\n",
    "                join_df = pdm_df[pdm_df['id']==id][:params+cycle][pdm_df[pdm_df['id']==id][:params+cycle].columns.difference(cols_normalize_train)].join(norm_pdm_df)\n",
    "                pdm_df_eval_online = join_df.reindex(columns = pdm_df[pdm_df['id']==id][cycle:params+cycle].columns)\n",
    "\n",
    "                seq_array_test_k = pdm_df_eval_online[sequence_cols].values[cycle:params+cycle]\n",
    "                seq_array_test_k = np.asarray(seq_array_test_k).astype(np.float32).reshape(1,params, len(sequence_cols))\n",
    "                                \n",
    "                #prob_RUL_smaller_DT    = estimator.predict(seq_array_validation_k).reshape(3)[2]\n",
    "                probabilities    = estimator.predict(seq_array_test_k).reshape(3)\n",
    "\n",
    "                # Predict\n",
    "                #with torch.no_grad():\n",
    "                 #   outputs = estimator(seq_tensor).squeeze()\n",
    "                #probabilities = torch.softmax(outputs, dim=1).cpu().numpy()\n",
    "                print(\"probabilities: \", probabilities)\n",
    "                #print(\"seq_array_test_k: \", seq_array_test_k)\n",
    "                \n",
    "                \n",
    "    return probabilities\n",
    "\n",
    "probabilities= calculate_probabilities(estimator, validation_df, min_max_scaler, sequence_length, cols_normalize, sequence_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "jG8Lip5w6Pt_",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 81\n",
      "(50, 25)\n",
      "(1, 50, 25)\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fd49ee927a0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fd49ee927a0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - 1s 724ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "prob_RUL_smaller_w1: 0.0003450279\n",
      "prob_RUL_smaller_DT: 7.4905634e-05\n",
      "(60, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "prob_RUL_smaller_w1: 0.00023959561\n",
      "prob_RUL_smaller_DT: 6.243493e-05\n",
      "(70, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "prob_RUL_smaller_w1: 0.0002938444\n",
      "prob_RUL_smaller_DT: 6.8955516e-05\n",
      "(80, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "prob_RUL_smaller_w1: 0.00036564202\n",
      "prob_RUL_smaller_DT: 7.509949e-05\n",
      "(90, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.0004004714\n",
      "prob_RUL_smaller_DT: 7.710036e-05\n",
      "(100, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "prob_RUL_smaller_w1: 0.00028379526\n",
      "prob_RUL_smaller_DT: 6.356979e-05\n",
      "(110, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "prob_RUL_smaller_w1: 0.00031937246\n",
      "prob_RUL_smaller_DT: 6.995845e-05\n",
      "(120, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "prob_RUL_smaller_w1: 0.00045025095\n",
      "prob_RUL_smaller_DT: 7.8704754e-05\n",
      "(130, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "prob_RUL_smaller_w1: 0.0013609803\n",
      "prob_RUL_smaller_DT: 0.00013490292\n",
      "(140, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "prob_RUL_smaller_w1: 0.00079187093\n",
      "prob_RUL_smaller_DT: 9.631077e-05\n",
      "(150, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "prob_RUL_smaller_w1: 0.00076301215\n",
      "prob_RUL_smaller_DT: 9.3640614e-05\n",
      "(160, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "prob_RUL_smaller_w1: 0.00062805094\n",
      "prob_RUL_smaller_DT: 8.4848194e-05\n",
      "(170, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "prob_RUL_smaller_w1: 0.0013242534\n",
      "prob_RUL_smaller_DT: 0.00012238613\n",
      "(180, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.004935699\n",
      "prob_RUL_smaller_DT: 0.00024442887\n",
      "(190, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "prob_RUL_smaller_w1: 0.031714268\n",
      "prob_RUL_smaller_DT: 0.00072824216\n",
      "(200, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "prob_RUL_smaller_w1: 0.3021872\n",
      "prob_RUL_smaller_DT: 0.0028032016\n",
      "prob_RUL_smaller_w1: 0.3021872\n",
      "prob_RUL_smaller_DT: 0.0028032016\n",
      "component ordering at cycle: 200.0\n",
      "(210, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "prob_RUL_smaller_w1: 0.86934966\n",
      "prob_RUL_smaller_DT: 0.006798307\n",
      "(220, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "prob_RUL_smaller_w1: 0.9338299\n",
      "prob_RUL_smaller_DT: 0.051550873\n",
      "(230, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "prob_RUL_smaller_w1: 0.72280043\n",
      "prob_RUL_smaller_DT: 0.26683104\n",
      "prob_RUL_smaller_DT: 0.26683104\n",
      "preventive replacement informed at cycle: 230.0\n",
      "True failure: 240\n",
      "-----------------------------------------\n",
      "ID: 82\n",
      "(50, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "prob_RUL_smaller_w1: 0.000101965525\n",
      "prob_RUL_smaller_DT: 5.5161454e-05\n",
      "(60, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 9.7929355e-05\n",
      "prob_RUL_smaller_DT: 5.2829375e-05\n",
      "(70, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "prob_RUL_smaller_w1: 0.00010833069\n",
      "prob_RUL_smaller_DT: 5.6135446e-05\n",
      "(80, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.000111115995\n",
      "prob_RUL_smaller_DT: 5.600675e-05\n",
      "(90, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "prob_RUL_smaller_w1: 0.00012325913\n",
      "prob_RUL_smaller_DT: 6.0781433e-05\n",
      "(100, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "prob_RUL_smaller_w1: 0.000114768336\n",
      "prob_RUL_smaller_DT: 5.6161967e-05\n",
      "(110, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "prob_RUL_smaller_w1: 0.0001286507\n",
      "prob_RUL_smaller_DT: 6.0498216e-05\n",
      "(120, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "prob_RUL_smaller_w1: 0.00014921704\n",
      "prob_RUL_smaller_DT: 6.2927444e-05\n",
      "(130, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.00024814333\n",
      "prob_RUL_smaller_DT: 8.177624e-05\n",
      "(140, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "prob_RUL_smaller_w1: 0.00035655973\n",
      "prob_RUL_smaller_DT: 8.9748726e-05\n",
      "(150, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "prob_RUL_smaller_w1: 0.0003911966\n",
      "prob_RUL_smaller_DT: 8.707695e-05\n",
      "(160, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "prob_RUL_smaller_w1: 0.00063514424\n",
      "prob_RUL_smaller_DT: 0.00010924895\n",
      "(170, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "prob_RUL_smaller_w1: 0.0034238049\n",
      "prob_RUL_smaller_DT: 0.00025709928\n",
      "(180, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "prob_RUL_smaller_w1: 0.18678705\n",
      "prob_RUL_smaller_DT: 0.0021541435\n",
      "prob_RUL_smaller_w1: 0.18678705\n",
      "prob_RUL_smaller_DT: 0.0021541435\n",
      "component ordering at cycle: 180.0\n",
      "(190, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.88185936\n",
      "prob_RUL_smaller_DT: 0.0035128708\n",
      "(200, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "prob_RUL_smaller_w1: 0.73898304\n",
      "prob_RUL_smaller_DT: 0.25619984\n",
      "prob_RUL_smaller_DT: 0.25619984\n",
      "preventive replacement informed at cycle: 200.0\n",
      "True failure: 214\n",
      "-----------------------------------------\n",
      "ID: 83\n",
      "(50, 25)\n",
      "(1, 50, 25)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "prob_RUL_smaller_w1: 9.379383e-05\n",
      "prob_RUL_smaller_DT: 5.3225995e-05\n",
      "(60, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "prob_RUL_smaller_w1: 9.0912996e-05\n",
      "prob_RUL_smaller_DT: 5.1813808e-05\n",
      "(70, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "prob_RUL_smaller_w1: 9.39818e-05\n",
      "prob_RUL_smaller_DT: 5.2913234e-05\n",
      "(80, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 9.472518e-05\n",
      "prob_RUL_smaller_DT: 5.255684e-05\n",
      "(90, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "prob_RUL_smaller_w1: 9.958778e-05\n",
      "prob_RUL_smaller_DT: 5.4111486e-05\n",
      "(100, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "prob_RUL_smaller_w1: 0.00011624222\n",
      "prob_RUL_smaller_DT: 6.0171296e-05\n",
      "(110, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "prob_RUL_smaller_w1: 0.000102668826\n",
      "prob_RUL_smaller_DT: 5.3924647e-05\n",
      "(120, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "prob_RUL_smaller_w1: 0.000112197646\n",
      "prob_RUL_smaller_DT: 5.599072e-05\n",
      "(130, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.00011429221\n",
      "prob_RUL_smaller_DT: 5.576105e-05\n",
      "(140, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "prob_RUL_smaller_w1: 0.000116114796\n",
      "prob_RUL_smaller_DT: 5.653314e-05\n",
      "(150, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "prob_RUL_smaller_w1: 0.00014482789\n",
      "prob_RUL_smaller_DT: 6.172897e-05\n",
      "(160, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "prob_RUL_smaller_w1: 0.00013182548\n",
      "prob_RUL_smaller_DT: 5.609453e-05\n",
      "(170, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "prob_RUL_smaller_w1: 0.00015118906\n",
      "prob_RUL_smaller_DT: 5.9921655e-05\n",
      "(180, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "prob_RUL_smaller_w1: 0.00016877023\n",
      "prob_RUL_smaller_DT: 6.0749808e-05\n",
      "(190, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "prob_RUL_smaller_w1: 0.00021097175\n",
      "prob_RUL_smaller_DT: 6.677068e-05\n",
      "(200, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "prob_RUL_smaller_w1: 0.00032955856\n",
      "prob_RUL_smaller_DT: 7.661768e-05\n",
      "(210, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "prob_RUL_smaller_w1: 0.00038885375\n",
      "prob_RUL_smaller_DT: 8.031838e-05\n",
      "(220, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "prob_RUL_smaller_w1: 0.00044115112\n",
      "prob_RUL_smaller_DT: 8.243843e-05\n",
      "(230, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.0003970946\n",
      "prob_RUL_smaller_DT: 7.572188e-05\n",
      "(240, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "prob_RUL_smaller_w1: 0.0010228525\n",
      "prob_RUL_smaller_DT: 0.00011810215\n",
      "(250, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "prob_RUL_smaller_w1: 0.0081565585\n",
      "prob_RUL_smaller_DT: 0.0003303263\n",
      "(260, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "prob_RUL_smaller_w1: 0.070946835\n",
      "prob_RUL_smaller_DT: 0.0011314511\n",
      "(270, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "prob_RUL_smaller_w1: 0.65803266\n",
      "prob_RUL_smaller_DT: 0.0037631968\n",
      "prob_RUL_smaller_w1: 0.65803266\n",
      "prob_RUL_smaller_DT: 0.0037631968\n",
      "component ordering at cycle: 270.0\n",
      "(280, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "prob_RUL_smaller_w1: 0.95707583\n",
      "prob_RUL_smaller_DT: 0.034261726\n",
      "(290, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "prob_RUL_smaller_w1: 0.02233337\n",
      "prob_RUL_smaller_DT: 0.9771375\n",
      "prob_RUL_smaller_DT: 0.9771375\n",
      "preventive replacement informed at cycle: 290.0\n",
      "True failure: 293\n",
      "-----------------------------------------\n",
      "ID: 84\n",
      "(50, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.00023154395\n",
      "prob_RUL_smaller_DT: 5.259091e-05\n",
      "(60, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "prob_RUL_smaller_w1: 0.00022167462\n",
      "prob_RUL_smaller_DT: 5.1007435e-05\n",
      "(70, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.00024059419\n",
      "prob_RUL_smaller_DT: 5.2536947e-05\n",
      "(80, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "prob_RUL_smaller_w1: 0.00025076058\n",
      "prob_RUL_smaller_DT: 5.35981e-05\n",
      "(90, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "prob_RUL_smaller_w1: 0.0002907333\n",
      "prob_RUL_smaller_DT: 5.795179e-05\n",
      "(100, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "prob_RUL_smaller_w1: 0.00033565416\n",
      "prob_RUL_smaller_DT: 6.048009e-05\n",
      "(110, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "prob_RUL_smaller_w1: 0.0003015969\n",
      "prob_RUL_smaller_DT: 5.749494e-05\n",
      "(120, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "prob_RUL_smaller_w1: 0.00031985727\n",
      "prob_RUL_smaller_DT: 5.9391856e-05\n",
      "(130, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.0002684512\n",
      "prob_RUL_smaller_DT: 5.3985666e-05\n",
      "(140, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "prob_RUL_smaller_w1: 0.000394633\n",
      "prob_RUL_smaller_DT: 6.6729575e-05\n",
      "(150, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "prob_RUL_smaller_w1: 0.00038920713\n",
      "prob_RUL_smaller_DT: 6.693528e-05\n",
      "(160, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "prob_RUL_smaller_w1: 0.0010132072\n",
      "prob_RUL_smaller_DT: 0.00010510182\n",
      "(170, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "prob_RUL_smaller_w1: 0.0017077303\n",
      "prob_RUL_smaller_DT: 0.00013923687\n",
      "(180, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "prob_RUL_smaller_w1: 0.0012790615\n",
      "prob_RUL_smaller_DT: 0.0001174323\n",
      "(190, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "prob_RUL_smaller_w1: 0.0009813885\n",
      "prob_RUL_smaller_DT: 0.00010706581\n",
      "(200, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "prob_RUL_smaller_w1: 0.0009917854\n",
      "prob_RUL_smaller_DT: 0.000107806925\n",
      "(210, 25)\n",
      "(1, 50, 25)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.0049101776\n",
      "prob_RUL_smaller_DT: 0.00025793636\n",
      "(220, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "prob_RUL_smaller_w1: 0.06357027\n",
      "prob_RUL_smaller_DT: 0.0012546367\n",
      "(230, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "prob_RUL_smaller_w1: 0.17725195\n",
      "prob_RUL_smaller_DT: 0.0027338236\n",
      "prob_RUL_smaller_w1: 0.17725195\n",
      "prob_RUL_smaller_DT: 0.0027338236\n",
      "component ordering at cycle: 230.0\n",
      "(240, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.37421903\n",
      "prob_RUL_smaller_DT: 0.004485946\n",
      "(250, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.9396799\n",
      "prob_RUL_smaller_DT: 0.012277887\n",
      "(260, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "prob_RUL_smaller_w1: 0.7059841\n",
      "prob_RUL_smaller_DT: 0.28518137\n",
      "prob_RUL_smaller_DT: 0.28518137\n",
      "preventive replacement informed at cycle: 260.0\n",
      "True failure: 267\n",
      "-----------------------------------------\n",
      "ID: 85\n",
      "(50, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.00021318355\n",
      "prob_RUL_smaller_DT: 5.7942576e-05\n",
      "(60, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.00027436172\n",
      "prob_RUL_smaller_DT: 6.5084205e-05\n",
      "(70, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "prob_RUL_smaller_w1: 0.00018385492\n",
      "prob_RUL_smaller_DT: 5.3036278e-05\n",
      "(80, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.00023451532\n",
      "prob_RUL_smaller_DT: 6.0427235e-05\n",
      "(90, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "prob_RUL_smaller_w1: 0.00038278193\n",
      "prob_RUL_smaller_DT: 7.52451e-05\n",
      "(100, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "prob_RUL_smaller_w1: 0.00058473577\n",
      "prob_RUL_smaller_DT: 8.771752e-05\n",
      "(110, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.0005554597\n",
      "prob_RUL_smaller_DT: 8.350952e-05\n",
      "(120, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "prob_RUL_smaller_w1: 0.001546747\n",
      "prob_RUL_smaller_DT: 0.00014249756\n",
      "(130, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.00497384\n",
      "prob_RUL_smaller_DT: 0.00023815251\n",
      "(140, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "prob_RUL_smaller_w1: 0.008058695\n",
      "prob_RUL_smaller_DT: 0.00029715986\n",
      "(150, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.010595716\n",
      "prob_RUL_smaller_DT: 0.00035451708\n",
      "(160, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.39921212\n",
      "prob_RUL_smaller_DT: 0.002848708\n",
      "prob_RUL_smaller_w1: 0.39921212\n",
      "prob_RUL_smaller_DT: 0.002848708\n",
      "component ordering at cycle: 160.0\n",
      "(170, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "prob_RUL_smaller_w1: 0.96491766\n",
      "prob_RUL_smaller_DT: 0.023054637\n",
      "(180, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "prob_RUL_smaller_w1: 0.13969551\n",
      "prob_RUL_smaller_DT: 0.85784316\n",
      "prob_RUL_smaller_DT: 0.85784316\n",
      "preventive replacement informed at cycle: 180.0\n",
      "True failure: 188\n",
      "-----------------------------------------\n",
      "ID: 86\n",
      "(50, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "prob_RUL_smaller_w1: 0.0003201705\n",
      "prob_RUL_smaller_DT: 7.383351e-05\n",
      "(60, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.00027596948\n",
      "prob_RUL_smaller_DT: 6.8505426e-05\n",
      "(70, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "prob_RUL_smaller_w1: 0.00028192953\n",
      "prob_RUL_smaller_DT: 6.7499896e-05\n",
      "(80, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "prob_RUL_smaller_w1: 0.0003091813\n",
      "prob_RUL_smaller_DT: 6.887638e-05\n",
      "(90, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "prob_RUL_smaller_w1: 0.00024296094\n",
      "prob_RUL_smaller_DT: 6.109864e-05\n",
      "(100, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.00024035765\n",
      "prob_RUL_smaller_DT: 6.184633e-05\n",
      "(110, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.00024220806\n",
      "prob_RUL_smaller_DT: 6.230469e-05\n",
      "(120, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "prob_RUL_smaller_w1: 0.00039358175\n",
      "prob_RUL_smaller_DT: 7.690924e-05\n",
      "(130, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "prob_RUL_smaller_w1: 0.00051014806\n",
      "prob_RUL_smaller_DT: 8.2838254e-05\n",
      "(140, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.00027430526\n",
      "prob_RUL_smaller_DT: 6.0196904e-05\n",
      "(150, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "prob_RUL_smaller_w1: 0.00039644525\n",
      "prob_RUL_smaller_DT: 7.4685966e-05\n",
      "(160, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "prob_RUL_smaller_w1: 0.00045176444\n",
      "prob_RUL_smaller_DT: 7.8713936e-05\n",
      "(170, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "prob_RUL_smaller_w1: 0.00047292883\n",
      "prob_RUL_smaller_DT: 7.8169454e-05\n",
      "(180, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "prob_RUL_smaller_w1: 0.0008534119\n",
      "prob_RUL_smaller_DT: 0.000106748485\n",
      "(190, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.0039680996\n",
      "prob_RUL_smaller_DT: 0.00023385268\n",
      "(200, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "prob_RUL_smaller_w1: 0.0058439975\n",
      "prob_RUL_smaller_DT: 0.00028649886\n",
      "(210, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "prob_RUL_smaller_w1: 0.0035026032\n",
      "prob_RUL_smaller_DT: 0.00021941129\n",
      "(220, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "prob_RUL_smaller_w1: 0.00745964\n",
      "prob_RUL_smaller_DT: 0.00032905737\n",
      "(230, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "prob_RUL_smaller_w1: 0.01936159\n",
      "prob_RUL_smaller_DT: 0.0005765215\n",
      "(240, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "prob_RUL_smaller_w1: 0.06858659\n",
      "prob_RUL_smaller_DT: 0.0013373177\n",
      "(250, 25)\n",
      "(1, 50, 25)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.8718283\n",
      "prob_RUL_smaller_DT: 0.0067370436\n",
      "prob_RUL_smaller_w1: 0.8718283\n",
      "prob_RUL_smaller_DT: 0.0067370436\n",
      "component ordering at cycle: 250.0\n",
      "(260, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "prob_RUL_smaller_w1: 0.81722677\n",
      "prob_RUL_smaller_DT: 0.17233896\n",
      "prob_RUL_smaller_DT: 0.17233896\n",
      "preventive replacement informed at cycle: 260.0\n",
      "True failure: 278\n",
      "-----------------------------------------\n",
      "ID: 87\n",
      "(50, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "prob_RUL_smaller_w1: 0.00027043006\n",
      "prob_RUL_smaller_DT: 6.44044e-05\n",
      "(60, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "prob_RUL_smaller_w1: 0.00041129734\n",
      "prob_RUL_smaller_DT: 7.988608e-05\n",
      "(70, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.0017731048\n",
      "prob_RUL_smaller_DT: 0.00015696452\n",
      "(80, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "prob_RUL_smaller_w1: 0.0006687211\n",
      "prob_RUL_smaller_DT: 9.115884e-05\n",
      "(90, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "prob_RUL_smaller_w1: 0.0005249292\n",
      "prob_RUL_smaller_DT: 8.349145e-05\n",
      "(100, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "prob_RUL_smaller_w1: 0.0006271435\n",
      "prob_RUL_smaller_DT: 9.191612e-05\n",
      "(110, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "prob_RUL_smaller_w1: 0.0009006861\n",
      "prob_RUL_smaller_DT: 0.00010474075\n",
      "(120, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "prob_RUL_smaller_w1: 0.0030211236\n",
      "prob_RUL_smaller_DT: 0.00018475596\n",
      "(130, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "prob_RUL_smaller_w1: 0.024804166\n",
      "prob_RUL_smaller_DT: 0.00057893596\n",
      "(140, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "prob_RUL_smaller_w1: 0.43402344\n",
      "prob_RUL_smaller_DT: 0.002952134\n",
      "prob_RUL_smaller_w1: 0.43402344\n",
      "prob_RUL_smaller_DT: 0.002952134\n",
      "component ordering at cycle: 140.0\n",
      "(150, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "prob_RUL_smaller_w1: 0.49604034\n",
      "prob_RUL_smaller_DT: 0.0035089587\n",
      "(160, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "prob_RUL_smaller_w1: 0.95739764\n",
      "prob_RUL_smaller_DT: 0.030571526\n",
      "(170, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "prob_RUL_smaller_w1: 0.06359921\n",
      "prob_RUL_smaller_DT: 0.9350199\n",
      "prob_RUL_smaller_DT: 0.9350199\n",
      "preventive replacement informed at cycle: 170.0\n",
      "True failure: 178\n",
      "-----------------------------------------\n",
      "ID: 88\n",
      "(50, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "prob_RUL_smaller_w1: 0.00025137747\n",
      "prob_RUL_smaller_DT: 7.553696e-05\n",
      "(60, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "prob_RUL_smaller_w1: 0.0002929162\n",
      "prob_RUL_smaller_DT: 7.515819e-05\n",
      "(70, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "prob_RUL_smaller_w1: 0.00020362489\n",
      "prob_RUL_smaller_DT: 6.0197715e-05\n",
      "(80, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.00021251819\n",
      "prob_RUL_smaller_DT: 6.319762e-05\n",
      "(90, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.00021917273\n",
      "prob_RUL_smaller_DT: 6.582541e-05\n",
      "(100, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.00029940566\n",
      "prob_RUL_smaller_DT: 7.3120624e-05\n",
      "(110, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "prob_RUL_smaller_w1: 0.00049342687\n",
      "prob_RUL_smaller_DT: 9.116657e-05\n",
      "(120, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "prob_RUL_smaller_w1: 0.00092452974\n",
      "prob_RUL_smaller_DT: 0.00012222014\n",
      "(130, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "prob_RUL_smaller_w1: 0.0009766868\n",
      "prob_RUL_smaller_DT: 0.00011801518\n",
      "(140, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.00070001656\n",
      "prob_RUL_smaller_DT: 9.822555e-05\n",
      "(150, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.0012376698\n",
      "prob_RUL_smaller_DT: 0.00013181784\n",
      "(160, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "prob_RUL_smaller_w1: 0.0064035244\n",
      "prob_RUL_smaller_DT: 0.00032301608\n",
      "(170, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "prob_RUL_smaller_w1: 0.049197607\n",
      "prob_RUL_smaller_DT: 0.000960401\n",
      "(180, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "prob_RUL_smaller_w1: 0.77271\n",
      "prob_RUL_smaller_DT: 0.0036355748\n",
      "prob_RUL_smaller_w1: 0.77271\n",
      "prob_RUL_smaller_DT: 0.0036355748\n",
      "component ordering at cycle: 180.0\n",
      "(190, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.9728578\n",
      "prob_RUL_smaller_DT: 0.015821269\n",
      "(200, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "prob_RUL_smaller_w1: 0.17317215\n",
      "prob_RUL_smaller_DT: 0.8241142\n",
      "prob_RUL_smaller_DT: 0.8241142\n",
      "preventive replacement informed at cycle: 200.0\n",
      "True failure: 213\n",
      "-----------------------------------------\n",
      "ID: 89\n",
      "(50, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "prob_RUL_smaller_w1: 0.00011429915\n",
      "prob_RUL_smaller_DT: 5.322222e-05\n",
      "(60, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "prob_RUL_smaller_w1: 0.00012174193\n",
      "prob_RUL_smaller_DT: 5.4792068e-05\n",
      "(70, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "prob_RUL_smaller_w1: 0.00013969213\n",
      "prob_RUL_smaller_DT: 5.830514e-05\n",
      "(80, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "prob_RUL_smaller_w1: 0.0001600228\n",
      "prob_RUL_smaller_DT: 6.215106e-05\n",
      "(90, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "prob_RUL_smaller_w1: 0.00016509251\n",
      "prob_RUL_smaller_DT: 5.9248865e-05\n",
      "(100, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "prob_RUL_smaller_w1: 0.0001839926\n",
      "prob_RUL_smaller_DT: 6.050127e-05\n",
      "(110, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "prob_RUL_smaller_w1: 0.00018544313\n",
      "prob_RUL_smaller_DT: 5.9985356e-05\n",
      "(120, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.00021668465\n",
      "prob_RUL_smaller_DT: 6.215809e-05\n",
      "(130, 25)\n",
      "(1, 50, 25)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.00027416318\n",
      "prob_RUL_smaller_DT: 6.918543e-05\n",
      "(140, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "prob_RUL_smaller_w1: 0.0003398626\n",
      "prob_RUL_smaller_DT: 7.266156e-05\n",
      "(150, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.00048169418\n",
      "prob_RUL_smaller_DT: 8.2107e-05\n",
      "(160, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "prob_RUL_smaller_w1: 0.0029662412\n",
      "prob_RUL_smaller_DT: 0.0002047251\n",
      "(170, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "prob_RUL_smaller_w1: 0.019198947\n",
      "prob_RUL_smaller_DT: 0.0005244683\n",
      "(180, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "prob_RUL_smaller_w1: 0.20558257\n",
      "prob_RUL_smaller_DT: 0.0019022088\n",
      "prob_RUL_smaller_w1: 0.20558257\n",
      "prob_RUL_smaller_DT: 0.0019022088\n",
      "component ordering at cycle: 180.0\n",
      "(190, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "prob_RUL_smaller_w1: 0.911695\n",
      "prob_RUL_smaller_DT: 0.0035890073\n",
      "(200, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.9489922\n",
      "prob_RUL_smaller_DT: 0.043746896\n",
      "(210, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "prob_RUL_smaller_w1: 0.013375198\n",
      "prob_RUL_smaller_DT: 0.98629016\n",
      "prob_RUL_smaller_DT: 0.98629016\n",
      "preventive replacement informed at cycle: 210.0\n",
      "True failure: 217\n",
      "-----------------------------------------\n",
      "ID: 90\n",
      "(50, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.0001173485\n",
      "prob_RUL_smaller_DT: 5.59608e-05\n",
      "(60, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "prob_RUL_smaller_w1: 0.00012724234\n",
      "prob_RUL_smaller_DT: 5.7334182e-05\n",
      "(70, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "prob_RUL_smaller_w1: 0.00017996557\n",
      "prob_RUL_smaller_DT: 6.6458095e-05\n",
      "(80, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "prob_RUL_smaller_w1: 0.00020310291\n",
      "prob_RUL_smaller_DT: 6.5873435e-05\n",
      "(90, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "prob_RUL_smaller_w1: 0.0003700147\n",
      "prob_RUL_smaller_DT: 8.651993e-05\n",
      "(100, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.00053555245\n",
      "prob_RUL_smaller_DT: 9.5206815e-05\n",
      "(110, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "prob_RUL_smaller_w1: 0.0015753029\n",
      "prob_RUL_smaller_DT: 0.00015377322\n",
      "(120, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "prob_RUL_smaller_w1: 0.016521292\n",
      "prob_RUL_smaller_DT: 0.0004714791\n",
      "(130, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "prob_RUL_smaller_w1: 0.39600405\n",
      "prob_RUL_smaller_DT: 0.0024898655\n",
      "prob_RUL_smaller_w1: 0.39600405\n",
      "prob_RUL_smaller_DT: 0.0024898655\n",
      "component ordering at cycle: 130.0\n",
      "(140, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "prob_RUL_smaller_w1: 0.9681382\n",
      "prob_RUL_smaller_DT: 0.026381461\n",
      "(150, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "prob_RUL_smaller_w1: 0.008545228\n",
      "prob_RUL_smaller_DT: 0.9912526\n",
      "prob_RUL_smaller_DT: 0.9912526\n",
      "preventive replacement informed at cycle: 150.0\n",
      "True failure: 154\n",
      "-----------------------------------------\n",
      "ID: 91\n",
      "(50, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "prob_RUL_smaller_w1: 0.0018450523\n",
      "prob_RUL_smaller_DT: 0.00013902457\n",
      "(60, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "prob_RUL_smaller_w1: 0.003493082\n",
      "prob_RUL_smaller_DT: 0.00018835031\n",
      "(70, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "prob_RUL_smaller_w1: 0.0031671596\n",
      "prob_RUL_smaller_DT: 0.00018332954\n",
      "(80, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "prob_RUL_smaller_w1: 0.0039531817\n",
      "prob_RUL_smaller_DT: 0.00021325338\n",
      "(90, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "prob_RUL_smaller_w1: 0.014228562\n",
      "prob_RUL_smaller_DT: 0.00043859333\n",
      "(100, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.21246357\n",
      "prob_RUL_smaller_DT: 0.0024093434\n",
      "prob_RUL_smaller_w1: 0.21246357\n",
      "prob_RUL_smaller_DT: 0.0024093434\n",
      "component ordering at cycle: 100.0\n",
      "(110, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "prob_RUL_smaller_w1: 0.63054234\n",
      "prob_RUL_smaller_DT: 0.0062541286\n",
      "(120, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "prob_RUL_smaller_w1: 0.9568336\n",
      "prob_RUL_smaller_DT: 0.017960694\n",
      "(130, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "prob_RUL_smaller_w1: 0.12837072\n",
      "prob_RUL_smaller_DT: 0.86948997\n",
      "prob_RUL_smaller_DT: 0.86948997\n",
      "preventive replacement informed at cycle: 130.0\n",
      "True failure: 135\n",
      "-----------------------------------------\n",
      "ID: 92\n",
      "(50, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "prob_RUL_smaller_w1: 0.00017622464\n",
      "prob_RUL_smaller_DT: 6.1943196e-05\n",
      "(60, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.00022386354\n",
      "prob_RUL_smaller_DT: 6.95326e-05\n",
      "(70, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.00019180894\n",
      "prob_RUL_smaller_DT: 6.306053e-05\n",
      "(80, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "prob_RUL_smaller_w1: 0.00015022326\n",
      "prob_RUL_smaller_DT: 5.6124856e-05\n",
      "(90, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.00016475022\n",
      "prob_RUL_smaller_DT: 5.9814316e-05\n",
      "(100, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "prob_RUL_smaller_w1: 0.00021071972\n",
      "prob_RUL_smaller_DT: 6.6402084e-05\n",
      "(110, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "prob_RUL_smaller_w1: 0.00026883246\n",
      "prob_RUL_smaller_DT: 7.151757e-05\n",
      "(120, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "prob_RUL_smaller_w1: 0.00023019064\n",
      "prob_RUL_smaller_DT: 6.304337e-05\n",
      "(130, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "prob_RUL_smaller_w1: 0.00018606008\n",
      "prob_RUL_smaller_DT: 5.6702436e-05\n",
      "(140, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "prob_RUL_smaller_w1: 0.00020201436\n",
      "prob_RUL_smaller_DT: 6.132822e-05\n",
      "(150, 25)\n",
      "(1, 50, 25)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "prob_RUL_smaller_w1: 0.00020659002\n",
      "prob_RUL_smaller_DT: 6.206881e-05\n",
      "(160, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "prob_RUL_smaller_w1: 0.0002091568\n",
      "prob_RUL_smaller_DT: 6.0669317e-05\n",
      "(170, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "prob_RUL_smaller_w1: 0.0002574892\n",
      "prob_RUL_smaller_DT: 6.82477e-05\n",
      "(180, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "prob_RUL_smaller_w1: 0.00021734128\n",
      "prob_RUL_smaller_DT: 6.173514e-05\n",
      "(190, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "prob_RUL_smaller_w1: 0.0002327807\n",
      "prob_RUL_smaller_DT: 6.195423e-05\n",
      "(200, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "prob_RUL_smaller_w1: 0.00033269296\n",
      "prob_RUL_smaller_DT: 7.375799e-05\n",
      "(210, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "prob_RUL_smaller_w1: 0.0003546311\n",
      "prob_RUL_smaller_DT: 7.5014934e-05\n",
      "(220, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "prob_RUL_smaller_w1: 0.0003110497\n",
      "prob_RUL_smaller_DT: 6.8684676e-05\n",
      "(230, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "prob_RUL_smaller_w1: 0.00049572036\n",
      "prob_RUL_smaller_DT: 8.7417924e-05\n",
      "(240, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "prob_RUL_smaller_w1: 0.0006698087\n",
      "prob_RUL_smaller_DT: 9.756674e-05\n",
      "(250, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "prob_RUL_smaller_w1: 0.0008584793\n",
      "prob_RUL_smaller_DT: 0.0001086473\n",
      "(260, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "prob_RUL_smaller_w1: 0.0006960734\n",
      "prob_RUL_smaller_DT: 9.571334e-05\n",
      "(270, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "prob_RUL_smaller_w1: 0.0010521805\n",
      "prob_RUL_smaller_DT: 0.000120031356\n",
      "(280, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "prob_RUL_smaller_w1: 0.010315475\n",
      "prob_RUL_smaller_DT: 0.0004422998\n",
      "(290, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "prob_RUL_smaller_w1: 0.1122132\n",
      "prob_RUL_smaller_DT: 0.0017487628\n",
      "prob_RUL_smaller_w1: 0.1122132\n",
      "prob_RUL_smaller_DT: 0.0017487628\n",
      "component ordering at cycle: 290.0\n",
      "(300, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.50071114\n",
      "prob_RUL_smaller_DT: 0.0045047826\n",
      "(310, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "prob_RUL_smaller_w1: 0.4910514\n",
      "prob_RUL_smaller_DT: 0.0055160765\n",
      "(320, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.87058187\n",
      "prob_RUL_smaller_DT: 0.009972535\n",
      "(330, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "prob_RUL_smaller_w1: 0.7549309\n",
      "prob_RUL_smaller_DT: 0.2363729\n",
      "prob_RUL_smaller_DT: 0.2363729\n",
      "preventive replacement informed at cycle: 330.0\n",
      "True failure: 341\n",
      "-----------------------------------------\n",
      "ID: 93\n",
      "(50, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "prob_RUL_smaller_w1: 0.00014497948\n",
      "prob_RUL_smaller_DT: 5.9811733e-05\n",
      "(60, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "prob_RUL_smaller_w1: 0.0001622742\n",
      "prob_RUL_smaller_DT: 6.3727675e-05\n",
      "(70, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "prob_RUL_smaller_w1: 0.00022708057\n",
      "prob_RUL_smaller_DT: 7.454868e-05\n",
      "(80, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "prob_RUL_smaller_w1: 0.0003358348\n",
      "prob_RUL_smaller_DT: 8.499279e-05\n",
      "(90, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "prob_RUL_smaller_w1: 0.00060106587\n",
      "prob_RUL_smaller_DT: 0.00010217813\n",
      "(100, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "prob_RUL_smaller_w1: 0.00064991205\n",
      "prob_RUL_smaller_DT: 0.000100220066\n",
      "(110, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "prob_RUL_smaller_w1: 0.0040526823\n",
      "prob_RUL_smaller_DT: 0.00025727358\n",
      "(120, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "prob_RUL_smaller_w1: 0.4283952\n",
      "prob_RUL_smaller_DT: 0.0029068056\n",
      "prob_RUL_smaller_w1: 0.4283952\n",
      "prob_RUL_smaller_DT: 0.0029068056\n",
      "component ordering at cycle: 120.0\n",
      "(130, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "prob_RUL_smaller_w1: 0.97708875\n",
      "prob_RUL_smaller_DT: 0.004161376\n",
      "(140, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "prob_RUL_smaller_w1: 0.7315629\n",
      "prob_RUL_smaller_DT: 0.26278925\n",
      "prob_RUL_smaller_DT: 0.26278925\n",
      "preventive replacement informed at cycle: 140.0\n",
      "True failure: 155\n",
      "-----------------------------------------\n",
      "ID: 94\n",
      "(50, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "prob_RUL_smaller_w1: 0.00021021442\n",
      "prob_RUL_smaller_DT: 4.916122e-05\n",
      "(60, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "prob_RUL_smaller_w1: 0.0002241859\n",
      "prob_RUL_smaller_DT: 5.1126277e-05\n",
      "(70, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "prob_RUL_smaller_w1: 0.00024765782\n",
      "prob_RUL_smaller_DT: 5.229615e-05\n",
      "(80, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "prob_RUL_smaller_w1: 0.00021118601\n",
      "prob_RUL_smaller_DT: 4.893409e-05\n",
      "(90, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "prob_RUL_smaller_w1: 0.00021050674\n",
      "prob_RUL_smaller_DT: 5.0776653e-05\n",
      "(100, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "prob_RUL_smaller_w1: 0.00024842372\n",
      "prob_RUL_smaller_DT: 5.461476e-05\n",
      "(110, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "prob_RUL_smaller_w1: 0.0004458533\n",
      "prob_RUL_smaller_DT: 7.254918e-05\n",
      "(120, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "prob_RUL_smaller_w1: 0.00032226468\n",
      "prob_RUL_smaller_DT: 5.9211707e-05\n",
      "(130, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.00020355871\n",
      "prob_RUL_smaller_DT: 4.866836e-05\n",
      "(140, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.00024895853\n",
      "prob_RUL_smaller_DT: 5.4108878e-05\n",
      "(150, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "prob_RUL_smaller_w1: 0.00028379157\n",
      "prob_RUL_smaller_DT: 5.7389476e-05\n",
      "(160, 25)\n",
      "(1, 50, 25)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "prob_RUL_smaller_w1: 0.00038831274\n",
      "prob_RUL_smaller_DT: 6.721159e-05\n",
      "(170, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "prob_RUL_smaller_w1: 0.0008319755\n",
      "prob_RUL_smaller_DT: 0.000101560094\n",
      "(180, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "prob_RUL_smaller_w1: 0.001094514\n",
      "prob_RUL_smaller_DT: 0.000114941766\n",
      "(190, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "prob_RUL_smaller_w1: 0.00089154765\n",
      "prob_RUL_smaller_DT: 0.000103829225\n",
      "(200, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.002824966\n",
      "prob_RUL_smaller_DT: 0.00019842037\n",
      "(210, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "prob_RUL_smaller_w1: 0.0493471\n",
      "prob_RUL_smaller_DT: 0.0010429827\n",
      "(220, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "prob_RUL_smaller_w1: 0.3523366\n",
      "prob_RUL_smaller_DT: 0.0037200174\n",
      "prob_RUL_smaller_w1: 0.3523366\n",
      "prob_RUL_smaller_DT: 0.0037200174\n",
      "component ordering at cycle: 220.0\n",
      "(230, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "prob_RUL_smaller_w1: 0.7318164\n",
      "prob_RUL_smaller_DT: 0.0069924532\n",
      "(240, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "prob_RUL_smaller_w1: 0.9537303\n",
      "prob_RUL_smaller_DT: 0.016662015\n",
      "(250, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "prob_RUL_smaller_w1: 0.50124913\n",
      "prob_RUL_smaller_DT: 0.49232095\n",
      "prob_RUL_smaller_DT: 0.49232095\n",
      "preventive replacement informed at cycle: 250.0\n",
      "True failure: 258\n",
      "-----------------------------------------\n",
      "ID: 95\n",
      "(50, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.0001273194\n",
      "prob_RUL_smaller_DT: 6.2127205e-05\n",
      "(60, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.00011088919\n",
      "prob_RUL_smaller_DT: 5.4819528e-05\n",
      "(70, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "prob_RUL_smaller_w1: 0.00012648494\n",
      "prob_RUL_smaller_DT: 6.2054605e-05\n",
      "(80, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "prob_RUL_smaller_w1: 0.00011920947\n",
      "prob_RUL_smaller_DT: 5.8633912e-05\n",
      "(90, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.0001154287\n",
      "prob_RUL_smaller_DT: 5.6367644e-05\n",
      "(100, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "prob_RUL_smaller_w1: 0.0001241483\n",
      "prob_RUL_smaller_DT: 5.8831716e-05\n",
      "(110, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "prob_RUL_smaller_w1: 0.00012660291\n",
      "prob_RUL_smaller_DT: 5.949075e-05\n",
      "(120, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "prob_RUL_smaller_w1: 0.00013366627\n",
      "prob_RUL_smaller_DT: 6.029501e-05\n",
      "(130, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.00013557919\n",
      "prob_RUL_smaller_DT: 6.0122642e-05\n",
      "(140, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.00016676406\n",
      "prob_RUL_smaller_DT: 6.485397e-05\n",
      "(150, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "prob_RUL_smaller_w1: 0.00019439509\n",
      "prob_RUL_smaller_DT: 6.869073e-05\n",
      "(160, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "prob_RUL_smaller_w1: 0.00018278534\n",
      "prob_RUL_smaller_DT: 6.442182e-05\n",
      "(170, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "prob_RUL_smaller_w1: 0.00023357113\n",
      "prob_RUL_smaller_DT: 7.0134985e-05\n",
      "(180, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.00024342956\n",
      "prob_RUL_smaller_DT: 6.871126e-05\n",
      "(190, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "prob_RUL_smaller_w1: 0.00055370416\n",
      "prob_RUL_smaller_DT: 9.932838e-05\n",
      "(200, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.0006094138\n",
      "prob_RUL_smaller_DT: 9.876919e-05\n",
      "(210, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "prob_RUL_smaller_w1: 0.0008621693\n",
      "prob_RUL_smaller_DT: 0.000114901326\n",
      "(220, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "prob_RUL_smaller_w1: 0.0016294727\n",
      "prob_RUL_smaller_DT: 0.00015463236\n",
      "(230, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "prob_RUL_smaller_w1: 0.005968833\n",
      "prob_RUL_smaller_DT: 0.0003098842\n",
      "(240, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "prob_RUL_smaller_w1: 0.08503587\n",
      "prob_RUL_smaller_DT: 0.0013292427\n",
      "(250, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "prob_RUL_smaller_w1: 0.69500715\n",
      "prob_RUL_smaller_DT: 0.0039659156\n",
      "prob_RUL_smaller_w1: 0.69500715\n",
      "prob_RUL_smaller_DT: 0.0039659156\n",
      "component ordering at cycle: 250.0\n",
      "(260, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.90705097\n",
      "prob_RUL_smaller_DT: 0.0055999635\n",
      "(270, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.9633014\n",
      "prob_RUL_smaller_DT: 0.020414777\n",
      "(280, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "prob_RUL_smaller_w1: 0.021615226\n",
      "prob_RUL_smaller_DT: 0.9778817\n",
      "prob_RUL_smaller_DT: 0.9778817\n",
      "preventive replacement informed at cycle: 280.0\n",
      "True failure: 283\n",
      "-----------------------------------------\n",
      "ID: 96\n",
      "(50, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "prob_RUL_smaller_w1: 0.00016858232\n",
      "prob_RUL_smaller_DT: 6.111781e-05\n",
      "(60, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "prob_RUL_smaller_w1: 0.00015189737\n",
      "prob_RUL_smaller_DT: 5.6484078e-05\n",
      "(70, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "prob_RUL_smaller_w1: 0.00014028842\n",
      "prob_RUL_smaller_DT: 5.4360335e-05\n",
      "(80, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "prob_RUL_smaller_w1: 0.0001403985\n",
      "prob_RUL_smaller_DT: 5.57979e-05\n",
      "(90, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.00017498025\n",
      "prob_RUL_smaller_DT: 6.205135e-05\n",
      "(100, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "prob_RUL_smaller_w1: 0.00014593048\n",
      "prob_RUL_smaller_DT: 5.5258588e-05\n",
      "(110, 25)\n",
      "(1, 50, 25)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.00014683668\n",
      "prob_RUL_smaller_DT: 5.5851942e-05\n",
      "(120, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.00017291665\n",
      "prob_RUL_smaller_DT: 6.0906463e-05\n",
      "(130, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "prob_RUL_smaller_w1: 0.00017552634\n",
      "prob_RUL_smaller_DT: 6.0196824e-05\n",
      "(140, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "prob_RUL_smaller_w1: 0.00015055844\n",
      "prob_RUL_smaller_DT: 5.481359e-05\n",
      "(150, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.00021113003\n",
      "prob_RUL_smaller_DT: 6.612352e-05\n",
      "(160, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.000273026\n",
      "prob_RUL_smaller_DT: 7.156782e-05\n",
      "(170, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.0002213682\n",
      "prob_RUL_smaller_DT: 6.226352e-05\n",
      "(180, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "prob_RUL_smaller_w1: 0.0002277789\n",
      "prob_RUL_smaller_DT: 6.2735395e-05\n",
      "(190, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.00026973855\n",
      "prob_RUL_smaller_DT: 6.8516834e-05\n",
      "(200, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "prob_RUL_smaller_w1: 0.00030339815\n",
      "prob_RUL_smaller_DT: 6.920815e-05\n",
      "(210, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "prob_RUL_smaller_w1: 0.00025689395\n",
      "prob_RUL_smaller_DT: 6.1112645e-05\n",
      "(220, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.00032110044\n",
      "prob_RUL_smaller_DT: 6.8022964e-05\n",
      "(230, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.00033111614\n",
      "prob_RUL_smaller_DT: 6.640327e-05\n",
      "(240, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "prob_RUL_smaller_w1: 0.00040226986\n",
      "prob_RUL_smaller_DT: 7.388239e-05\n",
      "(250, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "prob_RUL_smaller_w1: 0.00042178316\n",
      "prob_RUL_smaller_DT: 7.424162e-05\n",
      "(260, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "prob_RUL_smaller_w1: 0.0011644561\n",
      "prob_RUL_smaller_DT: 0.000121587\n",
      "(270, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.0014218529\n",
      "prob_RUL_smaller_DT: 0.0001349822\n",
      "(280, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.0036738599\n",
      "prob_RUL_smaller_DT: 0.00022802672\n",
      "(290, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.011493264\n",
      "prob_RUL_smaller_DT: 0.0004316337\n",
      "(300, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.4158835\n",
      "prob_RUL_smaller_DT: 0.0035699578\n",
      "prob_RUL_smaller_w1: 0.4158835\n",
      "prob_RUL_smaller_DT: 0.0035699578\n",
      "component ordering at cycle: 300.0\n",
      "(310, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.82549953\n",
      "prob_RUL_smaller_DT: 0.0078040757\n",
      "(320, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "prob_RUL_smaller_w1: 0.94308966\n",
      "prob_RUL_smaller_DT: 0.033574536\n",
      "(330, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "prob_RUL_smaller_w1: 0.5412765\n",
      "prob_RUL_smaller_DT: 0.45211607\n",
      "prob_RUL_smaller_DT: 0.45211607\n",
      "preventive replacement informed at cycle: 330.0\n",
      "True failure: 336\n",
      "-----------------------------------------\n",
      "ID: 97\n",
      "(50, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "prob_RUL_smaller_w1: 0.00014385264\n",
      "prob_RUL_smaller_DT: 5.782521e-05\n",
      "(60, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.00013484964\n",
      "prob_RUL_smaller_DT: 5.5849898e-05\n",
      "(70, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "prob_RUL_smaller_w1: 0.00013470424\n",
      "prob_RUL_smaller_DT: 5.5188117e-05\n",
      "(80, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "prob_RUL_smaller_w1: 0.00014798382\n",
      "prob_RUL_smaller_DT: 5.8394628e-05\n",
      "(90, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "prob_RUL_smaller_w1: 0.00016543649\n",
      "prob_RUL_smaller_DT: 6.217645e-05\n",
      "(100, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "prob_RUL_smaller_w1: 0.00017345413\n",
      "prob_RUL_smaller_DT: 6.210023e-05\n",
      "(110, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "prob_RUL_smaller_w1: 0.00019525808\n",
      "prob_RUL_smaller_DT: 6.328435e-05\n",
      "(120, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.00023297245\n",
      "prob_RUL_smaller_DT: 6.713588e-05\n",
      "(130, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.00030527558\n",
      "prob_RUL_smaller_DT: 7.5330616e-05\n",
      "(140, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "prob_RUL_smaller_w1: 0.00034505402\n",
      "prob_RUL_smaller_DT: 7.8381294e-05\n",
      "(150, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "prob_RUL_smaller_w1: 0.0006535395\n",
      "prob_RUL_smaller_DT: 0.00010791801\n",
      "(160, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "prob_RUL_smaller_w1: 0.0031343661\n",
      "prob_RUL_smaller_DT: 0.00023914392\n",
      "(170, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.1531904\n",
      "prob_RUL_smaller_DT: 0.001915309\n",
      "prob_RUL_smaller_w1: 0.1531904\n",
      "prob_RUL_smaller_DT: 0.001915309\n",
      "component ordering at cycle: 170.0\n",
      "(180, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "prob_RUL_smaller_w1: 0.91671723\n",
      "prob_RUL_smaller_DT: 0.0035159276\n",
      "(190, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "prob_RUL_smaller_w1: 0.63752395\n",
      "prob_RUL_smaller_DT: 0.357788\n",
      "prob_RUL_smaller_DT: 0.357788\n",
      "preventive replacement informed at cycle: 190.0\n",
      "True failure: 202\n",
      "-----------------------------------------\n",
      "ID: 98\n",
      "(50, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "prob_RUL_smaller_w1: 0.00015426817\n",
      "prob_RUL_smaller_DT: 6.500593e-05\n",
      "(60, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "prob_RUL_smaller_w1: 0.00015491707\n",
      "prob_RUL_smaller_DT: 6.1032857e-05\n",
      "(70, 25)\n",
      "(1, 50, 25)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "prob_RUL_smaller_w1: 0.00017830956\n",
      "prob_RUL_smaller_DT: 6.293756e-05\n",
      "(80, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "prob_RUL_smaller_w1: 0.00024598604\n",
      "prob_RUL_smaller_DT: 7.4197844e-05\n",
      "(90, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "prob_RUL_smaller_w1: 0.00042868298\n",
      "prob_RUL_smaller_DT: 9.112823e-05\n",
      "(100, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "prob_RUL_smaller_w1: 0.0007739748\n",
      "prob_RUL_smaller_DT: 0.000111014306\n",
      "(110, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "prob_RUL_smaller_w1: 0.0025060256\n",
      "prob_RUL_smaller_DT: 0.00019221567\n",
      "(120, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "prob_RUL_smaller_w1: 0.054702364\n",
      "prob_RUL_smaller_DT: 0.0009473801\n",
      "(130, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "prob_RUL_smaller_w1: 0.91228855\n",
      "prob_RUL_smaller_DT: 0.0029626966\n",
      "prob_RUL_smaller_w1: 0.91228855\n",
      "prob_RUL_smaller_DT: 0.0029626966\n",
      "component ordering at cycle: 130.0\n",
      "(140, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "prob_RUL_smaller_w1: 0.962015\n",
      "prob_RUL_smaller_DT: 0.03161376\n",
      "(150, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.013086624\n",
      "prob_RUL_smaller_DT: 0.9866158\n",
      "prob_RUL_smaller_DT: 0.9866158\n",
      "preventive replacement informed at cycle: 150.0\n",
      "True failure: 156\n",
      "-----------------------------------------\n",
      "ID: 99\n",
      "(50, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "prob_RUL_smaller_w1: 0.0001626045\n",
      "prob_RUL_smaller_DT: 6.0547125e-05\n",
      "(60, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.00020115607\n",
      "prob_RUL_smaller_DT: 6.6514134e-05\n",
      "(70, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.00015694159\n",
      "prob_RUL_smaller_DT: 5.752245e-05\n",
      "(80, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.00015478702\n",
      "prob_RUL_smaller_DT: 5.8823913e-05\n",
      "(90, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "prob_RUL_smaller_w1: 0.00025197747\n",
      "prob_RUL_smaller_DT: 7.407989e-05\n",
      "(100, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "prob_RUL_smaller_w1: 0.00030856018\n",
      "prob_RUL_smaller_DT: 7.608386e-05\n",
      "(110, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "prob_RUL_smaller_w1: 0.00064477307\n",
      "prob_RUL_smaller_DT: 9.984618e-05\n",
      "(120, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "prob_RUL_smaller_w1: 0.0011485267\n",
      "prob_RUL_smaller_DT: 0.00012779498\n",
      "(130, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "prob_RUL_smaller_w1: 0.0014105072\n",
      "prob_RUL_smaller_DT: 0.00014151611\n",
      "(140, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "prob_RUL_smaller_w1: 0.004677856\n",
      "prob_RUL_smaller_DT: 0.0002437292\n",
      "(150, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "prob_RUL_smaller_w1: 0.1985287\n",
      "prob_RUL_smaller_DT: 0.0018830936\n",
      "prob_RUL_smaller_w1: 0.1985287\n",
      "prob_RUL_smaller_DT: 0.0018830936\n",
      "component ordering at cycle: 150.0\n",
      "(160, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "prob_RUL_smaller_w1: 0.9090569\n",
      "prob_RUL_smaller_DT: 0.0034508314\n",
      "(170, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "prob_RUL_smaller_w1: 0.9219375\n",
      "prob_RUL_smaller_DT: 0.07189084\n",
      "(180, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "prob_RUL_smaller_w1: 0.009375438\n",
      "prob_RUL_smaller_DT: 0.99038625\n",
      "prob_RUL_smaller_DT: 0.99038625\n",
      "preventive replacement informed at cycle: 180.0\n",
      "True failure: 185\n",
      "-----------------------------------------\n",
      "ID: 100\n",
      "(50, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "prob_RUL_smaller_w1: 0.00022310589\n",
      "prob_RUL_smaller_DT: 6.153665e-05\n",
      "(60, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "prob_RUL_smaller_w1: 0.0002836887\n",
      "prob_RUL_smaller_DT: 7.180665e-05\n",
      "(70, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "prob_RUL_smaller_w1: 0.00064345414\n",
      "prob_RUL_smaller_DT: 0.00010410059\n",
      "(80, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "prob_RUL_smaller_w1: 0.00046956554\n",
      "prob_RUL_smaller_DT: 8.072282e-05\n",
      "(90, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "prob_RUL_smaller_w1: 0.00070598006\n",
      "prob_RUL_smaller_DT: 9.5992174e-05\n",
      "(100, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.0005940764\n",
      "prob_RUL_smaller_DT: 8.911277e-05\n",
      "(110, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.0005956024\n",
      "prob_RUL_smaller_DT: 8.849083e-05\n",
      "(120, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.00034106596\n",
      "prob_RUL_smaller_DT: 6.657425e-05\n",
      "(130, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "prob_RUL_smaller_w1: 0.0010211241\n",
      "prob_RUL_smaller_DT: 0.00011397487\n",
      "(140, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "prob_RUL_smaller_w1: 0.006141073\n",
      "prob_RUL_smaller_DT: 0.00027741006\n",
      "(150, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "prob_RUL_smaller_w1: 0.015922552\n",
      "prob_RUL_smaller_DT: 0.00045513213\n",
      "(160, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "prob_RUL_smaller_w1: 0.11417097\n",
      "prob_RUL_smaller_DT: 0.0013867567\n",
      "prob_RUL_smaller_w1: 0.11417097\n",
      "prob_RUL_smaller_DT: 0.0013867567\n",
      "component ordering at cycle: 160.0\n",
      "(170, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "prob_RUL_smaller_w1: 0.9614611\n",
      "prob_RUL_smaller_DT: 0.0048701665\n",
      "(180, 25)\n",
      "(1, 50, 25)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "prob_RUL_smaller_w1: 0.5706251\n",
      "prob_RUL_smaller_DT: 0.42218763\n",
      "prob_RUL_smaller_DT: 0.42218763\n",
      "preventive replacement informed at cycle: 180.0\n",
      "True failure: 200\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for id in validation_df['id'].unique():\n",
    "    print('ID:', id)\n",
    "    preventive_replacement = False\n",
    "    order                  = False\n",
    "\n",
    "    for cycle in range(validation_df[validation_df['id']==id].shape[0]-sequence_length+1):\n",
    "\n",
    "        if cycle in array_decisions:\n",
    "\n",
    "            norm_validation_df = pd.DataFrame(min_max_scaler.transform(validation_df[validation_df['id']==id][cols_normalize][:sequence_length+cycle]),\n",
    "                 columns=cols_normalize,\n",
    "                 index=validation_df[validation_df['id']==id][:sequence_length+cycle].index)\n",
    "            print(norm_validation_df.shape)\n",
    "            join_df = validation_df[validation_df['id']==id][:sequence_length+cycle][validation_df[validation_df['id']==id][:sequence_length+cycle].columns.difference(cols_normalize)].join(norm_validation_df)\n",
    "            validation_df_eval_online = join_df.reindex(columns = validation_df[validation_df['id']==id][cycle:sequence_length+cycle].columns)\n",
    "\n",
    "            seq_array_validation_k = validation_df_eval_online[sequence_cols].values[cycle:sequence_length+cycle]\n",
    "            seq_array_validation_k = np.asarray(seq_array_validation_k).astype(np.float32).reshape(1,sequence_length, nb_features)\n",
    "            #print(seq_array_validation_k.shape)\n",
    "            prob_RUL_smaller_DT    = estimator.predict(seq_array_validation_k).reshape(3)[2]\n",
    "            prob_RUL_smaller_w1    = estimator.predict(seq_array_validation_k).reshape(3)[1]\n",
    "\n",
    "            print('prob_RUL_smaller_w1:', prob_RUL_smaller_w1)\n",
    "            print('prob_RUL_smaller_DT:', prob_RUL_smaller_DT)\n",
    "\n",
    "\n",
    "            # evaluate decision heuristics\n",
    "            if order == False:\n",
    "                if C_p <= prob_RUL_smaller_w1*C_c:\n",
    "                    print('prob_RUL_smaller_w1:', prob_RUL_smaller_w1)\n",
    "                    print('prob_RUL_smaller_DT:', prob_RUL_smaller_DT)\n",
    "                    t_order_array[counter] = sequence_length+cycle\n",
    "                    order = True\n",
    "                    print('component ordering at cycle:', t_order_array[counter])\n",
    "\n",
    "            if C_p <= prob_RUL_smaller_DT*C_c:\n",
    "                print('prob_RUL_smaller_DT:', prob_RUL_smaller_DT)\n",
    "\n",
    "                t_LC_array[counter] = sequence_length+cycle\n",
    "                costs_rep_array[counter] = C_p\n",
    "                print('preventive replacement informed at cycle:', t_LC_array[counter])\n",
    "                # print('component lifecycle:', t_LC)\n",
    "                preventive_replacement = True\n",
    "                costs_delay_array[counter] = max(t_order_array[counter]+L-t_LC_array[counter], 0) * C_unav\n",
    "\n",
    "                costs_stock_array[counter]  = max(t_LC_array[counter] -(t_order_array[counter]+L), 0)*C_inv\n",
    "                # print('delay time', max(t_order+L-t_LC, 0))\n",
    "                # print('cost_delay_id:',cost_delay_id)\n",
    "                # print('cost of stock:', cost_stock_id)\n",
    "                break\n",
    "\n",
    "    if preventive_replacement == False:\n",
    "        t_LC_array[counter] = validation_df[validation_df['id']==id]['cycle'].iloc[-1]\n",
    "        print('Component failure at t:', t_LC_array[counter])\n",
    "        costs_rep_array[counter] = C_c\n",
    "\n",
    "        if order == False:\n",
    "            costs_delay_array[counter] = L * C_unav\n",
    "        else:\n",
    "            costs_delay_array[counter] = max(t_order_array[counter]+L-t_LC_array[counter], 0) * C_unav\n",
    "            costs_stock_array[counter] = max(t_LC_array[counter] -(t_order_array[counter]+L), 0)*C_inv\n",
    "\n",
    "    print('True failure:', validation_df[validation_df['id']==id]['cycle'].iloc[-1])\n",
    "    print('-----------------------------------------')\n",
    "    counter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "onea6sLe6PuA"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([100., 100., 100., 100., 100., 100., 100., 100., 100., 100., 100.,\n",
       "       100., 100., 100., 100., 100., 100., 100., 100., 100.])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "costs_rep_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "FAvJN15m6PuA"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0.,   0.,   0., 100.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "costs_delay_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "-Mmc0YIA6PuA"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10.,  0.,  0., 10.,  0.,  0., 10.,  0., 10.,  0., 10., 20.,  0.,\n",
       "       10., 10., 10.,  0.,  0., 10.,  0.])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "costs_stock_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "IkJNf5d26PuB"
   },
   "outputs": [],
   "source": [
    "costs_tot = costs_rep_array+costs_delay_array+costs_stock_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "Lp4AF1KW6PuB"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([110., 100., 100., 110., 100., 200., 110., 100., 110., 100., 110.,\n",
       "       120., 100., 110., 110., 110., 100., 100., 110., 100.])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "costs_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "fzXo4Qlw6PuB"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([230., 200., 290., 260., 180., 260., 170., 200., 210., 150., 130.,\n",
       "       330., 140., 250., 280., 330., 190., 150., 180., 180.])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_LC_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "QCNUa2J36PuB"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([200., 180., 270., 230., 160., 250., 140., 180., 180., 130., 100.,\n",
       "       290., 120., 220., 250., 300., 170., 130., 150., 160.])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_order_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S6g7k8Yrftya"
   },
   "source": [
    "### This code calculates the expected cost per unit time using the LSTM model. It computes the mean of the total costs divided by the mean of the time to component failure (t_LC_array). This metric gives an estimate of the average cost incurred per unit time in the system, considering both maintenance and operational costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P3_N4kNM6PuC"
   },
   "outputs": [],
   "source": [
    "expected_cost_LSTM = np.mean(costs_tot) / np.mean(t_LC_array)\n",
    "expected_cost_LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HQgoTz57gC_P"
   },
   "source": [
    "This code segment calculates the expected cost per unit time assuming perfect prognostics.\n",
    "`1. Perfect Prognostics Calculation:`\n",
    "> * It initializes an array `t_LC_perfect_array` to store the time of component failure for each unit in the validation dataset. This is calculated by dividing the last observed cycle number by the decision interval DT and then flooring the result to get the last decision cycle before failure.\n",
    "> * The loop iterates over each unique ID in the validation dataset, calculates the time of component failure for each unit, and stores it in\n",
    "`t_LC_perfect_array`.<br>\n",
    "> * `math.floor()` is used to round down the result to the nearest multiple of `DT`.\n",
    "> * Finally, the loop increments the counter for each unit.<br>\n",
    "\n",
    "`2. Cost Calculation:`\n",
    "> * `costs_perfect_array` is initialized with a value of `C_p`, representing the cost of preventive replacements. In a perfect scenario, only preventive replacements are made.\n",
    "> * This array holds the same cost value for each unit in the validation dataset.\n",
    "\n",
    "`3. Expected Cost Calculation:`\n",
    "> * `expected_cost_perfect` is calculated by taking the mean of `costs_perfect_array` and dividing it by the mean of `t_LC_perfect_array`.\n",
    "> * This calculation provides an estimate of the average cost per unit time assuming perfect prognostics, where components are replaced preventively at regular intervals.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IOD6NDfH6PuC"
   },
   "outputs": [],
   "source": [
    "# Perfect prognostics\n",
    "import math\n",
    "t_LC_perfect_array  = np.zeros(20)\n",
    "counter=0\n",
    "for id in validation_df['id'].unique():\n",
    "    t_LC_perfect_array[counter] = math.floor(validation_df[validation_df['id']==id]['cycle'].iloc[-1] /DT) * DT\n",
    "    counter+=1\n",
    "\n",
    "costs_perfect_array = np.ones(20)*C_p # a perfect policy will only lead to preventive replacements\n",
    "\n",
    "expected_cost_perfect = np.mean(costs_perfect_array)/np.mean(t_LC_perfect_array)\n",
    "expected_cost_perfect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H-vK-DBi6PuC"
   },
   "outputs": [],
   "source": [
    "t_LC_perfect_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZY7_LJce6PuC"
   },
   "outputs": [],
   "source": [
    "# evaluation of the metric defined in the paper\n",
    "M = (expected_cost_LSTM - expected_cost_perfect) / expected_cost_perfect\n",
    "M # it obtains a very small value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KofjvavY6PuD"
   },
   "outputs": [],
   "source": [
    "M*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P42Nu-Rg6PuE"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "4BsYPkY7gYGx",
    "ElhakcHtnX9J"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
